{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d047044f",
   "metadata": {},
   "source": [
    "# Agents with Memory\n",
    "\n",
    "We have an email assistant that uses a router to triage emails and then passes the email to the agent for response generation. We've also evaluated it and added human-in-the-loop (HITL) to review specific tool calls. Now, we add memory, giving our assistant the ability to remember our HITL feedback!\n",
    "\n",
    "![overview-img](img/overview_memory.png)\n",
    "\n",
    "## Memory in LangGraph\n",
    "\n",
    "### Thread-Scoped and Across-Thread Memory\n",
    "\n",
    "First, it's worth explaining how [memory works in LangGraph](https://langchain-ai.github.io/langgraphjs/concepts/memory/). LangGraph offers two distinct types of memory that serve complementary purposes:\n",
    "\n",
    "**Thread-Scoped Memory (Short-term)** operates within the boundaries of a single conversation thread. It's automatically managed as part of the graph's state and persisted through thread-scoped checkpoints. This memory type retains conversation history, uploaded files, retrieved documents, and other artifacts generated during the interaction. Think of it as the working memory that maintains context within one specific conversation, allowing the agent to reference earlier messages or actions without starting from scratch each time.\n",
    "\n",
    "**Across-Thread Memory (Long-term)** extends beyond individual conversations, creating a persistent knowledge base that spans multiple sessions. This memory is stored as JSON documents in a memory store, organized by namespaces (like folders) and distinct keys (like filenames). Unlike thread-scoped memory, this information persists even after conversations end, enabling the system to recall user preferences, past decisions, and accumulated knowledge. This is what allows an agent to truly learn and adapt over time, rather than treating each interaction as isolated.\n",
    "\n",
    "![short-vs-long-term-memory](img/short-vs-long.png)\n",
    "\n",
    "The [Store](https://langchain-ai.github.io/langgraphjs/concepts/persistence/) is the foundation of this architecture, providing a flexible database where memories can be organized, retrieved, and updated. What makes this approach powerful is that regardless of which memory type you're working with, the same Store interface provides consistent access patterns. This allows your agent's code to remain unchanged whether you're using a simple in-memory implementation during development or a production-grade database in deployment. \n",
    "\n",
    "### LangGraph Store\n",
    "\n",
    "LangGraph offers different [Store implementations depending on your deployment scenario](https://langchain-ai.github.io/langgraphjs/concepts/persistence/#memory-store):\n",
    "\n",
    "1. **Pure In-Memory (e.g., notebooks)**:\n",
    "   - Uses `import { InMemoryStore } from \"@langchain/langgraph/store/memory\"`\n",
    "   - Purely a JavaScript object in memory with no persistence\n",
    "   - Data is lost when the process terminates\n",
    "   - Useful for quick experiments and testing\n",
    "   - Includes semantic search with cosine similarity\n",
    "\n",
    "2. **Local Development with `langgraph dev`**:\n",
    "   - Similar to InMemoryStore but with pseudo-persistence\n",
    "   - Data is saved to the local filesystem between restarts\n",
    "   - Lightweight and fast, no need for external databases\n",
    "   - Semantic search uses cosine similarity for embedding comparisons\n",
    "   - Great for development but not designed for production use\n",
    "\n",
    "3. **LangGraph Platform or Production Deployments**:\n",
    "   - Uses PostgreSQL with pgvector for production-grade persistence\n",
    "   - Fully persistent data storage with reliable backups\n",
    "   - Scalable for larger datasets\n",
    "   - High-performance semantic search via pgvector\n",
    "   - Default distance metric is cosine similarity (customizable)\n",
    "\n",
    "Let's use the `InMemoryStore` here in the notebook! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa1dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Import or implement an in-memory store for development/testing\n",
    "import { InMemoryStore } from \"@langchain/langgraph\";\n",
    "\n",
    "const inMemoryStore = new InMemoryStore();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb204c",
   "metadata": {},
   "source": [
    "Memories are namespaced by an array, which in this specific example will be `[<user_id>, \"memories\"]`. The namespace array can be any length and represent anythingâ€”it does not have to be user specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0488a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "const userId = \"1\";\n",
    "const namespaceForMemory = [userId, \"memories\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8b303",
   "metadata": {},
   "source": [
    "We use the `store.put` method to save memories to our namespace in the store. When we do this, we specify the namespace (as defined above), and a key-value pair for the memory: the key is simply a unique identifier for the memory (`memoryId`), and the value (a plain JavaScript object) is the memory itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af95b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { v4 as uuid4 } from 'uuid';\n",
    "\n",
    "const memoryId = uuid4();\n",
    "const memory = { food_preference: \"I like pizza\" };\n",
    "await inMemoryStore.put(namespaceForMemory, memoryId, memory);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60408492",
   "metadata": {},
   "source": [
    "We can read out memories in our namespace using the `store.search` method, which will return all memories for a given user as an array. The most recent memory is the last in the array. Each memory is an object with certain attributes, such as `namespace`, `key`, `value`, `created_at`, and `updated_at`. The most important attribute is typically `value`, which contains the actual memory data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c25f5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  value: { food_preference: 'I like pizza' },\n",
      "  key: '2d29bbdd-7808-480e-bb0d-a163d3404601',\n",
      "  namespace: [ '1', 'memories' ],\n",
      "  createdAt: 2025-05-13T05:32:54.209Z,\n",
      "  updatedAt: 2025-05-13T05:32:54.209Z,\n",
      "  score: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "const memories: Record<string, any> = await inMemoryStore.search(namespaceForMemory);\n",
    "console.log(memories.at(-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3e781",
   "metadata": {},
   "source": [
    "To use this in a graph, all you need to do is compile the graph with the store and a checkpointer:\n",
    "\n",
    "```ts\n",
    "import { InMemorySaver } from \"@langchain/langgraph/checkpoint/memory\"; \n",
    "\n",
    "const checkpointer = new InMemorySaver();\n",
    "// When compiling your graph, pass both checkpointer and store:\n",
    "const graph = myGraph.compile({ checkpointer, store: inMemoryStore });\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c982928",
   "metadata": {},
   "source": [
    "The store is then accessible in any node of the graph, as we'll see below!\n",
    "\n",
    "## Adding Memory to our Assistant\n",
    "\n",
    "Let's take our graph with HITL and add memory to it. This will be very similar to what we had previously, but we'll simply update memory in the store when we get feedback from the user.\n",
    "\n",
    "![overview-img](img/HITL_flow_memory.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38308fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { StateGraph, START, END, interrupt, Command } from \"@langchain/langgraph\";\n",
    "import { initChatModel } from \"langchain/chat_models/universal\";\n",
    "\n",
    "// Email tool with correct properties\n",
    "const emailSchema = z.object({\n",
    "    recipient: z.string().describe(\"Email address of the recipient\"),\n",
    "    subject: z.string().describe(\"Clear and concise subject line for the email\"),\n",
    "    content: z.string().describe(\"Main body text of the email\"),\n",
    "});\n",
    "\n",
    "const writeEmail = tool(async ({\n",
    "    recipient,\n",
    "    subject,\n",
    "    content,\n",
    "}: z.infer<typeof emailSchema>) => {\n",
    "    return `Email draft created:\n",
    "To: ${recipient}\n",
    "Subject: ${subject}\n",
    "${content}\n",
    "[Draft saved. Ready to send or edit further.]`;\n",
    "}, {\n",
    "    name: \"write_email\",\n",
    "    description:\n",
    "        \"Write an email draft based on provided information. Use this when the user wants to compose a new email message.\",\n",
    "    schema: emailSchema,\n",
    "});\n",
    "\n",
    "\n",
    "const RouterSchema = z.object({\n",
    "    reasoning: z\n",
    "        .string()\n",
    "        .describe(\"Step-by-step reasoning behind the classification\"),\n",
    "    classification: z\n",
    "        .enum([\"ignore\", \"respond\", \"notify\"])\n",
    "        .describe(\n",
    "            \"The classification of an email: 'ignore' for irrelevant emails, \" +\n",
    "            \"'notify' for important information that doesn't need a response, \" +\n",
    "            \"'respond' for emails that need a reply\",\n",
    "        ),\n",
    "});\n",
    "\n",
    "// Calendar tool with correct properties\n",
    "const scheduleMeetingSchema = z.object({\n",
    "    title: z.string().describe(\"Meeting title\"),\n",
    "    attendees: z.array(z.string()).describe(\"List of attendees' emails\"),\n",
    "    startTime: z.string().describe(\"Meeting start time in ISO format\"),\n",
    "    endTime: z.string().describe(\"Meeting end time in ISO format\"),\n",
    "    description: z.string().optional().describe(\"Meeting description\"),\n",
    "});\n",
    "\n",
    "const scheduleMeeting = tool(async (args: z.infer<typeof scheduleMeetingSchema>) => {\n",
    "    const { title, attendees, startTime, endTime, description } = args;\n",
    "    // Mock implementation\n",
    "    return `Meeting \"${title}\" scheduled from ${startTime} to ${endTime} with ${attendees.length} attendees`;\n",
    "}, {\n",
    "    name: \"schedule_meeting\",\n",
    "    description: \"Schedule a meeting on the calendar\",\n",
    "    schema: scheduleMeetingSchema,\n",
    "});\n",
    "\n",
    "const availabilitySchema = z.object({\n",
    "    startTime: z.string().describe(\"Start time in ISO format\"),\n",
    "    endTime: z.string().describe(\"End time in ISO format\"),\n",
    "});\n",
    "\n",
    "const checkCalendarAvailability = tool(async (args: z.infer<typeof availabilitySchema>) => {\n",
    "    const { startTime, endTime } = args;\n",
    "    // Mock implementation\n",
    "    return `Time slot from ${startTime} to ${endTime} is available`;\n",
    "}, {\n",
    "    name: \"check_calendar_availability\",\n",
    "    description: \"Check calendar availability for a specified time range\",\n",
    "    schema: availabilitySchema,\n",
    "},\n",
    ");\n",
    "\n",
    "const Question = tool(\n",
    "    async ({ content }: { content: string }) => {\n",
    "        return `The user will see and can answer this question: ${content}`;\n",
    "    },\n",
    "    {\n",
    "        name: \"question\",\n",
    "        description: \"Ask the user a follow-up question\",\n",
    "        schema: z.object({\n",
    "            content: z.string().describe(\"The question to ask the user\"),\n",
    "        }),\n",
    "    },\n",
    ");\n",
    "\n",
    "// Define the doneSchema\n",
    "const doneSchema = z.object({\n",
    "    content: z.string().optional().describe(\"Optional completion message\"),\n",
    "});\n",
    "\n",
    "const Done = tool(async () => {\n",
    "    return \"Task completed successfully. No further actions required.\";\n",
    "}, {\n",
    "    name: \"Done\",\n",
    "    description:\n",
    "        \"Signal that you've completed the current task and no further actions are needed.\",\n",
    "    schema: doneSchema,\n",
    "});\n",
    "\n",
    "const tools = [\n",
    "    writeEmail,\n",
    "    scheduleMeeting,\n",
    "    checkCalendarAvailability,\n",
    "    Question,\n",
    "    Done,\n",
    "];\n",
    "\n",
    "const toolsByName = Object.fromEntries(tools.map((t) => [t.name, t]));\n",
    "\n",
    "// LLM setup\n",
    "const llm = initChatModel(\"openai:gpt-4.1\", { temperature: 0.0 });\n",
    "// Define RouterSchema and State as needed for your app\n",
    "const setupModels = async () => {\n",
    "    const baseModel = await llm;\n",
    "    const llmRouter = baseModel.withStructuredOutput(RouterSchema);\n",
    "    const llmWithTools = baseModel.bindTools(tools, { toolChoice: \"required\" });\n",
    "    return { llmRouter, llmWithTools };\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03538f56",
   "metadata": {},
   "source": [
    "Now, this is the critical part! We don't capture any feedback from the user in our graph.\n",
    "\n",
    "### Memory Management \n",
    "\n",
    "What we *want* to do is fairly straightforward: we want to add the feedback to the memory `Store`. If we compile our graph with the `Store`, we can access it in any nodeâ€”so that's not a problem!\n",
    "\n",
    "But we have to answer two questions:\n",
    "\n",
    "* 1) How do we want the memory to be structured?\n",
    "* 2) How do we want to update the memory?\n",
    "\n",
    "For 1), we'll just store memories as a string to keep things simple. In the function below, we'll fetch memories from the store as a string and initialize with a default if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2715152-2d19-4449-be4b-fdc602eee52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "const defaultTriageInstructions = `\n",
    "Emails that are not worth responding to:\n",
    "- Marketing newsletters and promotional emails\n",
    "- Spam or suspicious emails\n",
    "- CC'd on FYI threads with no direct questions\n",
    "\n",
    "There are also other things that should be known about, but don't require an email response. For these, you should notify (using the \\`notify\\` response). Examples of this include:\n",
    "- Team member out sick or on vacation\n",
    "- Build system notifications or deployments\n",
    "- Project status updates without action items\n",
    "- Important company announcements\n",
    "- FYI emails that contain relevant information for current projects\n",
    "- HR Department deadline reminders\n",
    "- Subscription status / renewal reminders\n",
    "- GitHub notifications\n",
    "\n",
    "Emails that are worth responding to:\n",
    "- Direct questions from team members requiring expertise\n",
    "- Meeting requests requiring confirmation\n",
    "- Critical bug reports related to team's projects\n",
    "- Requests from management requiring acknowledgment\n",
    "- Client inquiries about project status or features\n",
    "- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\n",
    "- Personal reminders related to family (wife / daughter)\n",
    "- Personal reminder related to self-care (doctor appointments, etc)\n",
    "`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9ab99d-bc21-4cf7-a58a-261e82920566",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Default calendar preferences\n",
    "const defaultCalPreferences = `\n",
    "30 minute meetings are preferred, but 15 minute meetings are also acceptable.\n",
    "`;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6cd98f1-15a7-4fbb-8cce-cbbb0503d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    " const defaultResponsePreferences = `\n",
    "Use professional and concise language. If the e-mail mentions a deadline, make sure to explicitly acknowledge and reference the deadline in your response.\n",
    "\n",
    "When responding to technical questions that require investigation:\n",
    "- Clearly state whether you will investigate or who you will ask\n",
    "- Provide an estimated timeline for when you'll have more information or complete the task\n",
    "\n",
    "When responding to event or conference invitations:\n",
    "- Always acknowledge any mentioned deadlines (particularly registration deadlines)\n",
    "- If workshops or specific topics are mentioned, ask for more specific details about them\n",
    "- If discounts (group or early bird) are mentioned, explicitly request information about them\n",
    "- Don't commit \n",
    "\n",
    "When responding to collaboration or project-related requests:\n",
    "- Acknowledge any existing work or materials mentioned (drafts, slides, documents, etc.)\n",
    "- Explicitly mention reviewing these materials before or during the meeting\n",
    "- When scheduling meetings, clearly state the specific day, date, and time proposed\n",
    "\n",
    "When responding to meeting scheduling requests:\n",
    "- If times are proposed, verify calendar availability for all time slots mentioned in the original email and then commit to one of the proposed times based on your availability by scheduling the meeting. Or, say you can't make it at the time proposed.\n",
    "- If no times are proposed, then check your calendar for availability and propose multiple time options when available instead of selecting just one.\n",
    "- Mention the meeting duration in your response to confirm you've noted it correctly.\n",
    "- Reference the meeting's purpose in your response.\n",
    "`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d195aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Get memory from the store or initialize with default if it doesn't exist.\n",
    " * @param store - The memory store instance\n",
    " * @param namespace - Array or tuple defining the memory namespace\n",
    " * @param defaultContent - Default content to use if memory doesn't exist\n",
    " * @returns The content of the memory profile, either from existing memory or the default\n",
    " */\n",
    "async function getMemory(\n",
    "  store,\n",
    "  namespace,\n",
    "  defaultContent,\n",
    ") {\n",
    "  // Search for existing memory with namespace and key\n",
    "  const userPreferences = await store.get(namespace, \"user_preferences\");\n",
    "\n",
    "  // If memory exists, return its content (the value)\n",
    "  if (userPreferences) {\n",
    "      return userPreferences.value ?? userPreferences;\n",
    "  }\n",
    "\n",
    "  // If memory doesn't exist, add it to the store and return the default content\n",
    "  await store.put(namespace, \"user_preferences\", defaultContent);\n",
    "\n",
    "  // Return the default content\n",
    "  return defaultContent;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5181e6",
   "metadata": {},
   "source": [
    "For 2) updating memory, we can use a few tricks from the [GPT-4.1 prompting guide](https://cookbook.openai.com/examples/gpt4-1_prompting_guide) to help us update the memory:\n",
    "\n",
    "* For optimal performance, repeat the key instructions at the start and end of the prompt\n",
    "* Create clear, explicit instructions \n",
    "* Use XML delimiters for structure\n",
    "* Provide examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f8aa70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { initChatModel } from \"langchain/chat_models/universal\";\n",
    "\n",
    "// Memory update instructions as template strings\n",
    "const MEMORY_UPDATE_INSTRUCTIONS = `\n",
    "# Role and Objective\n",
    "You are a memory profile manager for an email assistant agent that selectively updates user preferences based on feedback messages from human-in-the-loop interactions with the email assistant.\n",
    "\n",
    "# Instructions\n",
    "- NEVER overwrite the entire memory profile\n",
    "- ONLY make targeted additions of new information\n",
    "- ONLY update specific facts that are directly contradicted by feedback messages\n",
    "- PRESERVE all other existing information in the profile\n",
    "- Format the profile consistently with the original style\n",
    "- Generate the profile as a string\n",
    "\n",
    "# Reasoning Steps\n",
    "1. Analyze the current memory profile structure and content\n",
    "2. Review feedback messages from human-in-the-loop interactions\n",
    "3. Extract relevant user preferences from these feedback messages (such as edits to emails/calendar invites, explicit feedback on assistant performance, user decisions to ignore certain emails)\n",
    "4. Compare new information against existing profile\n",
    "5. Identify only specific facts to add or update\n",
    "6. Preserve all other existing information\n",
    "7. Output the complete updated profile\n",
    "\n",
    "# Example\n",
    "<memory_profile>\n",
    "RESPOND:\n",
    "- wife\n",
    "- specific questions\n",
    "- system admin notifications\n",
    "NOTIFY: \n",
    "- meeting invites\n",
    "IGNORE:\n",
    "- marketing emails\n",
    "- company-wide announcements\n",
    "- messages meant for other teams\n",
    "</memory_profile>\n",
    "\n",
    "<user_messages>\n",
    "\"The assistant shouldn't have responded to that system admin notification.\"\n",
    "</user_messages>\n",
    "\n",
    "<updated_profile>\n",
    "RESPOND:\n",
    "- wife\n",
    "- specific questions\n",
    "NOTIFY: \n",
    "- meeting invites\n",
    "- system admin notifications\n",
    "IGNORE:\n",
    "- marketing emails\n",
    "- company-wide announcements\n",
    "- messages meant for other teams\n",
    "</updated_profile>\n",
    "\n",
    "# Process current profile for {namespace}\n",
    "<memory_profile>\n",
    "{current_profile}\n",
    "</memory_profile>\n",
    "\n",
    "Think step by step about what specific feedback is being provided and what specific information should be added or updated in the profile while preserving everything else.`;\n",
    "\n",
    "const MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT = `\n",
    "Remember:\n",
    "- NEVER overwrite the entire profile\n",
    "- ONLY make targeted additions or changes based on explicit feedback\n",
    "- PRESERVE all existing information not directly contradicted\n",
    "- Output the complete updated profile as a string\n",
    "`;\n",
    "/**\n",
    " * Update memory profile in the store.\n",
    " * @param store - The memory store instance\n",
    " * @param namespace - Array defining the memory namespace\n",
    " * @param messages - Array of messages to update the memory with\n",
    " */\n",
    "async function updateMemory(\n",
    "    store,\n",
    "    namespace,\n",
    "    messages\n",
    ") {\n",
    "    // Get the existing memory\n",
    "    const userPreferences = await store.get(namespace, \"user_preferences\");\n",
    "\n",
    "\n",
    "    // Prepare the prompt\n",
    "    const prompt = [\n",
    "        {\n",
    "            role: \"system\",\n",
    "            content: MEMORY_UPDATE_INSTRUCTIONS\n",
    "                .replace(\"{current_profile}\", userPreferences?.value ?? \"\")\n",
    "                .replace(\"{namespace}\", namespace.join(\", \")),\n",
    "        },\n",
    "        {\n",
    "            role: \"user\",\n",
    "            content: \"Think carefully and update the memory profile based upon these user messages:\",\n",
    "        },\n",
    "        ...messages,\n",
    "    ];\n",
    "    const llm = await initChatModel(\n",
    "        \"openai:gpt-4o\",\n",
    "        { temperature: 0.0 }\n",
    "    );\n",
    "\n",
    "    const llmWithTools = llm.bindTools(tools, { toolChoice: \"required\" });\n",
    "    // Call the LLM\n",
    "    const result = await llmWithTools.invoke(prompt);\n",
    "\n",
    "    // Save the updated memory to the store\n",
    "    await store.put(namespace, \"user_preferences\", result.content);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af20960",
   "metadata": {},
   "source": [
    "We set up the triage router as we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1a789ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  StateGraph,\n",
    "  START,\n",
    "  END,\n",
    "  Command\n",
    "} from \"@langchain/langgraph\";\n",
    "// triage router node dependencies \n",
    "function parseEmail(email: EmailData): {\n",
    "  author: string;\n",
    "  to: string;\n",
    "  subject: string;\n",
    "  emailThread: string;\n",
    "} {\n",
    "  try {\n",
    "      // Extract key information from email data\n",
    "      const author = email.from_email;\n",
    "      const to = email.to_email;\n",
    "      const subject = email.subject;\n",
    "      const emailThread = email.page_content;\n",
    "\n",
    "      return { author, to, subject, emailThread };\n",
    "  } catch (error) {\n",
    "      console.error(\"Error parsing email:\", error);\n",
    "      throw new Error(\"Failed to parse email\");\n",
    "  }\n",
    "}\n",
    "\n",
    "const defaultTriageInstructions = `\n",
    "Emails that are not worth responding to:\n",
    "- Marketing newsletters and promotional emails\n",
    "- Spam or suspicious emails\n",
    "- CC'd on FYI threads with no direct questions\n",
    "\n",
    "There are also other things that should be known about, but don't require an email response. For these, you should notify (using the \\`notify\\` response). Examples of this include:\n",
    "- Team member out sick or on vacation\n",
    "- Build system notifications or deployments\n",
    "- Project status updates without action items\n",
    "- Important company announcements\n",
    "- FYI emails that contain relevant information for current projects\n",
    "- HR Department deadline reminders\n",
    "- Subscription status / renewal reminders\n",
    "- GitHub notifications\n",
    "\n",
    "Emails that are worth responding to:\n",
    "- Direct questions from team members requiring expertise\n",
    "- Meeting requests requiring confirmation\n",
    "- Critical bug reports related to team's projects\n",
    "- Requests from management requiring acknowledgment\n",
    "- Client inquiries about project status or features\n",
    "- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\n",
    "- Personal reminders related to family (wife / daughter)\n",
    "- Personal reminder related to self-care (doctor appointments, etc)\n",
    "`;\n",
    "\n",
    "///////PROMPTS \n",
    "const defaultBackground = `\n",
    "I'm Lance, a software engineer at LangChain.\n",
    "`;\n",
    "// Agentic workflow triage user prompt\n",
    "const triageUserPrompt = `\n",
    "Please determine how to handle the below email thread:\n",
    "\n",
    "From: {author}\n",
    "To: {to}\n",
    "Subject: {subject}\n",
    "{email_thread}`;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "const triageSystemPrompt = `\n",
    "<Role>\n",
    "Your role is to triage incoming emails based upon instructs and background information below.\n",
    "</Role>\n",
    "\n",
    "<Background>\n",
    "{background}. \n",
    "</Background>\n",
    "\n",
    "<Instructions>\n",
    "Categorize each email into one of three categories:\n",
    "1. IGNORE - Emails that are not worth responding to or tracking\n",
    "2. NOTIFY - Important information that worth notification but doesn't require a response\n",
    "3. RESPOND - Emails that need a direct response\n",
    "Classify the below email into one of these categories.\n",
    "</Instructions>\n",
    "\n",
    "<Rules>\n",
    "{triage_instructions}\n",
    "</Rules>\n",
    "`;\n",
    "\n",
    "function formatEmailMarkdown(\n",
    "  subject: string,\n",
    "  author: string,\n",
    "  to: string,\n",
    "  emailThread: string,\n",
    "): string {\n",
    "  return `## Email: ${subject}\n",
    "**From**: ${author}\n",
    "**To**: ${to}\n",
    "${emailThread}`;\n",
    "}\n",
    "\n",
    "type EmailData = {\n",
    "  id: string;\n",
    "  thread_id: string;\n",
    "  from_email: string;\n",
    "  subject: string;\n",
    "  page_content: string;\n",
    "  send_time: string;\n",
    "  to_email: string;\n",
    "};\n",
    "\n",
    "async function triageRouter(state) {\n",
    "  const { author, to, subject, emailThread } = parseEmail(state.email_input);\n",
    "\n",
    "  const emailMarkdown = formatEmailMarkdown(subject, author, to, emailThread);\n",
    "  // Fix the string template replacement issue\n",
    "  const userPrompt = triageUserPrompt\n",
    "      .replace(\"{author}\", author)\n",
    "      .replace(\"{to}\", to)\n",
    "      .replace(\"{subject}\", subject)\n",
    "      .replace(\"{email_thread}\", emailThread);\n",
    "  // Fix the string template replacement issue\n",
    "  const systemPrompt = triageSystemPrompt\n",
    "      .replace(\"{background}\", defaultBackground)\n",
    "      .replace(\"{triage_instructions}\", defaultTriageInstructions);\n",
    "\n",
    "  // Await the model to be initialized first\n",
    "  const model = await llm;\n",
    "  const routerModel = model.withStructuredOutput(RouterSchema);\n",
    "\n",
    "  // Await the invoke result\n",
    "  const result = await routerModel.invoke([\n",
    "      { role: \"system\", content: systemPrompt },\n",
    "      { role: \"user\", content: userPrompt },\n",
    "  ]);\n",
    "\n",
    "  const classification = result.classification;\n",
    "\n",
    "  if (classification === \"respond\") {\n",
    "      console.log(\"ðŸ“§ Classification: RESPOND - This email requires a response\");\n",
    "      return new Command({\n",
    "          goto: \"response_agent\",\n",
    "          update: {\n",
    "              classification_decision: result.classification,\n",
    "              messages: [\n",
    "                  {\n",
    "                      role: \"user\",\n",
    "                      content: `Respond to the email: ${emailMarkdown}`,\n",
    "                  },\n",
    "              ],\n",
    "          },\n",
    "      });\n",
    "  } else if (classification === \"ignore\") {\n",
    "      console.log(\"ðŸš« Classification: IGNORE - This email can be safely ignored\");\n",
    "      return new Command({\n",
    "          goto: END,\n",
    "          update: { classification_decision: classification },\n",
    "      });\n",
    "  } else if (classification === \"notify\") {\n",
    "      console.log(\"ðŸ”” Classification: NOTIFY - This email contains important information\");\n",
    "      return new Command({\n",
    "          goto: \"triage_interrupt_handler\",\n",
    "          update: { classification_decision: classification },\n",
    "      });\n",
    "  } else {\n",
    "      return new Command({\n",
    "          goto: END,\n",
    "          update: { classification_decision: classification },\n",
    "      });\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be4d63",
   "metadata": {},
   "source": [
    "We only need to make a small change to the interrupt handler to update the memory when the user provides feedback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f76ef46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async function triageInterruptHandler(state, store) {\n",
    "\n",
    "  const { author, to, subject, emailThread } = parseEmail(state.email_input);\n",
    "  const emailMarkdown = formatEmailMarkdown(subject, author, to, emailThread);\n",
    "\n",
    "  const messages = [\n",
    "      {\n",
    "          role: \"user\",\n",
    "          content: `Email to notify user about: ${emailMarkdown}`,\n",
    "      },\n",
    "  ];\n",
    "\n",
    "  const request = {\n",
    "      action_request: {\n",
    "          action: `Email Assistant: ${state.classification_decision}`,\n",
    "          args: {},\n",
    "      },\n",
    "      config: {\n",
    "          allow_ignore: true,\n",
    "          allow_respond: true,\n",
    "          allow_edit: true,\n",
    "          allow_accept: true,\n",
    "      },\n",
    "      description: emailMarkdown,\n",
    "  };\n",
    "\n",
    "  const response = interrupt([request])[0];\n",
    "\n",
    "  let goto: \"response_agent\" | \"__end__\";\n",
    "  if (response.type === \"response\") {\n",
    "      const userInput = response.args;\n",
    "      // Save feedback to memory\n",
    "      const memoryId = uuid4();\n",
    "      await store.put(namespaceForMemory, memoryId, { feedback: userInput, email: state.email_input });\n",
    "      messages.push({\n",
    "          role: \"user\",\n",
    "          content: `User wants to reply to the email. Use this feedback to respond: ${userInput}`,\n",
    "      });\n",
    "      goto = \"response_agent\";\n",
    "  } else if (response.type === \"ignore\") {\n",
    "      goto = END;\n",
    "  } else if (response.type === \"accept\") {\n",
    "      goto = \"response_agent\";\n",
    "  } else if (response.type === \"edit\") {\n",
    "      goto = \"response_agent\";\n",
    "  } else {\n",
    "      throw new Error(`Invalid response: ${JSON.stringify(response)}`);\n",
    "  }\n",
    "\n",
    "  return new Command({\n",
    "      goto,\n",
    "      update: { messages },\n",
    "  });\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd428f5",
   "metadata": {},
   "source": [
    "### Incorporating Memory into LLM Responses\n",
    "\n",
    "Now that we have memory managers set up, we can use the stored preferences when generating responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a82b17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * LLM decides whether to call a tool or not.\n",
    " * @param state - The agent state\n",
    " * @param store - The memory store instance\n",
    " * @returns An object with the LLM's response messages\n",
    " */\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async function llmCall(\n",
    "    state,\n",
    "    config\n",
    ") {\n",
    "    // Search for existing cal_preferences memory\n",
    "    const calPreferences = getMemory(config.store, [\"email_assistant\", \"cal_preferences\"], defaultCalPreferences);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60aff5d",
   "metadata": {},
   "source": [
    "### Memory Integration in the Interrupt Handler\n",
    "\n",
    "Similarly, we add memory to the interrupt handler! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "126d3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Creates an interrupt for human review of tool calls.\n",
    " * @param state - The agent state\n",
    " * @param store - The memory store instance\n",
    " * @returns Command object for the next node and state update\n",
    " */\n",
    "async function interruptHandler(\n",
    "  state,\n",
    "  store\n",
    ") {\n",
    "  const result = [];\n",
    "  let goto = \"llm_call\";\n",
    "\n",
    "  // Iterate over the tool calls in the last message\n",
    "  for (const toolCall of state.messages[state.messages.length - 1].tool_calls) {\n",
    "      const hitlTools = [\"write_email\", \"schedule_meeting\", \"Question\"];\n",
    "\n",
    "      // If tool is not in our HITL list, execute it directly without interruption\n",
    "      if (!hitlTools.includes(toolCall.name)) {\n",
    "          const tool = toolsByName[toolCall.name];\n",
    "          const observation = await tool.invoke(toolCall.args);\n",
    "          result.push({ role: \"tool\", content: observation, tool_call_id: toolCall.id });\n",
    "          continue;\n",
    "      }\n",
    "\n",
    "      // Get original email from email_input in state\n",
    "      const emailInput = state.email_input;\n",
    "      const { author, to, subject, emailThread } = parseEmail(emailInput);\n",
    "      const originalEmailMarkdown = formatEmailMarkdown(subject, author, to, emailThread);\n",
    "\n",
    "      function formatForDisplay(state, toolCall): string {\n",
    "          // Initialize empty display\n",
    "          let display = \"\";\n",
    "\n",
    "          // Add tool call information based on tool type\n",
    "          switch (toolCall.name) {\n",
    "              case \"write_email\":\n",
    "                  display += `# Email Draft\n",
    "    \n",
    "    **To**: ${toolCall.args.to}\n",
    "    **Subject**: ${toolCall.args.subject}\n",
    "    \n",
    "    ${toolCall.args.content}\n",
    "    `;\n",
    "                  break;\n",
    "\n",
    "              case \"schedule_meeting\":\n",
    "                  display += `# Calendar Invite\n",
    "    \n",
    "    **Meeting**: ${toolCall.args.subject}\n",
    "    **Attendees**: ${toolCall.args.attendees?.join(\", \")}\n",
    "    **Duration**: ${toolCall.args.duration_minutes} minutes\n",
    "    **Day**: ${toolCall.args.preferred_day}\n",
    "    `;\n",
    "                  break;\n",
    "\n",
    "              case \"question\":\n",
    "                  // Special formatting for questions to make them clear\n",
    "                  display += `# Question for User\n",
    "    \n",
    "    ${toolCall.args.content}\n",
    "    `;\n",
    "                  break;\n",
    "\n",
    "              default:\n",
    "                  // Generic format for other tools\n",
    "                  display += `# Tool Call: ${toolCall.name}\n",
    "    \n",
    "    Arguments:\n",
    "    ${JSON.stringify(toolCall.args, null, 2)}\n",
    "    `;\n",
    "          }\n",
    "\n",
    "          return display;\n",
    "      }\n",
    "      // Format tool call for display and prepend the original email\n",
    "      const toolDisplay = formatForDisplay(state, toolCall);\n",
    "      const description = originalEmailMarkdown + toolDisplay;\n",
    "\n",
    "      // Configure what actions are allowed in Agent Inbox\n",
    "      let config;\n",
    "      if (toolCall.name === \"write_email\" || toolCall.name === \"schedule_meeting\") {\n",
    "          config = {\n",
    "              allow_ignore: true,\n",
    "              allow_respond: true,\n",
    "              allow_edit: true,\n",
    "              allow_accept: true,\n",
    "          };\n",
    "      } else if (toolCall.name === \"Question\") {\n",
    "          config = {\n",
    "              allow_ignore: true,\n",
    "              allow_respond: true,\n",
    "              allow_edit: false,\n",
    "              allow_accept: false,\n",
    "          };\n",
    "      } else {\n",
    "          throw new Error(`Invalid tool call: ${toolCall.name}`);\n",
    "      }\n",
    "\n",
    "      // Create the interrupt request\n",
    "      const request = {\n",
    "          action_request: {\n",
    "              action: toolCall.name,\n",
    "              args: toolCall.args,\n",
    "          },\n",
    "          config,\n",
    "          description,\n",
    "      };\n",
    "\n",
    "      // Send to Agent Inbox and wait for response\n",
    "      const [response] = await interrupt([request]);\n",
    "\n",
    "      // Handle the responses\n",
    "      if (response.type === \"accept\") {\n",
    "          const tool = toolsByName[toolCall.name];\n",
    "          const observation = await tool.invoke(toolCall.args);\n",
    "          result.push({ role: \"tool\", content: observation, tool_call_id: toolCall.id });\n",
    "\n",
    "      } else if (response.type === \"edit\") {\n",
    "          const tool = toolsByName[toolCall.name];\n",
    "          const editedArgs = response.args.args;\n",
    "          const initialToolCall = `${toolCall.name}: ${JSON.stringify(toolCall.args)}`;\n",
    "          const aiMessage = state.messages[state.messages.length - 1];\n",
    "          const currentId = toolCall.id;\n",
    "\n",
    "          // Replace the original tool call with the edited one\n",
    "          aiMessage.tool_calls = [\n",
    "              ...aiMessage.tool_calls.filter(tc => tc.id !== currentId),\n",
    "              { type: \"tool_call\", name: toolCall.name, args: editedArgs, id: currentId }\n",
    "          ];\n",
    "\n",
    "          const observation = await tool.invoke(editedArgs);\n",
    "          result.push({ role: \"tool\", content: observation, tool_call_id: currentId });\n",
    "\n",
    "          // Update memory\n",
    "          if (toolCall.name === \"write_email\") {\n",
    "              await updateMemory(store, [\"email_assistant\", \"response_preferences\"], [\n",
    "                  {\n",
    "                      role: \"user\",\n",
    "                      content: `User edited the email response. Here is the initial email generated by the assistant: ${initialToolCall}. Here is the edited email: ${JSON.stringify(editedArgs)}. Follow all instructions above, and remember: ${MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.`\n",
    "                  }\n",
    "              ]);\n",
    "          } else if (toolCall.name === \"schedule_meeting\") {\n",
    "              await updateMemory(store, [\"email_assistant\", \"cal_preferences\"], [\n",
    "                  {\n",
    "                      role: \"user\",\n",
    "                      content: `User edited the calendar invitation. Here is the initial calendar invitation generated by the assistant: ${initialToolCall}. Here is the edited calendar invitation: ${JSON.stringify(editedArgs)}. Follow all instructions above, and remember: ${MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.`\n",
    "                  }\n",
    "              ]);\n",
    "          } else {\n",
    "              throw new Error(`Invalid tool call: ${toolCall.name}`);\n",
    "          }\n",
    "\n",
    "      } else if (response.type === \"ignore\") {\n",
    "          let ignoreContent = \"\";\n",
    "          if (toolCall.name === \"write_email\") {\n",
    "              ignoreContent = \"User ignored this email draft. Ignore this email and end the workflow.\";\n",
    "              goto = END;\n",
    "              await updateMemory(store, [\"email_assistant\", \"triage_preferences\"], [\n",
    "                  ...state.messages,\n",
    "                  ...result,\n",
    "                  {\n",
    "                      role: \"user\",\n",
    "                      content: `The user ignored the email draft. That means they did not want to respond to the email. Update the triage preferences to ensure emails of this type are not classified as respond. Follow all instructions above, and remember: ${MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.`\n",
    "                  }\n",
    "              ]);\n",
    "          } else if (toolCall.name === \"schedule_meeting\") {\n",
    "              ignoreContent = \"User ignored this calendar meeting draft. Ignore this email and end the workflow.\";\n",
    "              goto = END;\n",
    "              await updateMemory(store, [\"email_assistant\", \"triage_preferences\"], [\n",
    "                  ...state.messages,\n",
    "                  ...result,\n",
    "                  {\n",
    "                      role: \"user\",\n",
    "                      content: `The user ignored the calendar meeting draft. That means they did not want to schedule a meeting for this email. Update the triage preferences to ensure emails of this type are not classified as respond. Follow all instructions above, and remember: ${MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.`\n",
    "                  }\n",
    "              ]);\n",
    "          } else if (toolCall.name === \"Question\") {\n",
    "              ignoreContent = \"User ignored this question. Ignore this email and end the workflow.\";\n",
    "              goto = END;\n",
    "              await updateMemory(store, [\"email_assistant\", \"triage_preferences\"], [\n",
    "                  ...state.messages,\n",
    "                  ...result,\n",
    "                  {\n",
    "                      role: \"user\",\n",
    "                      content: `The user ignored the Question. That means they did not want to answer the question or deal with this email. Update the triage preferences to ensure emails of this type are not classified as respond. Follow all instructions above, and remember: ${MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.`\n",
    "                  }\n",
    "              ]);\n",
    "          } else {\n",
    "              throw new Error(`Invalid tool call: ${toolCall.name}`);\n",
    "          }\n",
    "          result.push({ role: \"tool\", content: ignoreContent, tool_call_id: toolCall.id });\n",
    "\n",
    "      } else if (response.type === \"response\") {\n",
    "          const userFeedback = response.args;\n",
    "          if (toolCall.name === \"write_email\") {\n",
    "              result.push({\n",
    "                  role: \"tool\",\n",
    "                  content: `User gave feedback, which can we incorporate into the email. Feedback: ${userFeedback}`,\n",
    "                  tool_call_id: toolCall.id\n",
    "              });\n",
    "              await updateMemory(store, [\"email_assistant\", \"response_preferences\"], [\n",
    "                  ...state.messages,\n",
    "                  ...result,\n",
    "                  {\n",
    "                      role: \"user\",\n",
    "                      content: `User gave feedback, which we can use to update the response preferences. Follow all instructions above, and remember: ${MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.`\n",
    "                  }\n",
    "              ]);\n",
    "          } else if (toolCall.name === \"schedule_meeting\") {\n",
    "              result.push({\n",
    "                  role: \"tool\",\n",
    "                  content: `User gave feedback, which can we incorporate into the meeting request. Feedback: ${userFeedback}`,\n",
    "                  tool_call_id: toolCall.id\n",
    "              });\n",
    "              await updateMemory(store, [\"email_assistant\", \"cal_preferences\"], [\n",
    "                  ...state.messages,\n",
    "                  ...result,\n",
    "                  {\n",
    "                      role: \"user\",\n",
    "                      content: `User gave feedback, which we can use to update the calendar preferences. Follow all instructions above, and remember: ${MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.`\n",
    "                  }\n",
    "              ]);\n",
    "          } else if (toolCall.name === \"Question\") {\n",
    "              result.push({\n",
    "                  role: \"tool\",\n",
    "                  content: `User answered the question, which we can use for any follow up actions. Feedback: ${userFeedback}`,\n",
    "                  tool_call_id: toolCall.id\n",
    "              });\n",
    "          } else {\n",
    "              throw new Error(`Invalid tool call: ${toolCall.name}`);\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "\n",
    "  // Update the state\n",
    "  const update = { messages: result };\n",
    "  return new Command({ goto, update });\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecedcaec",
   "metadata": {},
   "source": [
    "The rest is the same as before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7041f50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\ttriage_router(triage_router)\n",
      "\ttriage_interrupt_handler(triage_interrupt_handler)\n",
      "\tresponse_agent___start__(<p>__start__</p>)\n",
      "\tresponse_agent_llm_call(llm_call)\n",
      "\tresponse_agent_interrupt_handler(interrupt_handler)\n",
      "\tresponse_agent___end__(<p>__end__</p>)\n",
      "\t__start__ --> triage_router;\n",
      "\ttriage_router --> triage_interrupt_handler;\n",
      "\ttriage_router --> response_agent___start__;\n",
      "\tsubgraph response_agent\n",
      "\tresponse_agent___start__ --> response_agent_llm_call;\n",
      "\tresponse_agent_interrupt_handler --> response_agent_llm_call;\n",
      "\tresponse_agent_llm_call -.-> response_agent_interrupt_handler;\n",
      "\tresponse_agent_llm_call -.-> response_agent___end__;\n",
      "\tend\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2;\n",
      "\tclassDef first fill-opacity:0;\n",
      "\tclassDef last fill:#bfb6fc;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import { StateGraph, START, END, Command } from \"@langchain/langgraph\";\n",
    "import { AIMessage, BaseMessage, HumanMessage, ToolMessage } from \"@langchain/core/messages\";\n",
    "import { ToolCall } from \"@langchain/core/messages/tool\";\n",
    "import { Messages, addMessages } from \"@langchain/langgraph\";\n",
    "import \"@langchain/langgraph/zod\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "\n",
    "\n",
    "// Define proper state schema\n",
    "const MessagesState = z.object({\n",
    "    messages: z\n",
    "        .custom<BaseMessage[]>()\n",
    "        .default(() => [])\n",
    "        .langgraph.reducer<Messages>((left, right) => addMessages(left, right)),\n",
    "});\n",
    "\n",
    "// Extend MessagesState for our email agent\n",
    "const EmailAgentState = MessagesState.extend({\n",
    "    email_input: z.any(),\n",
    "    classification_decision: z\n",
    "        .enum([\"ignore\", \"respond\", \"notify\", \"error\"])\n",
    "        .nullable()\n",
    "        .default(null),\n",
    "});\n",
    "\n",
    "// Create shouldContinue function for conditional edges\n",
    "function shouldContinue(state) {\n",
    "    const messages = state.messages;\n",
    "    if (!messages || messages.length === 0) return END;\n",
    "\n",
    "    const lastMessage = messages[messages.length - 1];\n",
    "\n",
    "    if (hasToolCalls(lastMessage)) {\n",
    "        // Check if any tool call is the \"Done\" tool\n",
    "        if (lastMessage.tool_calls.some(toolCall => toolCall.name === \"Done\")) {\n",
    "            return END;\n",
    "        }\n",
    "        return \"interrupt_handler\";\n",
    "    }\n",
    "\n",
    "    return END;\n",
    "}\n",
    "\n",
    "\n",
    "// Helper for type checking\n",
    "const hasToolCalls = (\n",
    "    message: BaseMessage\n",
    "): message is AIMessage & { tool_calls: ToolCall[] } => {\n",
    "    return (\n",
    "        message.getType() === \"ai\" &&\n",
    "        \"tool_calls\" in message &&\n",
    "        Array.isArray((message as any).tool_calls) &&\n",
    "        (message as any).tool_calls.length > 0\n",
    "    );\n",
    "};\n",
    "\n",
    "// Build the agent workflow using the graph builder already defined\n",
    "const agentBuilder = new StateGraph(EmailAgentState)\n",
    "    .addNode(\"llm_call\", llmCall)\n",
    "    .addNode(\"interrupt_handler\", interruptHandler)\n",
    "    .addEdge(START, \"llm_call\")\n",
    "    .addConditionalEdges(\"llm_call\", shouldContinue)\n",
    "    .addEdge(\"interrupt_handler\", \"llm_call\");\n",
    "\n",
    "\n",
    "// Compile the agent\n",
    "const responseAgent = agentBuilder.compile();\n",
    "\n",
    "const StateSchema = z.object({\n",
    "    email_input: z.any(),\n",
    "    classification_decision: z.string().optional(),\n",
    "    messages: z.array(z.any()).default([]).langgraph.reducer(addMessages),\n",
    "});\n",
    "\n",
    "// 2. Use z.infer for the type (optional, for TS type safety)\n",
    "type State = z.infer<typeof StateSchema>;\n",
    "\n",
    "// Build overall workflow with store and checkpointer\n",
    "const overallWorkflow = new StateGraph(StateSchema)\n",
    "    .addNode(\"triage_router\", triageRouter)\n",
    "    .addNode(\"triage_interrupt_handler\", (state, config) => triageInterruptHandler(state, config.store))\n",
    "    .addNode(\"response_agent\", responseAgent)\n",
    "    .addEdge(START, \"triage_router\")\n",
    "    .addEdge(\"triage_router\", \"triage_interrupt_handler\")\n",
    "    .addEdge(\"triage_router\", \"response_agent\");\n",
    "// Compile the overall workflow\n",
    "const emailAssistant = overallWorkflow.compile();\n",
    "\n",
    "const drawnGraph = await emailAssistant.getGraphAsync({ xray: true })\n",
    "console.log(drawnGraph.drawMermaid());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43747219",
   "metadata": {},
   "source": [
    "## Testing the agent with memory\n",
    "\n",
    "Now that we've implemented memory into our email assistant, let's test how the system learns from user feedback and adapts over time. This testing section explores how different types of user interactions create distinct memory updates that improve the assistant's future performance.\n",
    "\n",
    "The key questions we're answering through these tests:\n",
    "1. How does the system capture and store user preferences?\n",
    "2. How do these stored preferences affect future decisions?\n",
    "3. What patterns of interaction lead to which types of memory updates?\n",
    "\n",
    "First, let's build a helper function to display memory content so we can track how it evolves throughout our tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59079929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    'Emails that are not worth responding to:\\n' +\n",
      "    '- Marketing newsletters and promotional emails\\n' +\n",
      "    '- Spam or suspicious emails\\n' +\n",
      "    \"- CC'd on FYI threads with no direct questions\\n\" +\n",
      "    '\\n' +\n",
      "    \"There are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\\n\" +\n",
      "    '- Team member out sick or on vacation\\n' +\n",
      "    '- Build system notifications or deployments\\n' +\n",
      "    '- Project status updates without action items\\n' +\n",
      "    '- Important company announcements\\n' +\n",
      "    '- FYI emails that contain relevant information for current projects\\n' +\n",
      "    '- HR Department deadline reminders\\n' +\n",
      "    '- Subscription status / renewal reminders\\n' +\n",
      "    '- GitHub notifications\\n' +\n",
      "    '\\n' +\n",
      "    'Emails that are worth responding to:\\n' +\n",
      "    '- Direct questions from team members requiring expertise\\n' +\n",
      "    '- Meeting requests requiring confirmation\\n' +\n",
      "    \"- Critical bug reports related to team's projects\\n\" +\n",
      "    '- Requests from management requiring acknowledgment\\n' +\n",
      "    '- Client inquiries about project status or features\\n' +\n",
      "    '- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\\n' +\n",
      "    '- Personal reminders related to family (wife / daughter)\\n' +\n",
      "    '- Personal reminder related to self-care (doctor appointments, etc)\\n'\n",
      "}\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- cal_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    '30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'\n",
      "}\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- response_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    'Use professional and concise language. If the e-mail mentions a deadline, make sure to explicitly acknowledge and reference the deadline in your response.\\n' +\n",
      "    '\\n' +\n",
      "    'When responding to technical questions that require investigation:\\n' +\n",
      "    '- Clearly state whether you will investigate or who you will ask\\n' +\n",
      "    \"- Provide an estimated timeline for when you'll have more information or complete the task\\n\" +\n",
      "    '\\n' +\n",
      "    'When responding to event or conference invitations:\\n' +\n",
      "    '- Always acknowledge any mentioned deadlines (particularly registration deadlines)\\n' +\n",
      "    '- If workshops or specific topics are mentioned, ask for more specific details about them\\n' +\n",
      "    '- If discounts (group or early bird) are mentioned, explicitly request information about them\\n' +\n",
      "    \"- Don't commit \\n\" +\n",
      "    '\\n' +\n",
      "    'When responding to collaboration or project-related requests:\\n' +\n",
      "    '- Acknowledge any existing work or materials mentioned (drafts, slides, documents, etc.)\\n' +\n",
      "    '- Explicitly mention reviewing these materials before or during the meeting\\n' +\n",
      "    '- When scheduling meetings, clearly state the specific day, date, and time proposed\\n' +\n",
      "    '\\n' +\n",
      "    'When responding to meeting scheduling requests:\\n' +\n",
      "    \"- If times are proposed, verify calendar availability for all time slots mentioned in the original email and then commit to one of the proposed times based on your availability by scheduling the meeting. Or, say you can't make it at the time proposed.\\n\" +\n",
      "    '- If no times are proposed, then check your calendar for availability and propose multiple time options when available instead of selecting just one.\\n' +\n",
      "    \"- Mention the meeting duration in your response to confirm you've noted it correctly.\\n\" +\n",
      "    \"- Reference the meeting's purpose in your response.\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "\n",
    "import { MemorySaver, InMemoryStore } from \"@langchain/langgraph\";\n",
    "const store = new InMemoryStore();\n",
    "const checkpointer = new MemorySaver();\n",
    "const graph = overallWorkflow.compile({ checkpointer, store });\n",
    "const threadId1 = uuidv4();\n",
    "\n",
    "// Helper function to display memory content\n",
    "async function displayMemoryContent(\n",
    "    store,\n",
    "    namespace,\n",
    ") {\n",
    "    console.log(\"\\n======= CURRENT MEMORY CONTENT =======\");\n",
    "    if (namespace) {\n",
    "        const memory = await store.get(namespace, \"user_preferences\");\n",
    "        if (memory) {\n",
    "            console.log(`\\n--- ${namespace[1]} ---`);\n",
    "            console.log({ preferences: memory.value });\n",
    "        } else {\n",
    "            console.log(`\\n--- ${namespace[1]} ---`);\n",
    "            console.log(\"No memory found\");\n",
    "        }\n",
    "    } else {\n",
    "        const namespaces = [\n",
    "            [\"email_assistant\", \"triage_preferences\"],\n",
    "            [\"email_assistant\", \"response_preferences\"],\n",
    "            [\"email_assistant\", \"cal_preferences\"],\n",
    "            [\"email_assistant\", \"background\"],\n",
    "        ];\n",
    "        for (const ns of namespaces) {\n",
    "\n",
    "            const memory = await store.get(ns, \"user_preferences\");\n",
    "            if (memory) {\n",
    "                console.log(`\\n--- ${ns[1]} ---`);\n",
    "                console.log({ preferences: memory.value });\n",
    "            } else {\n",
    "                console.log(`\\n--- ${ns[1]} ---`);\n",
    "                console.log(\"No memory found\");\n",
    "            }\n",
    "        }\n",
    "        console.log(\"=======================================\\n\");\n",
    "    }\n",
    "}\n",
    "// Initialize all user preference memories with their defaults\n",
    "await getMemory(store, [\"email_assistant\", \"triage_preferences\"], defaultTriageInstructions);\n",
    "await getMemory(store, [\"email_assistant\", \"cal_preferences\"], defaultCalPreferences);\n",
    "await getMemory(store, [\"email_assistant\", \"response_preferences\"], defaultResponsePreferences);\n",
    "\n",
    "// Display all user preference memories\n",
    "await displayMemoryContent(store, [\"email_assistant\", \"triage_preferences\"]);\n",
    "await displayMemoryContent(store, [\"email_assistant\", \"cal_preferences\"]);\n",
    "await displayMemoryContent(store, [\"email_assistant\", \"response_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397114bf",
   "metadata": {},
   "source": [
    "### Accept `write_email` and `schedule_meeting`\n",
    "\n",
    "Our first test examines what happens when a user accepts the agent's actions without modification. This baseline case helps us understand how the system behaves when no feedback is provided:\n",
    "\n",
    "1. We'll use the same tax planning email from our previous tests\n",
    "2. The system will classify it as \"RESPOND\" and propose scheduling a meeting\n",
    "3. We'll accept the meeting schedule without changes\n",
    "4. The agent will generate an email confirming the meeting\n",
    "5. We'll accept the email without changes\n",
    "\n",
    "This test demonstrates the default behavior of our memory-enabled system. When a user simply accepts proposed actions, we expect minimal or no memory updates since there's no explicit feedback to learn from. However, the system will still leverage existing memory (if any) when generating its responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "649cee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: { action: 'Email Assistant: respond', args: {} }\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    'Emails that are not worth responding to:\\n' +\n",
      "    '- Marketing newsletters and promotional emails\\n' +\n",
      "    '- Spam or suspicious emails\\n' +\n",
      "    \"- CC'd on FYI threads with no direct questions\\n\" +\n",
      "    '\\n' +\n",
      "    \"There are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\\n\" +\n",
      "    '- Team member out sick or on vacation\\n' +\n",
      "    '- Build system notifications or deployments\\n' +\n",
      "    '- Project status updates without action items\\n' +\n",
      "    '- Important company announcements\\n' +\n",
      "    '- FYI emails that contain relevant information for current projects\\n' +\n",
      "    '- HR Department deadline reminders\\n' +\n",
      "    '- Subscription status / renewal reminders\\n' +\n",
      "    '- GitHub notifications\\n' +\n",
      "    '\\n' +\n",
      "    'Emails that are worth responding to:\\n' +\n",
      "    '- Direct questions from team members requiring expertise\\n' +\n",
      "    '- Meeting requests requiring confirmation\\n' +\n",
      "    \"- Critical bug reports related to team's projects\\n\" +\n",
      "    '- Requests from management requiring acknowledgment\\n' +\n",
      "    '- Client inquiries about project status or features\\n' +\n",
      "    '- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\\n' +\n",
      "    '- Personal reminders related to family (wife / daughter)\\n' +\n",
      "    '- Personal reminder related to self-care (doctor appointments, etc)\\n'\n",
      "}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- response_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    'Use professional and concise language. If the e-mail mentions a deadline, make sure to explicitly acknowledge and reference the deadline in your response.\\n' +\n",
      "    '\\n' +\n",
      "    'When responding to technical questions that require investigation:\\n' +\n",
      "    '- Clearly state whether you will investigate or who you will ask\\n' +\n",
      "    \"- Provide an estimated timeline for when you'll have more information or complete the task\\n\" +\n",
      "    '\\n' +\n",
      "    'When responding to event or conference invitations:\\n' +\n",
      "    '- Always acknowledge any mentioned deadlines (particularly registration deadlines)\\n' +\n",
      "    '- If workshops or specific topics are mentioned, ask for more specific details about them\\n' +\n",
      "    '- If discounts (group or early bird) are mentioned, explicitly request information about them\\n' +\n",
      "    \"- Don't commit \\n\" +\n",
      "    '\\n' +\n",
      "    'When responding to collaboration or project-related requests:\\n' +\n",
      "    '- Acknowledge any existing work or materials mentioned (drafts, slides, documents, etc.)\\n' +\n",
      "    '- Explicitly mention reviewing these materials before or during the meeting\\n' +\n",
      "    '- When scheduling meetings, clearly state the specific day, date, and time proposed\\n' +\n",
      "    '\\n' +\n",
      "    'When responding to meeting scheduling requests:\\n' +\n",
      "    \"- If times are proposed, verify calendar availability for all time slots mentioned in the original email and then commit to one of the proposed times based on your availability by scheduling the meeting. Or, say you can't make it at the time proposed.\\n\" +\n",
      "    '- If no times are proposed, then check your calendar for availability and propose multiple time options when available instead of selecting just one.\\n' +\n",
      "    \"- Mention the meeting duration in your response to confirm you've noted it correctly.\\n\" +\n",
      "    \"- Reference the meeting's purpose in your response.\\n\"\n",
      "}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- cal_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    '30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'\n",
      "}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- background ---\n",
      "No memory found\n",
      "=======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "// Respond - Meeting Request Email\n",
    "const emailInputRespond = {\n",
    "    to: \"Lance Martin <lance@company.com>\",\n",
    "    author: \"Project Manager <pm@client.com>\",\n",
    "    subject: \"Tax season let's schedule call\",\n",
    "    email_thread: `Lance,\n",
    "  \n",
    "  It's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\n",
    "  \n",
    "  Are you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\n",
    "  \n",
    "  Regards,\n",
    "  Project Manager`\n",
    "};\n",
    "\n",
    "// Compile the graph\n",
    "\n",
    "\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "let interruptObject: any = null;\n",
    "const stream = await graph.stream(\n",
    "    { email_input: emailInputRespond },\n",
    "    { configurable: { thread_id: threadId1 } }\n",
    ")\n",
    "for await (const chunk of stream) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Display all user preference memories\n",
    "await displayMemoryContent(store);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e199e",
   "metadata": {},
   "source": [
    "Accept the `schedule_meeting` tool call\n",
    "\n",
    "As we examine the initial `schedule_meeting` proposal, note how the system uses existing memory to inform its decisions:\n",
    "\n",
    "1. The default calendar preferences show a preference for 30-minute meetings, though the email requests 45 minutes\n",
    "2. The agent still proposes a 45-minute meeting, respecting the sender's specific request\n",
    "3. We accept this proposal without modification to see if simple acceptance triggers any memory updates\n",
    "\n",
    "After running this step, we'll check the memory contents to confirm whether acceptance alone leads to memory updates. Simple acceptance represents the baseline user experience - the system works as intended without requiring adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9589423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user accepting the Email Assistant: respond tool call...\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    'Emails that are not worth responding to:\\n' +\n",
      "    '- Marketing newsletters and promotional emails\\n' +\n",
      "    '- Spam or suspicious emails\\n' +\n",
      "    \"- CC'd on FYI threads with no direct questions\\n\" +\n",
      "    '\\n' +\n",
      "    \"There are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\\n\" +\n",
      "    '- Team member out sick or on vacation\\n' +\n",
      "    '- Build system notifications or deployments\\n' +\n",
      "    '- Project status updates without action items\\n' +\n",
      "    '- Important company announcements\\n' +\n",
      "    '- FYI emails that contain relevant information for current projects\\n' +\n",
      "    '- HR Department deadline reminders\\n' +\n",
      "    '- Subscription status / renewal reminders\\n' +\n",
      "    '- GitHub notifications\\n' +\n",
      "    '\\n' +\n",
      "    'Emails that are worth responding to:\\n' +\n",
      "    '- Direct questions from team members requiring expertise\\n' +\n",
      "    '- Meeting requests requiring confirmation\\n' +\n",
      "    \"- Critical bug reports related to team's projects\\n\" +\n",
      "    '- Requests from management requiring acknowledgment\\n' +\n",
      "    '- Client inquiries about project status or features\\n' +\n",
      "    '- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\\n' +\n",
      "    '- Personal reminders related to family (wife / daughter)\\n' +\n",
      "    '- Personal reminder related to self-care (doctor appointments, etc)\\n'\n",
      "}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- response_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    'Use professional and concise language. If the e-mail mentions a deadline, make sure to explicitly acknowledge and reference the deadline in your response.\\n' +\n",
      "    '\\n' +\n",
      "    'When responding to technical questions that require investigation:\\n' +\n",
      "    '- Clearly state whether you will investigate or who you will ask\\n' +\n",
      "    \"- Provide an estimated timeline for when you'll have more information or complete the task\\n\" +\n",
      "    '\\n' +\n",
      "    'When responding to event or conference invitations:\\n' +\n",
      "    '- Always acknowledge any mentioned deadlines (particularly registration deadlines)\\n' +\n",
      "    '- If workshops or specific topics are mentioned, ask for more specific details about them\\n' +\n",
      "    '- If discounts (group or early bird) are mentioned, explicitly request information about them\\n' +\n",
      "    \"- Don't commit \\n\" +\n",
      "    '\\n' +\n",
      "    'When responding to collaboration or project-related requests:\\n' +\n",
      "    '- Acknowledge any existing work or materials mentioned (drafts, slides, documents, etc.)\\n' +\n",
      "    '- Explicitly mention reviewing these materials before or during the meeting\\n' +\n",
      "    '- When scheduling meetings, clearly state the specific day, date, and time proposed\\n' +\n",
      "    '\\n' +\n",
      "    'When responding to meeting scheduling requests:\\n' +\n",
      "    \"- If times are proposed, verify calendar availability for all time slots mentioned in the original email and then commit to one of the proposed times based on your availability by scheduling the meeting. Or, say you can't make it at the time proposed.\\n\" +\n",
      "    '- If no times are proposed, then check your calendar for availability and propose multiple time options when available instead of selecting just one.\\n' +\n",
      "    \"- Mention the meeting duration in your response to confirm you've noted it correctly.\\n\" +\n",
      "    \"- Reference the meeting's purpose in your response.\\n\"\n",
      "}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- cal_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    '30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'\n",
      "}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- background ---\n",
      "No memory found\n",
      "=======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (interruptObject) {\n",
    "  console.log(`\\nSimulating user accepting the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "\n",
    "  // Simulate user accepting the tool call\n",
    "  const stream = await graph.stream(\n",
    "      new Command({ resume: [{ type: \"accept\" }] }),\n",
    "      { configurable: { thread_id: threadId1 } }\n",
    "  );\n",
    "\n",
    "  let nextInterruptObject = null;\n",
    "  for await (const chunk of stream) {\n",
    "      if (\"__interrupt__\" in chunk) {\n",
    "          nextInterruptObject = chunk[\"__interrupt__\"][0];\n",
    "          console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "          console.log(\"Action Request:\", nextInterruptObject.value[0].action_request);\n",
    "      }\n",
    "  }\n",
    "\n",
    "  // After accepting, check memory contents\n",
    "  // Adjust the namespace as needed for your memory structure\n",
    "  displayMemoryContent(store);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b80f99",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call\n",
    "\n",
    "Now we'll accept the email draft that confirms the meeting scheduling:\n",
    "\n",
    "1. The email draft is generated with knowledge of our calendar preferences\n",
    "2. It includes details about the meeting time, duration, and purpose\n",
    "3. We'll accept it without changes to complete the baseline test case\n",
    "\n",
    "After accepting, we'll check all memory stores to see if any updates occurred. As expected, simply accepting the agent's proposals doesn't provide strong learning signals - there's no clear feedback about what the user likes or dislikes about the agent's approach.\n",
    "\n",
    "The trace link shows the complete workflow execution, where we can see that the memory is used in the LLM call for response generation, but no memory updates occur, which is the expected behavior for simple acceptances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "12035cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user accepting the Email Assistant: respond tool call...\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    'Emails that are not worth responding to:\\n' +\n",
      "    '- Marketing newsletters and promotional emails\\n' +\n",
      "    '- Spam or suspicious emails\\n' +\n",
      "    \"- CC'd on FYI threads with no direct questions\\n\" +\n",
      "    '\\n' +\n",
      "    \"There are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\\n\" +\n",
      "    '- Team member out sick or on vacation\\n' +\n",
      "    '- Build system notifications or deployments\\n' +\n",
      "    '- Project status updates without action items\\n' +\n",
      "    '- Important company announcements\\n' +\n",
      "    '- FYI emails that contain relevant information for current projects\\n' +\n",
      "    '- HR Department deadline reminders\\n' +\n",
      "    '- Subscription status / renewal reminders\\n' +\n",
      "    '- GitHub notifications\\n' +\n",
      "    '\\n' +\n",
      "    'Emails that are worth responding to:\\n' +\n",
      "    '- Direct questions from team members requiring expertise\\n' +\n",
      "    '- Meeting requests requiring confirmation\\n' +\n",
      "    \"- Critical bug reports related to team's projects\\n\" +\n",
      "    '- Requests from management requiring acknowledgment\\n' +\n",
      "    '- Client inquiries about project status or features\\n' +\n",
      "    '- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\\n' +\n",
      "    '- Personal reminders related to family (wife / daughter)\\n' +\n",
      "    '- Personal reminder related to self-care (doctor appointments, etc)\\n'\n",
      "}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- response_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    'Use professional and concise language. If the e-mail mentions a deadline, make sure to explicitly acknowledge and reference the deadline in your response.\\n' +\n",
      "    '\\n' +\n",
      "    'When responding to technical questions that require investigation:\\n' +\n",
      "    '- Clearly state whether you will investigate or who you will ask\\n' +\n",
      "    \"- Provide an estimated timeline for when you'll have more information or complete the task\\n\" +\n",
      "    '\\n' +\n",
      "    'When responding to event or conference invitations:\\n' +\n",
      "    '- Always acknowledge any mentioned deadlines (particularly registration deadlines)\\n' +\n",
      "    '- If workshops or specific topics are mentioned, ask for more specific details about them\\n' +\n",
      "    '- If discounts (group or early bird) are mentioned, explicitly request information about them\\n' +\n",
      "    \"- Don't commit \\n\" +\n",
      "    '\\n' +\n",
      "    'When responding to collaboration or project-related requests:\\n' +\n",
      "    '- Acknowledge any existing work or materials mentioned (drafts, slides, documents, etc.)\\n' +\n",
      "    '- Explicitly mention reviewing these materials before or during the meeting\\n' +\n",
      "    '- When scheduling meetings, clearly state the specific day, date, and time proposed\\n' +\n",
      "    '\\n' +\n",
      "    'When responding to meeting scheduling requests:\\n' +\n",
      "    \"- If times are proposed, verify calendar availability for all time slots mentioned in the original email and then commit to one of the proposed times based on your availability by scheduling the meeting. Or, say you can't make it at the time proposed.\\n\" +\n",
      "    '- If no times are proposed, then check your calendar for availability and propose multiple time options when available instead of selecting just one.\\n' +\n",
      "    \"- Mention the meeting duration in your response to confirm you've noted it correctly.\\n\" +\n",
      "    \"- Reference the meeting's purpose in your response.\\n\"\n",
      "}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- cal_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    '30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'\n",
      "}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- background ---\n",
      "No memory found\n",
      "=======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (interruptObject) {\n",
    "  console.log(`\\nSimulating user accepting the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "\n",
    "  // Simulate user accepting the tool call\n",
    "  const stream = await graph.stream(\n",
    "      new Command({ resume: [{ type: \"accept\" }] }),\n",
    "      { configurable: { thread_id: threadId1 } }\n",
    "  );\n",
    "\n",
    "  let nextInterruptObject = null;\n",
    "  for await (const chunk of stream) {\n",
    "      // Inspect response_agent's most recent message\n",
    "      if (\"response_agent\" in chunk) {\n",
    "          const messages = chunk.response_agent.messages;\n",
    "          const lastMessage = messages[messages.length - 1];\n",
    "          if (typeof lastMessage.prettyPrint === \"function\") {\n",
    "              lastMessage.prettyPrint();\n",
    "          } else {\n",
    "              console.log(lastMessage);\n",
    "          }\n",
    "      }\n",
    "      // Inspect interrupt object if present\n",
    "      if (\"__interrupt__\" in chunk) {\n",
    "          nextInterruptObject = chunk[\"__interrupt__\"][0];\n",
    "          console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "          console.log(\"Action Request:\", nextInterruptObject.value[0].action_request);\n",
    "      }\n",
    "  }\n",
    "\n",
    "  // After accepting, check memory contents\n",
    "  // Adjust the namespace as needed for your memory structure\n",
    "  displayMemoryContent(store);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc178d",
   "metadata": {},
   "source": [
    "We can look at the full messages, and the trace: \n",
    "\n",
    "https://smith.langchain.com/public/86ff6474-29fe-452e-8829-b05a91b458eb/r\n",
    "\n",
    "You'll notice that memory is used in the LLM call to respond. \n",
    "\n",
    "But the memory store *not* updated, because we haven't added any feedback via HITL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "10ce8197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage {\n",
      "  \"id\": \"fa28bec8-9055-4903-a7ea-381e7b32d613\",\n",
      "  \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"7c2de70a-1463-4835-b35a-2d8571b8c4fa\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"7751e20e-c370-412e-918c-3efa44068c34\",\n",
      "  \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"04f2e1c4-5eed-47c7-a3b9-f49a746a9207\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"824f1a87-3082-4460-825e-33ada76e6b5c\",\n",
      "  \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"ad88a667-0fac-4223-810f-262cdcea0223\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const threadConfig1 = { configurable: { thread_id: threadId1 } };\n",
    "\n",
    "const state1 = await graph.getState(threadConfig1);\n",
    "for (const m of state1.values.messages) {\n",
    "    if (typeof m.prettyPrint === \"function\") {\n",
    "        m.prettyPrint();\n",
    "    } else {\n",
    "        console.log(m);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58201a21",
   "metadata": {},
   "source": [
    "### Edit `write_email` and `schedule_meeting`\n",
    "\n",
    "This test explores how the system learns from direct edits to its proposed actions. When users modify the agent's suggestions, it creates clear, specific learning signals about their preferences:\n",
    "\n",
    "1. We'll use the same tax planning email as before\n",
    "2. When the agent proposes a 45-minute meeting, we'll edit it to:\n",
    "   - Change the duration to 30 minutes (matching our stored preference)\n",
    "   - Make the subject line more concise\n",
    "3. When the agent drafts an email, we'll edit it to be:\n",
    "   - Shorter and less formal\n",
    "   - Structured differently\n",
    "\n",
    "Edits provide the most explicit feedback about user preferences, letting the system learn exactly what changes are desired. We expect to see specific, targeted updates to our memory stores that reflect these edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac260423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: { action: 'Email Assistant: respond', args: {} }\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- cal_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    '30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'\n",
      "}\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 378534,\n",
      "  [Symbol(trigger_async_id_symbol)]: 378533,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Same email as before\n",
    "const emailInputRespond = {\n",
    "  to: \"Lance Martin <lance@company.com>\",\n",
    "  author: \"Project Manager <pm@client.com>\",\n",
    "  subject: \"Tax season let's schedule call\",\n",
    "  email_thread: `Lance,\n",
    "\n",
    "It's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\n",
    "\n",
    "Are you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\n",
    "\n",
    "Regards,\n",
    "Project Manager`\n",
    "};\n",
    "\n",
    "// Compile the graph with new thread\n",
    "const checkpointer = new MemorySaver();\n",
    "const store = new InMemoryStore();\n",
    "const graph = overallWorkflow.compile({ checkpointer: checkpointer, store: store });\n",
    "const threadId2 = uuidv4();\n",
    "const threadConfig = { configurable: { thread_id: threadId } };\n",
    "\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "const stream = await graph2.stream(\n",
    "  { email_input: emailInputRespond },\n",
    "  { configurable: { thread_id: threadId2 } }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "  if (\"__interrupt__\" in chunk) {\n",
    "      const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "      console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "      console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "  }\n",
    "}\n",
    "// Ensure cal_preferences is initialized\n",
    "await getMemory(store2, [\"email_assistant\", \"cal_preferences\"], defaultCalPreferences);\n",
    "\n",
    "// Now display memory content\n",
    "displayMemoryContent(store2, [\"email_assistant\", \"cal_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73ba71",
   "metadata": {},
   "source": [
    "Edit the `schedule_meeting` tool call\n",
    "\n",
    "When we edit the meeting proposal, we're providing direct, explicit feedback about our preferences. This creates a significant learning opportunity for the system:\n",
    "\n",
    "1. The agent initially proposes a 45-minute meeting (the duration requested in the email)\n",
    "2. We edit it to 30 minutes and simplify the subject from \"Tax Planning Strategies Discussion\" to \"Tax Planning Discussion\"\n",
    "3. This creates clear, specific feedback about our time preferences and naming conventions\n",
    "\n",
    "After the edit, we'll check the calendar preferences memory store to see how it's updated. The memory update should capture both:\n",
    "- Our preference for shorter 30-minute meetings\n",
    "- Our preference for more concise meeting subjects\n",
    "\n",
    "The trace reveals the precise memory update logic, showing how the system analyzes the difference between its proposal and our edits to extract meaningful patterns and preferences. We can see the detailed justification for each memory update, ensuring transparency in the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "af760977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user editing the schedule_meeting tool call...\n",
      "HumanMessage {\n",
      "  \"id\": \"694cf44f-ab10-4ddd-a284-a333b32208bf\",\n",
      "  \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"98700c23-846e-42a7-a9aa-0cde90de6047\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "\n",
      "Checking memory after editing schedule_meeting:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- cal_preferences ---\n",
      "{\n",
      "  preferences: '\\n' +\n",
      "    '30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'\n",
      "}\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 381114,\n",
      "  [Symbol(trigger_async_id_symbol)]: 381044,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(\"\\nSimulating user editing the schedule_meeting tool call...\");\n",
    "const editedScheduleArgs = {\n",
    "    attendees: [\"pm@client.com\", \"lance@company.com\"],\n",
    "    subject: \"Tax Planning Discussion\",\n",
    "    duration_minutes: 30, // Changed from 45 to 30\n",
    "    preferred_day: \"2025-04-22\",\n",
    "    start_time: 14\n",
    "};\n",
    "\n",
    "const stream = await graph2.stream(\n",
    "    new Command({ resume: [{ type: \"edit\", args: { args: editedScheduleArgs } }] }),\n",
    "    { configurable: { thread_id: threadId2 } }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    // Inspect response_agent's most recent message\n",
    "    if (\"response_agent\" in chunk) {\n",
    "        const messages = chunk.response_agent.messages;\n",
    "        const lastMessage = messages[messages.length - 1];\n",
    "        if (typeof lastMessage.prettyPrint === \"function\") {\n",
    "            lastMessage.prettyPrint();\n",
    "        } else {\n",
    "            console.log(lastMessage);\n",
    "        }\n",
    "    }\n",
    "    // Inspect interrupt object if present\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Check memory after editing schedule_meeting\n",
    "console.log(\"\\nChecking memory after editing schedule_meeting:\");\n",
    "displayMemoryContent(store2, [\"email_assistant\", \"cal_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc585a",
   "metadata": {},
   "source": [
    "Looking at the memory after editing the calendar invitation, we can see that it's been updated:\n",
    "\n",
    "1. The system has identified that we prefer 30-minute meetings over longer durations\n",
    "2. It's also captured our preference for concise meeting subjects\n",
    "\n",
    "What's particularly impressive about this memory update is:\n",
    "- It doesn't just record our specific edit, but generalizes to a broader preference pattern\n",
    "- It preserves all existing memory content while adding the new information\n",
    "- It extracts multiple preference signals from a single edit interaction\n",
    "\n",
    "Now, let's edit the email draft to see how the system captures different types of communication preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "81a1fa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "Simulating user editing the write_email tool call...\n",
      "\n",
      "--- response_preferences ---\n",
      "No memory found\n",
      "\n",
      "Checking memory after editing write_email:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- response_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 381930,\n",
      "  [Symbol(trigger_async_id_symbol)]: 381923,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Display current response_preferences memory before editing\n",
    "displayMemoryContent(store2, [\"email_assistant\", \"response_preferences\"]);\n",
    "\n",
    "// Now simulate user editing the write_email tool call\n",
    "console.log(\"\\nSimulating user editing the write_email tool call...\");\n",
    "const editedEmailArgs = {\n",
    "    to: \"pm@client.com\",\n",
    "    subject: \"Re: Tax season let's schedule call\",\n",
    "    content: `Thanks! I scheduled a 30-minute call next Thursday at 3:00 PM. Would that work for you?\n",
    "\n",
    "Best regards,\n",
    "Lance Martin`\n",
    "};\n",
    "\n",
    "const stream = await graph2.stream(\n",
    "    new Command({ resume: [{ type: \"edit\", args: { args: editedEmailArgs } }] }),\n",
    "    { configurable: { thread_id: threadId2 } }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    // Inspect response_agent's most recent message\n",
    "    if (\"response_agent\" in chunk) {\n",
    "        const messages = chunk.response_agent.messages;\n",
    "        const lastMessage = messages[messages.length - 1];\n",
    "        if (typeof lastMessage.prettyPrint === \"function\") {\n",
    "            lastMessage.prettyPrint();\n",
    "        } else {\n",
    "            console.log(lastMessage);\n",
    "        }\n",
    "    }\n",
    "    // Inspect interrupt object if present\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Check memory after editing write_email\n",
    "console.log(\"\\nChecking memory after editing write_email:\");\n",
    "displayMemoryContent(store2, [\"email_assistant\", \"response_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbd5f9",
   "metadata": {},
   "source": [
    "Our email edit reveals even more sophisticated learning capabilities:\n",
    "\n",
    "1. We've dramatically shortened and simplified the email content\n",
    "2. We've changed the tone to be more casual\n",
    "3. We've added a question asking for confirmation rather than assuming the time works\n",
    "4. We've slightly altered the meeting details (day and time)\n",
    "\n",
    "Looking at the updated memory, we can see that the system has extracted a key insight about our communication style:\n",
    "\n",
    "```\n",
    "When scheduling a meeting, ask the recipient to confirm if the proposed time works for them, rather than assuming and stating the meeting is already scheduled.\n",
    "```\n",
    "\n",
    "This demonstrates the system's ability to:\n",
    "- Analyze our edit not just at a superficial level, but to understand intent\n",
    "- Extract generalizable principles from specific examples\n",
    "- Preserve all existing guidance while adding new insights\n",
    "- Maintain the organization and structure of the memory\n",
    "\n",
    "These targeted, high-quality memory updates will improve all future interactions without requiring repeated corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8ad818d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage {\n",
      "  \"id\": \"1ee1a15c-3b8c-4c7d-bfe7-cc37362f8f2d\",\n",
      "  \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"58f1271e-ef65-48a2-850e-2558c43400bf\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"694cf44f-ab10-4ddd-a284-a333b32208bf\",\n",
      "  \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"98700c23-846e-42a7-a9aa-0cde90de6047\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const state = await graph2.getState(threadConfig2);\n",
    "for (const m of state.values.messages) {\n",
    "    if (typeof m.prettyPrint === \"function\") {\n",
    "        m.prettyPrint();\n",
    "    } else {\n",
    "        console.log(m);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14918e",
   "metadata": {},
   "source": [
    "## Ignore `write_email`, `schedule_meeting`, and `question`\n",
    "\n",
    "This test explores how the system learns from rejection. When users ignore (reject) the agent's suggestions, it creates a strong signal about content they don't want to handle:\n",
    "\n",
    "1. We'll first test ignoring a `schedule_meeting` request entirely\n",
    "2. Then we'll test accepting a meeting but ignoring the follow-up email\n",
    "3. Finally, we'll test ignoring a `question` for a different email context\n",
    "\n",
    "These rejection signals help the system learn what types of emails and actions a user prefers not to deal with, leading to more appropriate triage decisions in the future. We expect significant updates to the triage preferences memory after each ignore action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0d015c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: { action: 'Email Assistant: respond', args: {} }\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 392237,\n",
      "  [Symbol(trigger_async_id_symbol)]: 392172,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Respond - Meeting Request Email\n",
    "const emailInputRespond3 = {\n",
    "  to: \"Lance Martin <lance@company.com>\",\n",
    "  author: \"Project Manager <pm@client.com>\",\n",
    "  subject: \"Tax season let's schedule call\",\n",
    "  email_thread: `Lance,\n",
    "\n",
    "It's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\n",
    "\n",
    "Are you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\n",
    "\n",
    "Regards,\n",
    "Project Manager`\n",
    "};\n",
    "\n",
    "// Compile the graph\n",
    "const checkpointer3 = new MemorySaver();\n",
    "const store3 = new InMemoryStore();\n",
    "const graph3 = overallWorkflow.compile({ checkpointer: checkpointer3, store: store3 });\n",
    "const threadId3 = uuidv4();\n",
    "const threadConfig3 = { configurable: { thread_id: threadId3 } };\n",
    "\n",
    "// Run the graph until the first interrupt\n",
    "// Email will be classified as \"respond\"\n",
    "// Agent will create a schedule_meeting and write_email tool call\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "const stream = await graph3.stream(\n",
    "  { email_input: emailInputRespond3 },\n",
    "  { configurable: { thread_id: threadId3 } }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "  if (\"__interrupt__\" in chunk) {\n",
    "      const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "      console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "      console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "  }\n",
    "}\n",
    "\n",
    "// Check memory after first interrupt\n",
    "displayMemoryContent(store3, [\"email_assistant\", \"triage_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782e711",
   "metadata": {},
   "source": [
    "Ignore the `schedule_meeting` tool call\n",
    "\n",
    "When we ignore a meeting scheduling request, we're signaling that we don't want to handle this type of email through the assistant. This creates a powerful learning opportunity about our triage preferences:\n",
    "\n",
    "1. The assistant initially classified the tax planning email as \"RESPOND\"\n",
    "2. But by ignoring the scheduling request, we indicate we'd prefer not to handle this type of email\n",
    "3. The system needs to update its triage classification preferences to reflect this rejection\n",
    "\n",
    "After ignoring the request, we'll check the triage preferences memory to see how the rejection affected the system's understanding. The memory update should show a new pattern added to the \"not worth responding to\" section, specifically about tax planning calls or similar recurring discussions.\n",
    "\n",
    "The trace shows how the system processes this rejection, identifies the pattern, and updates the memory with specific justification for why this type of email should be classified differently in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "16c4d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user ignoring the Email Assistant: respond tool call...\n",
      "\n",
      "Checking memory after ignoring first tool call:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 393142,\n",
      "  [Symbol(trigger_async_id_symbol)]: 393074,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(`\\nSimulating user ignoring the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "const stream = await graph3.stream(\n",
    "    new Command({ resume: [{ type: \"ignore\" }] }),\n",
    "    { configurable: { thread_id: threadId3 } }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    // Inspect interrupt object if present\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Check memory after ignoring first tool call\n",
    "console.log(\"\\nChecking memory after ignoring first tool call:\");\n",
    "displayMemoryContent(store3, [\"email_assistant\", \"triage_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67462024",
   "metadata": {},
   "source": [
    "Looking at the memory update after ignoring the `schedule_meeting` tool call, we can see a remarkable triage preference update:\n",
    "\n",
    "1. The system has added \"Client requests to schedule tax planning calls\" to the \"emails not worth responding to\" section\n",
    "2. It correctly identified the general pattern (scheduling routine calls) rather than overfitting to just this specific instance\n",
    "3. It included the parenthetical note \"(unless explicitly instructed otherwise)\" to maintain flexibility\n",
    "\n",
    "This update demonstrates the system's ability to:\n",
    "- Infer general patterns from specific instances of rejection\n",
    "- Update the triage filters that determine initial email classification\n",
    "- Preserve the organization and priority of existing preferences\n",
    "- Include appropriate qualifiers to avoid overly rigid rules\n",
    "\n",
    "Next, let's see what happens when we accept the meeting but reject the email draft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b869485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: { action: 'Email Assistant: respond', args: {} }\n",
      "\n",
      "Simulating user accepting the Email Assistant: respond tool call...\n",
      "HumanMessage {\n",
      "  \"id\": \"08d2d8f6-c443-46bc-88e3-3ac71424a406\",\n",
      "  \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"9abe710c-b001-4862-b578-fb165ab60fc1\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "\n",
      "Simulating user ignoring the Email Assistant: respond tool call...\n",
      "\n",
      "Checking memory after ignoring second tool call:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "No memory found\n"
     ]
    }
   ],
   "source": [
    "import { MemorySaver, InMemoryStore } from \"@langchain/langgraph\";\n",
    "import { Command } from \"@langchain/langgraph\";\n",
    "\n",
    "// Respond - Meeting Request Email\n",
    "const emailInputRespond4 = {\n",
    "    to: \"Lance Martin <lance@company.com>\",\n",
    "    author: \"Project Manager <pm@client.com>\",\n",
    "    subject: \"Tax season let's schedule call\",\n",
    "    email_thread: `Lance,\n",
    "\n",
    "It's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\n",
    "\n",
    "Are you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\n",
    "\n",
    "Regards,\n",
    "Project Manager`\n",
    "};\n",
    "\n",
    "async function displayMemoryContent(\n",
    "    store: InMemoryStore,\n",
    "    namespace?: string[],\n",
    ") {\n",
    "    console.log(\"\\n======= CURRENT MEMORY CONTENT =======\");\n",
    "\n",
    "    if (namespace) {\n",
    "        try {\n",
    "            const memory = await store.get(namespace, \"user_preferences\");\n",
    "            if (memory) {\n",
    "                console.log(`\\n--- ${namespace[1]} ---`);\n",
    "                console.log({ preferences: memory.value });\n",
    "            } else {\n",
    "                console.log(`\\n--- ${namespace[1]} ---`);\n",
    "                console.log(\"No memory found\");\n",
    "            }\n",
    "        } catch (error) {\n",
    "            console.log(`\\n--- ${namespace[1]} ---`);\n",
    "            console.log(\"Error retrieving memory\");\n",
    "        }\n",
    "    } else {\n",
    "        const namespaces = [\n",
    "            [\"email_assistant\", \"triage_preferences\"],\n",
    "            [\"email_assistant\", \"response_preferences\"],\n",
    "            [\"email_assistant\", \"cal_preferences\"],\n",
    "            [\"email_assistant\", \"background\"],\n",
    "        ];\n",
    "\n",
    "        for (const ns of namespaces) {\n",
    "            try {\n",
    "                const memory = await store.get(ns, \"user_preferences\");\n",
    "                if (memory) {\n",
    "                    console.log(`\\n--- ${ns[1]} ---`);\n",
    "                    console.log({ preferences: memory.value });\n",
    "                } else {\n",
    "                    console.log(`\\n--- ${ns[1]} ---`);\n",
    "                    console.log(\"No memory found\");\n",
    "                }\n",
    "            } catch (error) {\n",
    "                console.log(`\\n--- ${ns[1]} ---`);\n",
    "                console.log(\"Error retrieving memory\");\n",
    "            }\n",
    "            console.log(\"=======================================\\n\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Compile the graph\n",
    "const checkpointer4 = new MemorySaver();\n",
    "const store4 = new InMemoryStore();\n",
    "const graph4 = overallWorkflow.compile({ checkpointer: checkpointer4, store: store4 });\n",
    "const threadId4 = uuid4();\n",
    "const threadConfig4 = { configurable: { thread_id: threadId4 } };\n",
    "\n",
    "// Run the graph until the first interrupt\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "let interruptObject;\n",
    "const stream1 = await graph4.stream({ email_input: emailInputRespond4 }, threadConfig4);\n",
    "for await (const chunk of stream1) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Simulate user accepting the first tool call\n",
    "console.log(`\\nSimulating user accepting the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "const stream2 = await graph4.stream(new Command({ resume: [{ type: \"accept\" }] }), threadConfig4);\n",
    "for await (const chunk of stream2) {\n",
    "    if (\"response_agent\" in chunk) {\n",
    "        const messages = chunk.response_agent.messages;\n",
    "        const lastMessage = messages[messages.length - 1];\n",
    "        if (typeof lastMessage.prettyPrint === \"function\") {\n",
    "            lastMessage.prettyPrint();\n",
    "        } else {\n",
    "            console.log(lastMessage);\n",
    "        }\n",
    "    }\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Simulate user ignoring the next tool call\n",
    "console.log(`\\nSimulating user ignoring the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "const stream3 = await graph4.stream(new Command({ resume: [{ type: \"ignore\" }] }), threadConfig4);\n",
    "for await (const chunk of stream3) {\n",
    "    if (\"response_agent\" in chunk) {\n",
    "        const messages = chunk.response_agent.messages;\n",
    "        const lastMessage = messages[messages.length - 1];\n",
    "        if (typeof lastMessage.prettyPrint === \"function\") {\n",
    "            lastMessage.prettyPrint();\n",
    "        } else {\n",
    "            console.log(lastMessage);\n",
    "        }\n",
    "    }\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Check memory after ignoring second tool call\n",
    "console.log(\"\\nChecking memory after ignoring second tool call:\");\n",
    "await displayMemoryContent(store4, [\"email_assistant\", \"triage_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694db9f5",
   "metadata": {},
   "source": [
    "When we accept the meeting but ignore the email draft, we're sending a more nuanced signal about our preferences:\n",
    "\n",
    "1. We're willing to schedule the meeting (accepting the first tool call)\n",
    "2. But we don't want to send a confirmation email about it (ignoring the second tool call)\n",
    "\n",
    "Looking at the memory update, we see another evolution of our triage preferences:\n",
    "\n",
    "```\n",
    "\"Client requests to schedule routine calls (such as tax planning or similar recurring discussions)\"\n",
    "```\n",
    "\n",
    "The system has:\n",
    "- Broadened the pattern from just \"tax planning calls\" to \"routine calls\" generally\n",
    "- Added examples in parentheses for clarity\n",
    "- Positioned this in the \"not worth responding to\" section\n",
    "- Maintained all other existing preferences\n",
    "\n",
    "This demonstrates how the memory evolves over multiple interactions, becoming increasingly accurate and generalizable with each additional data point. The system is continuously refining its understanding based on our feedback patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "272bb9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage {\n",
      "  \"id\": \"08d2d8f6-c443-46bc-88e3-3ac71424a406\",\n",
      "  \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"9abe710c-b001-4862-b578-fb165ab60fc1\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const state3 = await graph4.getState(threadConfig4);\n",
    "for (const m of state3.values.messages) {\n",
    "    if (typeof m.prettyPrint === \"function\") {\n",
    "        m.prettyPrint();\n",
    "    } else {\n",
    "        console.log(m);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597930b3",
   "metadata": {},
   "source": [
    "Now let's try an email that calls the `Question` tool\n",
    "\n",
    "For our third rejection test, we'll use a different type of email - a casual social invitation about brunch. This gives us insight into how the system learns about personal vs. professional communication preferences:\n",
    "\n",
    "1. The system classifies this personal invitation as \"RESPOND\"\n",
    "2. Rather than answering directly, it uses the Question tool to ask for clarification\n",
    "3. We'll ignore this question, indicating we don't want to handle these types of emails through the assistant\n",
    "\n",
    "This test shows how ignoring questions (not just actions) can also update our triage preferences. By rejecting the clarification attempt, we signal that this entire category of email doesn't warrant response through the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "efb91337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: { action: 'Email Assistant: respond', args: {} }\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 412132,\n",
      "  [Symbol(trigger_async_id_symbol)]: 412067,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Respond - Meeting Request Email\n",
    "const emailInputRespond5 = {\n",
    "  to: \"Lance Martin <lance@company.com>\",\n",
    "  author: \"Partner <partner@home.com>\",\n",
    "  subject: \"Meet Jim and Lisa for brunch in 3 weeks?\",\n",
    "  email_thread: `Hey, should we invite Jim and Lisa to brunch in 3 weeks? We could go to the new place on 17th that everyone is talking about.`\n",
    "};\n",
    "\n",
    "// Compile the graph\n",
    "const checkpointer5 = new MemorySaver();\n",
    "const store5 = new InMemoryStore();\n",
    "const graph5 = overallWorkflow.compile({ checkpointer: checkpointer5, store: store5 });\n",
    "const threadId5 = uuidv4();\n",
    "const threadConfig5 = { configurable: { thread_id: threadId5 } };\n",
    "\n",
    "// Run the graph until the first interrupt\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "\n",
    "// Await the stream before iterating\n",
    "const stream = await graph5.stream({ email_input: emailInputRespond5 }, threadConfig5);\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "  if (\"__interrupt__\" in chunk) {\n",
    "      const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "      console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "      console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "  }\n",
    "}\n",
    "\n",
    "// Check memory after first interrupt for Question tool\n",
    "displayMemoryContent(store5, [\"email_assistant\", \"triage_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6581a",
   "metadata": {},
   "source": [
    "Ignore the `question` tool call\n",
    "\n",
    "When we ignore a question from the assistant about a personal social invitation, we're providing yet another type of feedback:\n",
    "\n",
    "1. The system initially tries to get clarification before responding\n",
    "2. By ignoring the question, we indicate we don't even want to engage with this type of email\n",
    "3. This suggests the entire category of social invitations should be handled differently\n",
    "\n",
    "After ignoring, we'll check the triage preferences again to see how they've evolved. We expect to see a new entry about social invitations added to the \"not worth responding to\" section.\n",
    "\n",
    "The memory update justification analyzes our rejection of the question about an informal social invitation and extracts a general pattern about our preference not to handle social invitations through the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f227a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user ignoring the Email Assistant: respond tool call...\n",
      "\n",
      "Checking memory after ignoring Question tool:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 413037,\n",
      "  [Symbol(trigger_async_id_symbol)]: 412969,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(`\\nSimulating user ignoring the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "\n",
    "// Await the stream before iterating, and use the correct config key\n",
    "const stream = await graph5.stream(\n",
    "    new Command({ resume: [{ type: \"ignore\" }] }),\n",
    "    threadConfig5 // This is { configurable: { thread_id: ... } }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Check memory after ignoring Question tool\n",
    "console.log(\"\\nChecking memory after ignoring Question tool:\");\n",
    "displayMemoryContent(store5, [\"email_assistant\", \"triage_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bea846",
   "metadata": {},
   "source": [
    "Looking at the memory update after ignoring the question about brunch plans, we see another sophisticated triage preference update:\n",
    "\n",
    "```\n",
    "\"Social invitations from partner (e.g., brunch plans, casual meetups)\"\n",
    "```\n",
    "\n",
    "This demonstrates how the system:\n",
    "1. Correctly identifies personal social invitations as a distinct category\n",
    "2. Specifically notes they're from \"partner\" - showing it's learning to distinguish senders\n",
    "3. Provides examples to clarify the pattern\n",
    "4. Adds this to the \"not worth responding to\" section\n",
    "\n",
    "These three ignores have collectively taught the system quite a bit about what types of emails we prefer not to handle through the assistant:\n",
    "- Tax planning calls and routine client scheduling\n",
    "- Social invitations from partners\n",
    "- Each with appropriate specificity and generalizability\n",
    "\n",
    "In a real-world scenario, these learned preferences would ensure that similar future emails would be classified differently, saving the user time by automatically filtering out categories they've previously rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2ca65c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage {\n",
      "  \"id\": \"102b6441-935d-490b-b98e-19e47a668372\",\n",
      "  \"content\": \"Respond to the email: ## Email: Meet Jim and Lisa for brunch in 3 weeks?\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"c4ab368c-8d48-4905-a93b-028439d7b59d\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Meet Jim and Lisa for brunch in 3 weeks?\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const state4 = await graph5.getState(threadConfig5);\n",
    "for (const m of state4.values.messages) {\n",
    "    if (typeof m.prettyPrint === \"function\") {\n",
    "        m.prettyPrint();\n",
    "    } else {\n",
    "        console.log(m);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d92a42b",
   "metadata": {},
   "source": [
    "### Respond (with feedback) `write_email`, `schedule_meeting`, and `question`\n",
    "\n",
    "Our final test set explores the \"response\" feedback pattern - providing guidance without directly editing or accepting. This conversational feedback mechanism offers a middle ground between acceptance and editing:\n",
    "\n",
    "1. First, we'll test feedback for meeting scheduling by requesting:\n",
    "   - Shorter duration (30 minutes instead of 45)\n",
    "   - Afternoon meeting times (after 2pm)\n",
    "   \n",
    "2. Next, we'll test feedback for email drafting by requesting:\n",
    "   - Shorter, less formal language\n",
    "   - A specific closing statement about looking forward to the meeting\n",
    "   \n",
    "3. Finally, we'll test feedback for questions by providing:\n",
    "   - A direct answer with additional context\n",
    "   - Specific preferences (brunch location, time)\n",
    "\n",
    "This natural language feedback approach lets users guide the assistant without having to do the work themselves. We expect to see detailed memory updates that extract the general principles from our specific feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "07676231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: { action: 'Email Assistant: respond', args: {} }\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- cal_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 423306,\n",
      "  [Symbol(trigger_async_id_symbol)]: 423241,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Respond - Meeting Request Email\n",
    "const emailInputRespond6 = {\n",
    "  to: \"Lance Martin <lance@company.com>\",\n",
    "  author: \"Project Manager <pm@client.com>\",\n",
    "  subject: \"Tax season let's schedule call\",\n",
    "  email_thread: `Lance,\n",
    "\n",
    "It's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\n",
    "\n",
    "Are you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\n",
    "\n",
    "Regards,\n",
    "Project Manager`\n",
    "};\n",
    "\n",
    "// Compile the graph\n",
    "const checkpointer6 = new MemorySaver();\n",
    "const store6 = new InMemoryStore();\n",
    "const graph6 = overallWorkflow.compile({ checkpointer: checkpointer6, store: store6 });\n",
    "const threadId6 = uuidv4();\n",
    "const threadConfig6 = { configurable: { thread_id: threadId6 } };\n",
    "\n",
    "// Run the graph until the first interrupt\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "\n",
    "// Await the stream before iterating\n",
    "const stream = await graph6.stream({ email_input: emailInputRespond6 }, threadConfig6);\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "  if (\"__interrupt__\" in chunk) {\n",
    "      const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "      console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "      console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "  }\n",
    "}\n",
    "\n",
    "// Check memory after first interrupt\n",
    "displayMemoryContent(store6, [\"email_assistant\", \"cal_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85fc45d",
   "metadata": {},
   "source": [
    "Provide feedback for the `schedule_meeting` tool call\n",
    "\n",
    "Instead of directly editing the meeting proposal or simply accepting it, we'll provide natural language feedback:\n",
    "\n",
    "1. We request a 30-minute meeting instead of 45 minutes\n",
    "2. We express a preference for afternoon meetings after 2pm\n",
    "3. The system must interpret this feedback and generate a new proposal\n",
    "\n",
    "This conversational approach is often more natural and efficient than direct editing, especially for mobile users or those who prefer to give high-level direction rather than detailed edits.\n",
    "\n",
    "After providing feedback, we'll examine the calendar preferences memory to see how this natural language guidance is captured. We expect to see the system extract both the meeting duration and time-of-day preferences as general principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "30a151f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user providing feedback for the Email Assistant: respond tool call...\n",
      "\n",
      "Checking memory after providing feedback for schedule_meeting:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- cal_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 425645,\n",
      "  [Symbol(trigger_async_id_symbol)]: 425575,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(`\\nSimulating user providing feedback for the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "\n",
    "// Await the stream before iterating, and use the correct config key\n",
    "const stream = await graph6.stream(\n",
    "    new Command({\n",
    "        resume: [\n",
    "            {\n",
    "                type: \"response\",\n",
    "                args: \"Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\"\n",
    "            }\n",
    "        ]\n",
    "    }),\n",
    "    threadConfig6\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Check memory after providing feedback for schedule_meeting\n",
    "console.log(\"\\nChecking memory after providing feedback for schedule_meeting:\");\n",
    "displayMemoryContent(store6, [\"email_assistant\", \"cal_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088757c",
   "metadata": {},
   "source": [
    "Our memory check after providing feedback shows an elegantly simple calendar preference update:\n",
    "\n",
    "```\n",
    "30 minute meetings are preferred, but 15 minute meetings are also acceptable.\n",
    "Afternoon meetings after 2pm are preferred.\n",
    "```\n",
    "\n",
    "The system has:\n",
    "1. Captured both aspects of our feedback (duration and time of day)\n",
    "2. Preserved the existing preference about 15-minute meetings\n",
    "3. Added our preference for afternoon meetings after 2pm as a new line\n",
    "4. Kept the format clean and readable\n",
    "\n",
    "This natural language feedback mechanism creates the same quality of memory updates as direct editing but requires less effort from the user. The system is able to extract structured preferences from unstructured feedback, showing its ability to learn from conversational interactions.\n",
    "\n",
    "Let's accept this revised meeting proposal and move to the email draft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "545063be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user accepting the Email Assistant: respond tool call...\n",
      "\n",
      "Checking memory after accepting schedule_meeting after feedback:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- response_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 426336,\n",
      "  [Symbol(trigger_async_id_symbol)]: 426329,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(`\\nSimulating user accepting the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "\n",
    "// Await the stream before iterating, and use the correct config key\n",
    "const stream = await graph6.stream(\n",
    "    new Command({ resume: [{ type: \"accept\" }] }),\n",
    "    threadConfig6 // This is { configurable: { thread_id: ... } }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Check memory after accepting schedule_meeting after feedback\n",
    "console.log(\"\\nChecking memory after accepting schedule_meeting after feedback:\");\n",
    "displayMemoryContent(store6, [\"email_assistant\", \"response_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ede94",
   "metadata": {},
   "source": [
    "Now provide feedback for the `write_email` tool call\n",
    "\n",
    "Similar to our meeting feedback, we'll now provide natural language guidance for the email draft:\n",
    "\n",
    "1. We request \"shorter and less formal\" language - a style preference\n",
    "2. We ask for a specific closing statement about looking forward to the meeting\n",
    "3. The system must interpret this guidance and rewrite the email accordingly\n",
    "\n",
    "After providing this feedback, we'll check the response preferences memory to see how these style and structure preferences are captured. We expect to see generalizable guidelines about email brevity, formality, and closing statements added to our preference profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9831ad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user providing feedback for the Email Assistant: respond tool call...\n",
      "\n",
      "Checking memory after providing feedback for write_email:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- response_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 427041,\n",
      "  [Symbol(trigger_async_id_symbol)]: 427034,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(`\\nSimulating user providing feedback for the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "\n",
    "// Await the stream before iterating, and use the correct config key\n",
    "const stream = await graph6.stream(\n",
    "    new Command({\n",
    "        resume: [\n",
    "            {\n",
    "                type: \"response\",\n",
    "                args: \"Shorter and less formal. Include a closing statement about looking forward to the meeting!\"\n",
    "            }\n",
    "        ]\n",
    "    }),\n",
    "    threadConfig6 // This is { configurable: { thread_id: ... } }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    // Inspect response_agent's most recent message\n",
    "    if (\"response_agent\" in chunk) {\n",
    "        const messages = chunk.response_agent.messages;\n",
    "        const lastMessage = messages[messages.length - 1];\n",
    "        if (typeof lastMessage.prettyPrint === \"function\") {\n",
    "            lastMessage.prettyPrint();\n",
    "        } else {\n",
    "            console.log(lastMessage);\n",
    "        }\n",
    "    }\n",
    "    // Inspect interrupt object if present\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Check memory after providing feedback for write_email\n",
    "console.log(\"\\nChecking memory after providing feedback for write_email:\");\n",
    "displayMemoryContent(store6, [\"email_assistant\", \"response_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b360a2",
   "metadata": {},
   "source": [
    "The memory update after our email feedback shows highly sophisticated learning about both meeting scheduling and email writing preferences:\n",
    "\n",
    "1. The system has added a complete new section to the response preferences entitled \"When writing email responses\" with two key preferences:\n",
    "   - \"Favor shorter and less formal language when possible, unless the context requires formality\"\n",
    "   - \"Include a closing statement expressing that you look forward to the meeting or conversation when confirming appointments\"\n",
    "\n",
    "2. It has also added a new bullet point to the \"When responding to meeting scheduling requests\" section:\n",
    "   - \"When scheduling meetings, prefer afternoon times after 2pm when possible, and default to 30-minute durations unless otherwise specified\"\n",
    "\n",
    "This demonstrates the system's ability to:\n",
    "- Organize learned preferences into appropriate categories\n",
    "- Extract multiple insights from a single feedback instance\n",
    "- Apply meeting preferences to both calendar and email contexts\n",
    "- Capture nuance with appropriate qualifiers (\"when possible,\" \"unless otherwise specified\")\n",
    "- Maintain the hierarchical structure of the memory\n",
    "\n",
    "The resulting email shows all these preferences applied: it's shorter, less formal, includes a closing statement about looking forward to the chat, and correctly references the 30-minute meeting time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8c64999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user accepting the Email Assistant: respond tool call...\n",
      "\n",
      "Checking memory after accepting write_email after feedback:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- response_preferences ---\n",
      "No memory found\n",
      "Promise {\n",
      "  undefined,\n",
      "  [Symbol(async_id_symbol)]: 427748,\n",
      "  [Symbol(trigger_async_id_symbol)]: 427741,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(`\\nSimulating user accepting the ${interruptObject.value[0].action_request.action} tool call...`);\n",
    "\n",
    "// Await the stream before iterating, and use the correct config key\n",
    "const stream = await graph6.stream(\n",
    "    new Command({ resume: [{ type: \"accept\" }] }),\n",
    "    threadConfig6 // This is { configurable: { thread_id: ... } }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    // Inspect interrupt object if present\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk[\"__interrupt__\"][0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(\"Action Request:\", interruptObject.value[0].action_request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Check memory after accepting write_email after feedback\n",
    "console.log(\"\\nChecking memory after accepting write_email after feedback:\");\n",
    "displayMemoryContent(store6, [\"email_assistant\", \"response_preferences\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e63cb",
   "metadata": {},
   "source": [
    "Look at the full message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fa9cf91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage {\n",
      "  \"id\": \"d7a684fd-c983-4533-a58b-8cd4af40d1f2\",\n",
      "  \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"a2666cad-f1fe-4e59-9827-84f4af2bb40b\",\n",
      "  \"content\": \"Email to notify user about: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"e4cad591-f6c2-436f-8dd7-f59c7af3df07\",\n",
      "  \"content\": \"User wants to reply to the email. Use this feedback to respond: Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const state5 = await graph6.getState(threadConfig6);\n",
    "for (const m of state5.values.messages) {\n",
    "    if (typeof m.prettyPrint === \"function\") {\n",
    "        m.prettyPrint();\n",
    "    } else {\n",
    "        console.log(m);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac9df0-cd39-4c32-a073-c2482d9554b6",
   "metadata": {},
   "source": [
    "## Testing with Local Deployment\n",
    "\n",
    "You can find this graph with memory integration in the `src/` directory:\n",
    "\n",
    "* `src/email_assistant_hitl_memory.ts`\n",
    "\n",
    "Test it with an email:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "853d3f05-2a47-4859-942c-0a662b40ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "const emailInput = {\n",
    "  author: \"Alice Smith <alice.smith@company.com>\",\n",
    "  to: \"John Doe <john.doe@company.com>\",\n",
    "  subject: \"Quick question about API documentation\",\n",
    "  email_thread: `Hi John,\n",
    "I was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\n",
    "Specifically, I'm looking at:\n",
    "- /auth/refresh\n",
    "- /auth/validate\n",
    "Thanks!\n",
    "Alice`\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4aa8b0-f8b7-4197-8701-87dda60daa26",
   "metadata": {},
   "source": [
    "Testing this locally gives you the full experience of a memory-enabled HITL system:\n",
    "\n",
    "1. **Start the local server**: Run `langgraph dev` to launch the agent locally\n",
    "2. **Connect Agent Inbox**: Use the graph URL from the `langgraph.json` file\n",
    "3. **Submit test emails**: Try different email types to see classification in action\n",
    "4. **Provide various feedback types**: Try accepting, editing, ignoring, and responding\n",
    "5. **Observe memory evolution**: Check the Memory tab in LangGraph Studio to see changes\n",
    "\n",
    "![inbox](img/agent-inbox-edit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075a3ea",
   "metadata": {},
   "source": [
    "The Memory tab in LangGraph Studio offers a real-time view of how your preferences are being captured and updated with each interaction:\n",
    "\n",
    "![studio-img](img/memory-studio.png)\n",
    "\n",
    "Through continued use, the system becomes increasingly personalized:\n",
    "- It learns which emails you want to respond to, be notified about, or ignore\n",
    "- It adapts to your communication style preferences\n",
    "- It remembers your scheduling preferences\n",
    "- It refines its understanding with each interaction\n",
    "\n",
    "This combination of HITL and memory creates a system that balances automation with control - handling routine tasks automatically while learning from your feedback to become more aligned with your preferences over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f60fa538",
   "metadata": {},
   "outputs": [],
   "source": [
    "// langgraph dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6319d",
   "metadata": {},
   "source": [
    "![inbox](img/agent-inbox-edit.png)\n",
    "\n",
    "As you provide feedback or edit replies, you can see memories accumulate in the `memory` tab in LangGraph Studio.\n",
    "\n",
    "![studio-img](img/memory-studio.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad7580",
   "metadata": {},
   "source": [
    "### Future Extensions\n",
    "\n",
    "Consider adding memory to store background information from emails.\n",
    "\n",
    "**Example: Add this to the `llmCall` node:**\n",
    "\n",
    "```ts\n",
    "// Search for existing background memory\n",
    "// TODO: Here, semantic search over a facts collection of background information from emails could be added.\n",
    "const background = getMemory(store, [\"email_assistant\", \"background\"], defaultBackground);\n",
    "```\n",
    "\n",
    "**Example: Add this to the `interruptHandler` node:**\n",
    "\n",
    "```ts\n",
    "else if (toolCall.name === \"Question\") {\n",
    "  // Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "  result.push({\n",
    "    role: \"tool\",\n",
    "    content: `User answered the question, which we can use for any follow up actions. Feedback: ${userFeedback}`,\n",
    "    tool_call_id: toolCall.id\n",
    "  });\n",
    "  // TODO: Here, we could update the background information with the user's answer.\n",
    "  // await updateMemory(store, [\"email_assistant\", \"background\"], [\n",
    "  //   {\n",
    "  //     role: \"user\",\n",
    "  //     content: \"Update background information based upon these messages:\"\n",
    "  //   },\n",
    "  //   ...state.messages,\n",
    "  //   ...result\n",
    "  // ]);\n",
    "}\n",
    "```\n",
    "\n",
    "For more advanced memory management, consider using [LangMem](https://langchain-ai.github.io/langmem/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca357f61",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
