{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c57479",
   "metadata": {},
   "source": [
    "# Agents with Human-in-the-Loop\n",
    "\n",
    "We have an email assistant that uses a router to triage emails and then passes the email to the agent for response generation. We've also evaluated it. But do we fully *trust* it to manage our inbox autonomously? For such a sensitive task, human-in-the-loop (HITL) is important! Here we'll show how to add a human-in-the-loop to our email assistant so that we can review specific tool calls. \n",
    "\n",
    "![overview-img](img/overview_hitl.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77003d",
   "metadata": {},
   "source": [
    "First, let's preview it. Let's run a local deployment of our email assistant with HITL from `src/email_assistant_hitl.ts`  As before, run `pnpm agent`, select `hitlEmailAssistant` in Studio, and submit the e-mail:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f73f12",
   "metadata": {},
   "source": [
    "The graph will *now pause* before specific tools calls, such as `write_email`.\n",
    "\n",
    "![overview-img](img/hitl_schematic.png)\n",
    "\n",
    "You can see the specific tool call that triggered the interrupt in Studio. \n",
    "\n",
    "![studio-img](img/studio-interrupt.png)\n",
    "\n",
    "We'll use a custom interface to handle these interrupts called [Agent Inbox](https://dev.agentinbox.ai/). This interface is a nice way to edit, approve, ignore, or provide feedback on specific actions taken by LangGraph agents.  If you go to [dev.agentinbox.ai](https://dev.agentinbox.ai/), you can add the graph url:\n",
    "   * Graph name: the name from the `langgraph.json` file (`hitlEmailAssistant`)\n",
    "   * Graph URL: `http://localhost:2024/`\n",
    "\n",
    "All interrupted threads run will be visible: \n",
    "\n",
    "![agent-inbox-img](img/agent-inbox.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566464d",
   "metadata": {},
   "source": [
    "## Adding HITL to our email assistant\n",
    "\n",
    "Now that we've seen interrupt in Studio with Agent Inbox, let's add HITL to our email assistant. \n",
    "\n",
    "We can start with tools, just as we did before. We will also add some zod schemas necessary for the tools.\n",
    "\n",
    "But now, we'll add a few new tools including `Question` that will allow the assist to ask the user a question. We can answer questions via HITL! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4dfb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { StateGraph, START, END, interrupt, Command } from \"@langchain/langgraph\";\n",
    "import { initChatModel } from \"langchain/chat_models/universal\";\n",
    "import { AIMessage, BaseMessage, HumanMessage } from \"@langchain/core/messages\";\n",
    "import { Messages, addMessages } from \"@langchain/langgraph\";\n",
    "import \"@langchain/langgraph/zod\";\n",
    "\n",
    "// Define the Zod schemas for the email assistant states\n",
    "const MessagesState = z.object({\n",
    "    messages: z\n",
    "        .custom<BaseMessage[]>()\n",
    "        .default(() => [])\n",
    "        .langgraph.reducer<Messages>((left, right) => addMessages(left, right)),\n",
    "});\n",
    "\n",
    "const BaseEmailAgentState = MessagesState.extend({\n",
    "    email_input: z.any(),\n",
    "    classification_decision: z\n",
    "        .enum([\"ignore\", \"respond\", \"notify\"])\n",
    "        .nullable()\n",
    "        .default(null),\n",
    "});\n",
    "\n",
    "const EmailAgentHITLState = MessagesState.extend({\n",
    "    email_input: z.any(),\n",
    "    classification_decision: z\n",
    "        .enum([\"ignore\", \"respond\", \"notify\", \"error\"])\n",
    "        .nullable()\n",
    "        .default(null),\n",
    "});\n",
    "\n",
    "// Export the inferred types from the Zod schemas\n",
    "type BaseEmailAgentStateType = z.infer<typeof BaseEmailAgentState>;\n",
    "type EmailAgentHITLStateType = z.infer<typeof EmailAgentHITLState>;\n",
    "\n",
    "// Email tool with correct properties\n",
    "const emailSchema = z.object({\n",
    "    recipient: z.string().describe(\"Email address of the recipient\"),\n",
    "    subject: z.string().describe(\"Clear and concise subject line for the email\"),\n",
    "    content: z.string().describe(\"Main body text of the email\"),\n",
    "});\n",
    "\n",
    "const writeEmail = tool(async ({\n",
    "    recipient,\n",
    "    subject,\n",
    "    content,\n",
    "}: z.infer<typeof emailSchema>) => {\n",
    "    return `Email draft created:\n",
    "To: ${recipient}\n",
    "Subject: ${subject}\n",
    "${content}\n",
    "[Draft saved. Ready to send or edit further.]`;\n",
    "}, {\n",
    "    name: \"write_email\",\n",
    "    description:\n",
    "        \"Write an email draft based on provided information. Use this when the user wants to compose a new email message.\",\n",
    "    schema: emailSchema,\n",
    "});\n",
    "\n",
    "// Calendar tool with correct properties\n",
    "const scheduleMeetingSchema = z.object({\n",
    "    title: z.string().describe(\"Meeting title\"),\n",
    "    attendees: z.array(z.string()).describe(\"List of attendees' emails\"),\n",
    "    startTime: z.string().describe(\"Meeting start time in ISO format\"),\n",
    "    endTime: z.string().describe(\"Meeting end time in ISO format\"),\n",
    "    description: z.string().optional().describe(\"Meeting description\"),\n",
    "});\n",
    "\n",
    "const scheduleMeeting = tool(async (args: z.infer<typeof scheduleMeetingSchema>) => {\n",
    "    const { title, attendees, startTime, endTime, description } = args;\n",
    "    // Mock implementation\n",
    "    return `Meeting \"${title}\" scheduled from ${startTime} to ${endTime} with ${attendees.length} attendees`;\n",
    "}, {\n",
    "    name: \"schedule_meeting\",\n",
    "    description: \"Schedule a meeting on the calendar\",\n",
    "    schema: scheduleMeetingSchema,\n",
    "});\n",
    "\n",
    "const availabilitySchema = z.object({\n",
    "    startTime: z.string().describe(\"Start time in ISO format\"),\n",
    "    endTime: z.string().describe(\"End time in ISO format\"),\n",
    "});\n",
    "\n",
    "const checkCalendarAvailability = tool(async (args: z.infer<typeof availabilitySchema>) => {\n",
    "    const { startTime, endTime } = args;\n",
    "    // Mock implementation\n",
    "    return `Time slot from ${startTime} to ${endTime} is available`;\n",
    "}, {\n",
    "    name: \"check_calendar_availability\",\n",
    "    description: \"Check calendar availability for a specified time range\",\n",
    "    schema: availabilitySchema,\n",
    "},\n",
    ");\n",
    "\n",
    "const questionTool = tool(\n",
    "    async ({ content }: { content: string }) => {\n",
    "        return `The user will see and can answer this question: ${content}`;\n",
    "    },\n",
    "    {\n",
    "        name: \"question\",\n",
    "        description: \"Ask the user a follow-up question\",\n",
    "        schema: z.object({\n",
    "            content: z.string().describe(\"The question to ask the user\"),\n",
    "        }),\n",
    "    },\n",
    ");\n",
    "\n",
    "// Define the doneSchema\n",
    "const doneSchema = z.object({\n",
    "    content: z.string().optional().describe(\"Optional completion message\"),\n",
    "});\n",
    "\n",
    "const Done = tool(async () => {\n",
    "    return \"Task completed successfully. No further actions required.\";\n",
    "}, {\n",
    "    name: \"Done\",\n",
    "    description:\n",
    "        \"Signal that you've completed the current task and no further actions are needed.\",\n",
    "    schema: doneSchema,\n",
    "});\n",
    "\n",
    "const tools = [\n",
    "    writeEmail,\n",
    "    scheduleMeeting,\n",
    "    checkCalendarAvailability,\n",
    "    questionTool,\n",
    "    Done,\n",
    "];\n",
    "\n",
    "const toolsByName = Object.fromEntries(tools.map((t) => [t.name, t]));\n",
    "\n",
    "// LLM setup\n",
    "const llm = initChatModel(\"openai:gpt-4.1\", { temperature: 0.0 });\n",
    "\n",
    "// Using async/await and promise chaining for models with structured outputs\n",
    "const setupModels = async () => {\n",
    "    const baseRouterModel = await initChatModel(\"openai:gpt-4.1\", { temperature: 0.0 });\n",
    "    const baseToolsModel = await initChatModel(\"openai:gpt-4.1\", { temperature: 0.0 });\n",
    "    const llmRouter = baseRouterModel.withStructuredOutput(RouterSchema);\n",
    "    const llmWithTools = baseToolsModel.bindTools(tools, { toolChoice: \"required\" });\n",
    "    return { llmRouter, llmWithTools };\n",
    "};\n",
    "\n",
    "const RouterSchema = z.object({\n",
    "    reasoning: z\n",
    "        .string()\n",
    "        .describe(\"Step-by-step reasoning behind the classification\"),\n",
    "    classification: z\n",
    "        .enum([\"ignore\", \"respond\", \"notify\"])\n",
    "        .describe(\n",
    "            \"The classification of an email: 'ignore' for irrelevant emails, \" +\n",
    "            \"'notify' for important information that doesn't need a response, \" +\n",
    "            \"'respond' for emails that need a reply\",\n",
    "        ),\n",
    "});\n",
    "\n",
    "// Input schema (once)\n",
    "const StateInput = z.object({\n",
    "    email_input: z.any(),\n",
    "});\n",
    "\n",
    "// For simplified state access in functions\n",
    "interface State {\n",
    "    email_input: any;\n",
    "    classification_decision?: string;\n",
    "    messages: BaseMessage[];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf05b260-9809-4f32-807b-abe1632e4181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. write_email(to, subject, content) - Send emails to specified recipients\n",
      "2. schedule_meeting(attendees, subject, duration_minutes, preferred_day, start_time) - Schedule calendar meetings where preferred_day is a datetime object\n",
      "3. check_calendar_availability(day) - Check available time slots for a given day\n",
      "4. Question(content) - Ask the user any follow-up questions\n",
      "5. Done - E-mail has been sent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Tool descriptions for HITL workflow\n",
    "const HITL_TOOLS_PROMPT = `\n",
    "1. write_email(to, subject, content) - Send emails to specified recipients\n",
    "2. schedule_meeting(attendees, subject, duration_minutes, preferred_day, start_time) - Schedule calendar meetings where preferred_day is a datetime object\n",
    "3. check_calendar_availability(day) - Check available time slots for a given day\n",
    "4. Question(content) - Ask the user any follow-up questions\n",
    "5. Done - E-mail has been sent\n",
    "`;\n",
    "console.log(HITL_TOOLS_PROMPT);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8f334",
   "metadata": {},
   "source": [
    "#### Triage node\n",
    "\n",
    "We define a TypeScript function with our triage routing logic, just as we did before.\n",
    "\n",
    "But, if the classification is `notify`, we want to interrupt the graph to allow the user to review the email! So we go to a new node, `triageRouter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65efb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "function parseEmail(email: EmailData): {\n",
    "  author: string;\n",
    "  to: string;\n",
    "  subject: string;\n",
    "  emailThread: string;\n",
    "} {\n",
    "  try {\n",
    "      // Extract key information from email data\n",
    "      const author = email.from_email;\n",
    "      const to = email.to_email;\n",
    "      const subject = email.subject;\n",
    "      const emailThread = email.page_content;\n",
    "\n",
    "      return { author, to, subject, emailThread };\n",
    "  } catch (error) {\n",
    "      console.error(\"Error parsing email:\", error);\n",
    "      throw new Error(\"Failed to parse email\");\n",
    "  }\n",
    "}\n",
    "\n",
    "const defaultTriageInstructions = `\n",
    "Emails that are not worth responding to:\n",
    "- Marketing newsletters and promotional emails\n",
    "- Spam or suspicious emails\n",
    "- CC'd on FYI threads with no direct questions\n",
    "\n",
    "There are also other things that should be known about, but don't require an email response. For these, you should notify (using the \\`notify\\` response). Examples of this include:\n",
    "- Team member out sick or on vacation\n",
    "- Build system notifications or deployments\n",
    "- Project status updates without action items\n",
    "- Important company announcements\n",
    "- FYI emails that contain relevant information for current projects\n",
    "- HR Department deadline reminders\n",
    "- Subscription status / renewal reminders\n",
    "- GitHub notifications\n",
    "\n",
    "Emails that are worth responding to:\n",
    "- Direct questions from team members requiring expertise\n",
    "- Meeting requests requiring confirmation\n",
    "- Critical bug reports related to team's projects\n",
    "- Requests from management requiring acknowledgment\n",
    "- Client inquiries about project status or features\n",
    "- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\n",
    "- Personal reminders related to family (wife / daughter)\n",
    "- Personal reminder related to self-care (doctor appointments, etc)\n",
    "`;\n",
    "\n",
    "///////PROMPTS \n",
    "const defaultBackground = `\n",
    "I'm Lance, a software engineer at LangChain.\n",
    "`;\n",
    "// Agentic workflow triage user prompt\n",
    "const triageUserPrompt = `\n",
    "Please determine how to handle the below email thread:\n",
    "\n",
    "From: {author}\n",
    "To: {to}\n",
    "Subject: {subject}\n",
    "{email_thread}`;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "const triageSystemPrompt = `\n",
    "<Role>\n",
    "Your role is to triage incoming emails based upon instructs and background information below.\n",
    "</Role>\n",
    "\n",
    "<Background>\n",
    "{background}. \n",
    "</Background>\n",
    "\n",
    "<Instructions>\n",
    "Categorize each email into one of three categories:\n",
    "1. IGNORE - Emails that are not worth responding to or tracking\n",
    "2. NOTIFY - Important information that worth notification but doesn't require a response\n",
    "3. RESPOND - Emails that need a direct response\n",
    "Classify the below email into one of these categories.\n",
    "</Instructions>\n",
    "\n",
    "<Rules>\n",
    "{triage_instructions}\n",
    "</Rules>\n",
    "`;\n",
    "\n",
    "function formatEmailMarkdown(\n",
    "  subject: string,\n",
    "  author: string,\n",
    "  to: string,\n",
    "  emailThread: string,\n",
    "): string {\n",
    "  return `## Email: ${subject}\n",
    "**From**: ${author}\n",
    "**To**: ${to}\n",
    "${emailThread}`;\n",
    "}\n",
    "\n",
    "type EmailData = {\n",
    "  id: string;\n",
    "  thread_id: string;\n",
    "  from_email: string;\n",
    "  subject: string;\n",
    "  page_content: string;\n",
    "  send_time: string;\n",
    "  to_email: string;\n",
    "};\n",
    "\n",
    "async function triageRouter(state: State) {\n",
    "  const { author, to, subject, emailThread } = parseEmail(state.email_input);\n",
    "\n",
    "  const emailMarkdown = formatEmailMarkdown(subject, author, to, emailThread);\n",
    "  // Fix the string template replacement issue\n",
    "  const userPrompt = triageUserPrompt\n",
    "      .replace(\"{author}\", author)\n",
    "      .replace(\"{to}\", to)\n",
    "      .replace(\"{subject}\", subject)\n",
    "      .replace(\"{email_thread}\", emailThread);\n",
    "  // Fix the string template replacement issue\n",
    "  const systemPrompt = triageSystemPrompt\n",
    "      .replace(\"{background}\", defaultBackground)\n",
    "      .replace(\"{triage_instructions}\", defaultTriageInstructions);\n",
    "\n",
    "  // Await the model to be initialized first\n",
    "  const model = await initChatModel(\"openai:gpt-4.1\", { temperature: 0.0 });\n",
    "  const routerModel = model.withStructuredOutput(RouterSchema);\n",
    "\n",
    "  // Await the invoke result\n",
    "  const result = await routerModel.invoke([\n",
    "      { role: \"system\", content: systemPrompt },\n",
    "      { role: \"user\", content: userPrompt },\n",
    "  ]);\n",
    "\n",
    "  const classification = result.classification;\n",
    "\n",
    "  if (classification === \"respond\") {\n",
    "      console.log(\"ðŸ“§ Classification: RESPOND - This email requires a response\");\n",
    "      return new Command({\n",
    "          goto: \"response_agent\",\n",
    "          update: {\n",
    "              classification_decision: result.classification,\n",
    "              messages: [\n",
    "                  {\n",
    "                      role: \"user\",\n",
    "                      content: `Respond to the email: ${emailMarkdown}`,\n",
    "                  },\n",
    "              ],\n",
    "          },\n",
    "      });\n",
    "  } else if (classification === \"ignore\") {\n",
    "      console.log(\"ðŸš« Classification: IGNORE - This email can be safely ignored\");\n",
    "      return new Command({\n",
    "          goto: END,\n",
    "          update: { classification_decision: classification },\n",
    "      });\n",
    "  } else if (classification === \"notify\") {\n",
    "      console.log(\"ðŸ”” Classification: NOTIFY - This email contains important information\");\n",
    "      return new Command({\n",
    "          goto: \"triage_interrupt_handler\",\n",
    "          update: { classification_decision: classification },\n",
    "      });\n",
    "  } else {\n",
    "      return new Command({\n",
    "          goto: END,\n",
    "          update: { classification_decision: classification },\n",
    "      });\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f564a",
   "metadata": {},
   "source": [
    "But, remember now we want to interrupt the graph at the `notify` classification to allow the user to review the email. \n",
    "\n",
    "![overview-img](img/hitl_schematic.png)\n",
    "\n",
    "For this, we simply add a new node, `triageInterruptHandler`, that will: \n",
    "\n",
    "1. Show the classification to the user if it is `notify`: We'll pass an object to the interrupt that contains our classification. \n",
    "2. Allow the user to respond to the decision: We'll design the code to handle what we will get back from Agent Inbox. \n",
    "\n",
    "As you can see [here](https://github.com/langchain-ai/agent-inbox?tab=readme-ov-file#what-do-the-fields-mean) (note: Agent Inbox itself might be a separate system, ensure its API aligns with your LangGraph JS interrupt structure), we format our interrupt with specific fields so that it can be viewed in Agent Inbox:\n",
    "\n",
    "* `action_request`: The action and arguments for the interrupt with `action` (the action name) and `args` (the tool call arguments). This is rendered in the Agent Inbox as the main header for the interrupt event.\n",
    "* `config`: Configures which interaction types are allowed, and specific UI elements for each. \n",
    "* `description`: Should be detailed, and may be markdown. This will be rendered in the Agent Inbox as the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "203346bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "function triageInterruptHandler(state) {\n",
    "  const { author, to, subject, emailThread } = parseEmail(state.email_input);\n",
    "  const emailMarkdown = formatEmailMarkdown(subject, author, to, emailThread);\n",
    "\n",
    "  const messages = [\n",
    "      {\n",
    "          role: \"user\",\n",
    "          content: `Email to notify user about: ${emailMarkdown}`,\n",
    "      },\n",
    "  ];\n",
    "\n",
    "  const request = {\n",
    "      action_request: {\n",
    "          action: `Email Assistant: ${state.classification_decision}`,\n",
    "          args: {},\n",
    "      },\n",
    "      config: {\n",
    "          allow_ignore: true,\n",
    "          allow_respond: true,\n",
    "          allow_edit: false,\n",
    "          allow_accept: false,\n",
    "      },\n",
    "      description: emailMarkdown,\n",
    "  };\n",
    "\n",
    "  const response = interrupt([request])[0];\n",
    "\n",
    "  // Declare routing destination variable\n",
    "  let routeTo;\n",
    "\n",
    "  if (response.type === \"response\") {\n",
    "      const userInput = response.args;\n",
    "      messages.push({\n",
    "          role: \"user\",\n",
    "          content: `User wants to reply to the email. Use this feedback to respond: ${userInput}`,\n",
    "      });\n",
    "      routeTo = \"response_agent\";\n",
    "  } else if (response.type === \"ignore\") {\n",
    "      routeTo = END;\n",
    "  } else {\n",
    "      throw new Error(`Invalid response: ${JSON.stringify(response)}`);\n",
    "  }\n",
    "\n",
    "  return new Command({\n",
    "      goto: routeTo,\n",
    "      update: { messages },\n",
    "  });\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613e4c4",
   "metadata": {},
   "source": [
    "The `llmCall` node is the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036aba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import z from \"zod\";\n",
    "import { initChatModel } from \"langchain/chat_models/universal\";\n",
    "\n",
    "// Define the router schema using Zod\n",
    "const RouterSchema = z.object({\n",
    "    reasoning: z.string().describe(\"Step-by-step reasoning behind the classification.\"),\n",
    "    classification: z.enum([\"ignore\", \"respond\", \"notify\"]).describe(\n",
    "        \"The classification of an email: 'ignore' for irrelevant emails, \" +\n",
    "        \"'notify' for important information that doesn't need a response, \" +\n",
    "        \"'respond' for emails that need a reply\"\n",
    "    )\n",
    "});\n",
    "\n",
    "// Default calendar preferences\n",
    "const defaultCalPreferences = `\n",
    "30 minute meetings are preferred, but 15 minute meetings are also acceptable.\n",
    "`;\n",
    "\n",
    "// Tool descriptions for HITL workflow\n",
    "const HITL_TOOLS_PROMPT = `\n",
    "1. write_email(to, subject, content) - Send emails to specified recipients\n",
    "2. schedule_meeting(attendees, subject, duration_minutes, preferred_day, start_time) - Schedule calendar meetings where preferred_day is a datetime object\n",
    "3. check_calendar_availability(day) - Check available time slots for a given day\n",
    "4. Question(content) - Ask the user any follow-up questions\n",
    "5. Done - E-mail has been sent\n",
    "`;\n",
    "\n",
    "// Agentic workflow with HITL prompt\n",
    "const agentSystemPromptHitl = `\n",
    "<Role>\n",
    "You are a top-notch executive assistant who cares about helping your executive perform as well as possible.\n",
    "</Role>\n",
    "\n",
    "<Tools>\n",
    "You have access to the following tools to help manage communications and schedule:\n",
    "{tools_prompt}\n",
    "</Tools>\n",
    "\n",
    "<Instructions>\n",
    "When handling emails, follow these steps:\n",
    "1. Carefully analyze the email content and purpose\n",
    "2. IMPORTANT --- always call a tool and call one tool at a time until the task is complete: \n",
    "3. If you need more information to complete the task, use the Question tool to ask a follow-up question to the user \n",
    "4. For responding to the email, draft a response email with the write_email tool\n",
    "5. For meeting requests, use the check_calendar_availability tool to find open time slots\n",
    "6. To schedule a meeting, use the schedule_meeting tool with a datetime object for the preferred_day parameter\n",
    "   - Today's date is ${new Date().toISOString().split(\"T\")[0]} - use this for scheduling meetings accurately\n",
    "7. If you scheduled a meeting, then draft a short response email using the write_email tool\n",
    "8. After using the write_email tool, the task is complete\n",
    "9. If you have sent the email, then use the Done tool to indicate that the task is complete\n",
    "</Instructions>\n",
    "\n",
    "<Background>\n",
    "{background}\n",
    "</Background>\n",
    "\n",
    "<Response Preferences>\n",
    "{response_preferences}\n",
    "</Response Preferences>\n",
    "\n",
    "<Calendar Preferences>\n",
    "{cal_preferences}\n",
    "</Calendar Preferences>\n",
    "`;\n",
    "\n",
    "\n",
    "const defaultResponsePreferences = `\n",
    "Use professional and concise language. If the e-mail mentions a deadline, make sure to explicitly acknowledge and reference the deadline in your response.\n",
    "\n",
    "When responding to technical questions that require investigation:\n",
    "- Clearly state whether you will investigate or who you will ask\n",
    "- Provide an estimated timeline for when you'll have more information or complete the task\n",
    "\n",
    "When responding to event or conference invitations:\n",
    "- Always acknowledge any mentioned deadlines (particularly registration deadlines)\n",
    "- If workshops or specific topics are mentioned, ask for more specific details about them\n",
    "- If discounts (group or early bird) are mentioned, explicitly request information about them\n",
    "- Don't commit \n",
    "\n",
    "When responding to collaboration or project-related requests:\n",
    "- Acknowledge any existing work or materials mentioned (drafts, slides, documents, etc.)\n",
    "- Explicitly mention reviewing these materials before or during the meeting\n",
    "- When scheduling meetings, clearly state the specific day, date, and time proposed\n",
    "\n",
    "When responding to meeting scheduling requests:\n",
    "- If times are proposed, verify calendar availability for all time slots mentioned in the original email and then commit to one of the proposed times based on your availability by scheduling the meeting. Or, say you can't make it at the time proposed.\n",
    "- If no times are proposed, then check your calendar for availability and propose multiple time options when available instead of selecting just one.\n",
    "- Mention the meeting duration in your response to confirm you've noted it correctly.\n",
    "- Reference the meeting's purpose in your response.\n",
    "`;\n",
    "\n",
    "\n",
    "const llm = await initChatModel(\n",
    "    \"openai:gpt-4o\",\n",
    "    { temperature: 0.0 }\n",
    ");\n",
    "\n",
    "\n",
    "const llmWithTools = llm.bindTools(tools, { toolChoice: \"required\" });\n",
    "\n",
    "async function llmCall(state) {\n",
    "    /**\n",
    "     * LLM decides whether to call a tool or not\n",
    "     * This is the main decision-making node that generates responses or tool calls\n",
    "     */\n",
    "    const messages = [...state.messages];\n",
    "    const systemPromptContent = agentSystemPromptHitl\n",
    "        .replace(\"{tools_prompt}\", HITL_TOOLS_PROMPT)\n",
    "        .replace(\"{background}\", defaultBackground)\n",
    "        .replace(\"{response_preferences}\", defaultResponsePreferences)\n",
    "        .replace(\"{cal_preferences}\", defaultCalPreferences);\n",
    "\n",
    "    // Run the LLM with the messages\n",
    "    const response = await llmWithTools.invoke([\n",
    "        { role: \"system\", content: systemPromptContent },\n",
    "        ...messages,\n",
    "    ]);\n",
    "\n",
    "    // Return messages in the format expected by the graph\n",
    "    return {\n",
    "        messages: response,\n",
    "    };\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397516ee",
   "metadata": {},
   "source": [
    "The `interrupt_handler` is the core HITL component of our response agent. \n",
    "\n",
    "Its job is to examine the tool calls that the LLM wants to make and determine which ones need human review before execution. Here's how it works:\n",
    "\n",
    "1. **Tool Selection**: The handler maintains a list of \"HITL tools\" that require human approval:\n",
    "   - `write_email`: Since sending emails has significant external impact\n",
    "   - `schedule_meeting`: Since scheduling meetings affects calendars\n",
    "   - `Question`: Since asking users questions requires direct interaction\n",
    "\n",
    "2. **Direct Execution**: Tools not in the HITL list (like `check_calendar_availability`) are executed immediately without interruption. This allows low-risk operations to proceed automatically.\n",
    "\n",
    "3. **Context Preparation**: For tools requiring review, the handler:\n",
    "   - Retrieves the original email for context\n",
    "   - Formats the tool call details for clear display\n",
    "   - Configures which interaction types are allowed for each tool type\n",
    "\n",
    "4. **Interrupt Creation**: The handler creates a structured interrupt request with:\n",
    "   - The action name and arguments\n",
    "   - Configuration for allowed interaction types\n",
    "   - A description that includes both the original email and the proposed action\n",
    "\n",
    "5. **Response Processing**: After the interrupt, the handler processes the human response:\n",
    "   - **Accept**: Executes the tool with original arguments\n",
    "   - **Edit**: Updates the tool call with edited arguments and then executes\n",
    "   - **Ignore**: Cancels the tool execution\n",
    "   - **Response**: Records feedback without execution\n",
    "\n",
    "This handler ensures humans have oversight of all significant actions while allowing routine operations to proceed automatically. \n",
    "\n",
    "The ability to edit tool arguments (like email content or meeting details) gives users precise control over the assistant's actions.\n",
    "\n",
    "We can visualize the overall flow: \n",
    "\n",
    "![overview-img](img/HITL_flow.png)\n",
    "\n",
    "Agent Inbox will allow us review each tool call. As an example, with `write_email` you can fully edit the email content in a rich text editor, allowing for precise control over the final message. Agent Inbox returns a list of dicts with a single key `type` that can be `accept`, `edit`, `ignore`, or `response`.   \n",
    "\n",
    "![agent-inbox-img](img/agent-inbox-draft.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6d1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import {\n",
    "    StateGraph,\n",
    "    START,\n",
    "    END,\n",
    "    interrupt,\n",
    "    Command\n",
    "} from \"@langchain/langgraph\";\n",
    "import { AIMessage, BaseMessage, HumanMessage, ToolMessage } from \"@langchain/core/messages\";\n",
    "import { Messages, addMessages } from \"@langchain/langgraph\";\n",
    "import \"@langchain/langgraph/zod\";\n",
    "import { ToolCall } from \"@langchain/core/messages/tool\";\n",
    "\n",
    "// Helper for type checking\n",
    "const hasToolCalls = (\n",
    "    message: BaseMessage\n",
    "): message is AIMessage & { tool_calls: ToolCall[] } => {\n",
    "    return (\n",
    "        message.getType() === \"ai\" &&\n",
    "        \"tool_calls\" in message &&\n",
    "        Array.isArray((message as any).tool_calls) &&\n",
    "        (message as any).tool_calls.length > 0\n",
    "    );\n",
    "};\n",
    "\n",
    "// Define proper state schema\n",
    "const MessagesState = z.object({\n",
    "    messages: z\n",
    "        .custom<BaseMessage[]>()\n",
    "        .default(() => [])\n",
    "        .langgraph.reducer<Messages>((left, right) => addMessages(left, right)),\n",
    "});\n",
    "\n",
    "// Extend MessagesState for our email agent\n",
    "const EmailAgentState = MessagesState.extend({\n",
    "    email_input: z.any(),\n",
    "    classification_decision: z\n",
    "        .enum([\"ignore\", \"respond\", \"notify\", \"error\"])\n",
    "        .nullable()\n",
    "        .default(null),\n",
    "});\n",
    "\n",
    "// Define types from schemas\n",
    "type EmailAgentStateType = z.infer<typeof EmailAgentState>;\n",
    "\n",
    "// Input schema\n",
    "const StateInputSchema = z.object({\n",
    "    email_input: z.any(),\n",
    "});\n",
    "type StateInputType = z.infer<typeof StateInputSchema>;\n",
    "\n",
    "// Create the interrupt handler node\n",
    "async function interruptHandler(\n",
    "    state: EmailAgentStateType\n",
    "): Promise<Command> {\n",
    "    // Store messages to be returned\n",
    "    const result: BaseMessage[] = [];\n",
    "    // Default goto is llm_call\n",
    "    let goto: typeof END | \"llm_call\" = \"llm_call\";\n",
    "\n",
    "    // Get the last message\n",
    "    const lastMessage = state.messages[state.messages.length - 1];\n",
    "\n",
    "    // Exit early if there are no tool calls\n",
    "    if (!hasToolCalls(lastMessage)) {\n",
    "        return new Command({\n",
    "            goto,\n",
    "            update: { messages: [] },\n",
    "        });\n",
    "    }\n",
    "\n",
    "    // Process one tool call at a time\n",
    "    for (const toolCall of lastMessage.tool_calls) {\n",
    "        const hitlTools = [\"write_email\", \"schedule_meeting\", \"Question\"];\n",
    "\n",
    "        if (!hitlTools.includes(toolCall.name)) {\n",
    "            const tool = toolsByName[toolCall.name];\n",
    "            const observation = await tool.invoke(toolCall.args);\n",
    "            result.push(new ToolMessage({\n",
    "                content: observation,\n",
    "                tool_call_id: toolCall.id\n",
    "            }));\n",
    "            continue;\n",
    "        }\n",
    "\n",
    "        const emailInput = state.email_input;\n",
    "        const { author, to, subject, emailThread } = parseEmail(emailInput);\n",
    "        const originalEmailMarkdown = formatEmailMarkdown(subject, author, to, emailThread);\n",
    "        function formatForDisplay(toolCall: ToolCall): string {\n",
    "            // Initialize empty display\n",
    "            let display = \"\";\n",
    "\n",
    "            // Add tool call information based on tool type\n",
    "            switch (toolCall.name) {\n",
    "                case \"write_email\":\n",
    "                    display += `# Email Draft\n",
    "    \n",
    "    **To**: ${toolCall.args.to}\n",
    "    **Subject**: ${toolCall.args.subject}\n",
    "    \n",
    "    ${toolCall.args.content}\n",
    "    `;\n",
    "                    break;\n",
    "\n",
    "                case \"schedule_meeting\":\n",
    "                    display += `# Calendar Invite\n",
    "    \n",
    "    **Meeting**: ${toolCall.args.subject}\n",
    "    **Attendees**: ${toolCall.args.attendees?.join(\", \")}\n",
    "    **Duration**: ${toolCall.args.duration_minutes} minutes\n",
    "    **Day**: ${toolCall.args.preferred_day}\n",
    "    `;\n",
    "                    break;\n",
    "\n",
    "                case \"question\":\n",
    "                    // Special formatting for questions to make them clear\n",
    "                    display += `# Question for User\n",
    "    \n",
    "    ${toolCall.args.content}\n",
    "    `;\n",
    "                    break;\n",
    "\n",
    "                default:\n",
    "                    // Generic format for other tools\n",
    "                    display += `# Tool Call: ${toolCall.name}\n",
    "    \n",
    "    Arguments:\n",
    "    ${JSON.stringify(toolCall.args, null, 2)}\n",
    "    `;\n",
    "            }\n",
    "\n",
    "            return display;\n",
    "        }\n",
    "        const toolDisplay = formatForDisplay(toolCall);\n",
    "        const description = originalEmailMarkdown + toolDisplay;\n",
    "\n",
    "        let config;\n",
    "        if (toolCall.name === \"write_email\" || toolCall.name === \"schedule_meeting\") {\n",
    "            config = {\n",
    "                allow_ignore: true,\n",
    "                allow_respond: true,\n",
    "                allow_edit: true,\n",
    "                allow_accept: true,\n",
    "            };\n",
    "        } else if (toolCall.name === \"Question\") {\n",
    "            config = {\n",
    "                allow_ignore: true,\n",
    "                allow_respond: true,\n",
    "                allow_edit: false,\n",
    "                allow_accept: false,\n",
    "            };\n",
    "        } else {\n",
    "            throw new Error(`Invalid tool call: ${toolCall.name}`);\n",
    "        }\n",
    "\n",
    "        const request = {\n",
    "            action_request: {\n",
    "                action: toolCall.name,\n",
    "                args: toolCall.args,\n",
    "            },\n",
    "            config,\n",
    "            description,\n",
    "        };\n",
    "\n",
    "        const response = interrupt([request])[0];\n",
    "\n",
    "        if (response.type === \"accept\") {\n",
    "            const tool = toolsByName[toolCall.name];\n",
    "            const observation = await tool.invoke(toolCall.args);\n",
    "            result.push(new ToolMessage({\n",
    "                content: observation,\n",
    "                tool_call_id: toolCall.id\n",
    "            }));\n",
    "        } else if (response.type === \"edit\") {\n",
    "            const tool = toolsByName[toolCall.name];\n",
    "            const editedArgs = response.args;\n",
    "            const observation = await tool.invoke(editedArgs);\n",
    "            result.push(new ToolMessage({\n",
    "                content: observation,\n",
    "                tool_call_id: toolCall.id\n",
    "            }));\n",
    "        } else if (response.type === \"ignore\") {\n",
    "            result.push(new ToolMessage({\n",
    "                content: `User ignored this ${toolCall.name} draft. Ignore this and end the workflow.`,\n",
    "                tool_call_id: toolCall.id\n",
    "            }));\n",
    "            goto = END;\n",
    "        } else if (response.type === \"response\") {\n",
    "            const userFeedback = response.args;\n",
    "            result.push(new ToolMessage({\n",
    "                content: `User gave feedback, which can we incorporate into the ${toolCall.name}. Feedback: ${userFeedback}`,\n",
    "                tool_call_id: toolCall.id\n",
    "            }));\n",
    "        } else {\n",
    "            throw new Error(`Invalid response: ${JSON.stringify(response)}`);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return new Command({\n",
    "        goto,\n",
    "        update: { messages: result }\n",
    "    });\n",
    "}\n",
    "\n",
    "// Create shouldContinue function for conditional edges\n",
    "function shouldContinue(state: EmailAgentStateType) {\n",
    "    const messages = state.messages;\n",
    "    if (!messages || messages.length === 0) return END;\n",
    "\n",
    "    const lastMessage = messages[messages.length - 1];\n",
    "\n",
    "    if (hasToolCalls(lastMessage)) {\n",
    "        // Check if any tool call is the \"Done\" tool\n",
    "        if (lastMessage.tool_calls.some(toolCall => toolCall.name === \"Done\")) {\n",
    "            return END;\n",
    "        }\n",
    "        return \"interrupt_handler\";\n",
    "    }\n",
    "\n",
    "    return END;\n",
    "}\n",
    "\n",
    "// Build the agent workflow using the graph builder already defined\n",
    "const agentBuilder = new StateGraph(EmailAgentState)\n",
    "    .addNode(\"llm_call\", llmCall)\n",
    "    .addNode(\"interrupt_handler\", interruptHandler)\n",
    "    .addEdge(START, \"llm_call\")\n",
    "    .addConditionalEdges(\"llm_call\", shouldContinue)\n",
    "    .addEdge(\"interrupt_handler\", \"llm_call\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747dcda",
   "metadata": {},
   "source": [
    "Now, we can test some of the HITL patterns. \n",
    "\n",
    "## Accept the `write_email` tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c12b2097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "{\n",
      "  triage_router: { classification_decision: 'respond', messages: [ [Object] ] }\n",
      "}\n",
      "{\n",
      "  response_agent: {\n",
      "    messages: [\n",
      "      HumanMessage {\n",
      "        \"id\": \"0f71b6fe-54c8-41ac-8552-790740de4540\",\n",
      "        \"content\": \"Respond to the email: ## Email: Tax season let's schedule call\\n**From**: undefined\\n**To**: undefined\\nundefined\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {}\n",
      "      },\n",
      "      AIMessage {\n",
      "        \"id\": \"chatcmpl-BWVQ7iyjQ7p2n54hK39LLPLYrbcKH\",\n",
      "        \"content\": \"\",\n",
      "        \"additional_kwargs\": {\n",
      "          \"tool_calls\": [\n",
      "            {\n",
      "              \"id\": \"call_oGwsrNfD15TqYMQaSqtD9wtL\",\n",
      "              \"type\": \"function\",\n",
      "              \"function\": \"[Object]\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"response_metadata\": {\n",
      "          \"tokenUsage\": {\n",
      "            \"promptTokens\": 968,\n",
      "            \"completionTokens\": 63,\n",
      "            \"totalTokens\": 1031\n",
      "          },\n",
      "          \"finish_reason\": \"tool_calls\",\n",
      "          \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "          \"usage\": {\n",
      "            \"prompt_tokens\": 968,\n",
      "            \"completion_tokens\": 63,\n",
      "            \"total_tokens\": 1031,\n",
      "            \"prompt_tokens_details\": {\n",
      "              \"cached_tokens\": 0,\n",
      "              \"audio_tokens\": 0\n",
      "            },\n",
      "            \"completion_tokens_details\": {\n",
      "              \"reasoning_tokens\": 0,\n",
      "              \"audio_tokens\": 0,\n",
      "              \"accepted_prediction_tokens\": 0,\n",
      "              \"rejected_prediction_tokens\": 0\n",
      "            }\n",
      "          },\n",
      "          \"system_fingerprint\": \"fp_d8864f8b6b\"\n",
      "        },\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"name\": \"question\",\n",
      "            \"args\": {\n",
      "              \"content\": \"Could you please provide more details about the email content, such as the sender's email address, any proposed times for the call, and any specific topics or deadlines mentioned? This will help me assist you better in scheduling the call and drafting a response.\"\n",
      "            },\n",
      "            \"type\": \"tool_call\",\n",
      "            \"id\": \"call_oGwsrNfD15TqYMQaSqtD9wtL\"\n",
      "          }\n",
      "        ],\n",
      "        \"invalid_tool_calls\": [],\n",
      "        \"usage_metadata\": {\n",
      "          \"output_tokens\": 63,\n",
      "          \"input_tokens\": 968,\n",
      "          \"total_tokens\": 1031,\n",
      "          \"input_token_details\": {\n",
      "            \"audio\": 0,\n",
      "            \"cache_read\": 0\n",
      "          },\n",
      "          \"output_token_details\": {\n",
      "            \"audio\": 0,\n",
      "            \"reasoning\": 0\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      ToolMessage {\n",
      "        \"id\": \"1e209d7c-2660-4e76-8f53-190a1610dd65\",\n",
      "        \"content\": \"The user will see and can answer this question: Could you please provide more details about the email content, such as the sender's email address, any proposed times for the call, and any specific topics or deadlines mentioned? This will help me assist you better in scheduling the call and drafting a response.\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {},\n",
      "        \"tool_call_id\": \"call_oGwsrNfD15TqYMQaSqtD9wtL\"\n",
      "      },\n",
      "      AIMessage {\n",
      "        \"id\": \"chatcmpl-BWVQ9urPHicuuT0gpfowznsnY7hJ1\",\n",
      "        \"content\": \"Could you please provide more details about the email content, such as the sender's email address, any proposed times for the call, and any specific topics or deadlines mentioned? This will help me assist you better in scheduling the call and drafting a response.\",\n",
      "        \"additional_kwargs\": {},\n",
      "        \"response_metadata\": {\n",
      "          \"tokenUsage\": {\n",
      "            \"promptTokens\": 1097,\n",
      "            \"completionTokens\": 52,\n",
      "            \"totalTokens\": 1149\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "          \"usage\": {\n",
      "            \"prompt_tokens\": 1097,\n",
      "            \"completion_tokens\": 52,\n",
      "            \"total_tokens\": 1149,\n",
      "            \"prompt_tokens_details\": {\n",
      "              \"cached_tokens\": 1024,\n",
      "              \"audio_tokens\": 0\n",
      "            },\n",
      "            \"completion_tokens_details\": {\n",
      "              \"reasoning_tokens\": 0,\n",
      "              \"audio_tokens\": 0,\n",
      "              \"accepted_prediction_tokens\": 0,\n",
      "              \"rejected_prediction_tokens\": 0\n",
      "            }\n",
      "          },\n",
      "          \"system_fingerprint\": \"fp_d8864f8b6b\"\n",
      "        },\n",
      "        \"tool_calls\": [],\n",
      "        \"invalid_tool_calls\": [],\n",
      "        \"usage_metadata\": {\n",
      "          \"output_tokens\": 52,\n",
      "          \"input_tokens\": 1097,\n",
      "          \"total_tokens\": 1149,\n",
      "          \"input_token_details\": {\n",
      "            \"audio\": 0,\n",
      "            \"cache_read\": 1024\n",
      "          },\n",
      "          \"output_token_details\": {\n",
      "            \"audio\": 0,\n",
      "            \"reasoning\": 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    email_input: {\n",
      "      to: 'Lance Martin <lance@company.com>',\n",
      "      author: 'Project Manager <pm@client.com>',\n",
      "      subject: \"Tax season let's schedule call\",\n",
      "      email_thread: 'Lance,\\n' +\n",
      "        '\\n' +\n",
      "        \"It's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\" +\n",
      "        '\\n' +\n",
      "        'Are you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n' +\n",
      "        '\\n' +\n",
      "        'Regards,\\n' +\n",
      "        'Project Manager'\n",
      "    },\n",
      "    classification_decision: 'respond'\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "import { interrupt } from \"@langchain/langgraph\";\n",
    "\n",
    "// Email to respond to\n",
    "const emailInputRespond = {\n",
    "    to: \"Lance Martin <lance@company.com>\",\n",
    "    author: \"Project Manager <pm@client.com>\",\n",
    "    subject: \"Tax season let's schedule call\",\n",
    "    email_thread: `Lance,\n",
    "\n",
    "It's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\n",
    "\n",
    "Are you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\n",
    "\n",
    "Regards,\n",
    "Project Manager`\n",
    "};\n",
    "\n",
    "// Compile the agent subgraph first\n",
    "const responseAgent = agentBuilder.compile();\n",
    "\n",
    "// Now build the overall workflow graph\n",
    "const overallWorkflow = new StateGraph(EmailAgentState)\n",
    "    .addNode(\"triage_router\", triageRouter)\n",
    "    .addNode(\"triage_interrupt_handler\", triageInterruptHandler)\n",
    "    .addNode(\"response_agent\", responseAgent)\n",
    "    .addEdge(START, \"triage_router\")\n",
    "    .addConditionalEdges(\n",
    "        \"triage_router\",\n",
    "        (state) => {\n",
    "            const classification = state.classification_decision;\n",
    "            if (classification === \"respond\") {\n",
    "                return \"response_agent\";\n",
    "            } else if (classification === \"notify\") {\n",
    "                return \"triage_interrupt_handler\";\n",
    "            } else {\n",
    "                return END;\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .addConditionalEdges(\n",
    "        \"triage_interrupt_handler\",\n",
    "        (state) => {\n",
    "            const messages = state.messages;\n",
    "            if (!messages || messages.length === 0) return END;\n",
    "            const lastMessage = messages[messages.length - 1];\n",
    "            // Use getType() for message type check\n",
    "            if (\n",
    "                lastMessage.getType() === \"human\" &&\n",
    "                typeof lastMessage.content === \"string\" &&\n",
    "                lastMessage.content.includes(\"User wants to reply to the email\")\n",
    "            ) {\n",
    "                return \"response_agent\";\n",
    "            }\n",
    "            return END;\n",
    "        }\n",
    "    )\n",
    "    .addEdge(\"response_agent\", END);\n",
    "\n",
    "// Compile the graph \n",
    "const graph = overallWorkflow.compile();\n",
    "const threadId1 = uuidv4();\n",
    "const threadConfig1 = { configurable: { thread_id: threadId1 } };\n",
    "\n",
    "// Run the graph until a tool call that we choose to interrupt\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "for await (const chunk of await graph.stream({ email_input: emailInputRespond }, threadConfig1)) {\n",
    "    console.log(chunk)\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546ad46",
   "metadata": {},
   "source": [
    "What happened? In our agent loop, we added a simple LangGraph [interrupt](https://langchain-ai.github.io/langgraphjs/concepts/human_in_the_loop/) (see also [how to wait for user input](https://langchain-ai.github.io/langgraphjs/how-tos/human_in_the_loop/wait-user-input/)), which allows us to pause execution of an agent at a specific point in the code. The interrupt allowed us to pass through the tool call for the user to review!\n",
    "\n",
    "\n",
    "```typescript\n",
    "import { interrupt } from \"@langchain/langgraph\";\n",
    "\n",
    "const feedback = interrupt.invoke(myToolCall); \n",
    "```\n",
    "\n",
    "You can see the `action` (tool call name) and `args` (tool call arguments) that we want to interrupt. Now, how do we handle the interrupt? This is where the `Command` interface comes in . [The `Command` object in LangGraph has several powerful capabilities](https://langchain-ai.github.io/langgraphjs/how-tos/command/). Previously we saw it used to direct the flow of the graph: \n",
    "- `goto`: Specifies which node to route to next\n",
    "- `update`: Modifies the state before continuing execution\n",
    "\n",
    "Here, we'll use a similar concept to resume the graph from the interrupted state:\n",
    "- `resume` : Provides the value to return from the interrupt call\n",
    "\n",
    "We can return whatever value our graph is designed to handle. In our case, the graph is designed to handle a list of objects with a single key `type` that can be `accept`, `edit`, `ignore`, or `response`. So, we can simply pass `{ type: \"accept\" }` to the resume mechanism in order to tell the graph that we accept the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b1f772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    }
   ],
   "source": [
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "import { Command } from \"@langchain/langgraph\";\n",
    "\n",
    "// Run the graph until a tool call that we choose to interrupt\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "for await (const chunk of await graph.stream({ email_input: emailInputRespond }, threadConfig1)) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "\n",
    "        // Example: Simulate user accepting the tool call\n",
    "        await graph.invoke(\n",
    "            new Command({ resume: [{ type: \"accept\" }] }),\n",
    "            threadConfig1\n",
    "        );\n",
    "        break; // Stop after first interrupt for demonstration\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77baa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promise {\n",
      "  <pending>,\n",
      "  [Symbol(async_id_symbol)]: 35611,\n",
      "  [Symbol(trigger_async_id_symbol)]: 35601,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UnhandledPromiseRejection: GraphValueError: No checkpointer set\n",
      "    at CompiledStateGraph.getState (/Users/dylan/Desktop/agents-from-scratch-ts/node_modules/.pnpm/@langchain+langgraph@0.2.71_@langchain+core@0.3.50_openai@4.96.2_zod@3.24.3___zod-to-json-schema@3.24.5_zod@3.24.3_/node_modules/@langchain/langgraph/dist/pregel/index.cjs:654:19)\n",
      "    at evalmachine.<anonymous>:4:39\n",
      "    at evalmachine.<anonymous>:14:3\n",
      "    at evalmachine.<anonymous>:16:3\n",
      "    at sigintHandlersWrap (node:vm:280:12)\n",
      "    at Script.runInThisContext (node:vm:135:14)\n",
      "    at Object.runInThisContext (node:vm:317:38)\n",
      "    at Object.execute (/Users/dylan/Desktop/agents-from-scratch-ts/node_modules/.pnpm/tslab@1.0.22/node_modules/tslab/dist/executor.js:160:38)\n",
      "    at JupyterHandlerImpl.handleExecuteImpl (/Users/dylan/Desktop/agents-from-scratch-ts/node_modules/.pnpm/tslab@1.0.22/node_modules/tslab/dist/jupyter.js:250:38)\n",
      "    at /Users/dylan/Desktop/agents-from-scratch-ts/node_modules/.pnpm/tslab@1.0.22/node_modules/tslab/dist/jupyter.js:208:57 {\n",
      "  lc_error_code: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "(async () => {\n",
    "  const state = await graph.getState(threadConfig1);\n",
    "  const messages = state.values.messages;\n",
    "  if (Array.isArray(messages)) {\n",
    "      for (const m of messages) {\n",
    "          console.log(m);\n",
    "      }\n",
    "  } else {\n",
    "      console.log(\"No messages found in state:\", messages);\n",
    "  }\n",
    "})();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b1ba30",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Edit `write_email` and `schedule_meeting`\n",
    "\n",
    "This test demonstrates how human modification works in the HITL flow:\n",
    "1. We start with the same tax planning email as before\n",
    "2. The agent proposes a meeting with the same parameters\n",
    "3. This time, the user EDITS the meeting proposal to change:\n",
    "   - Duration from 45 to 30 minutes\n",
    "   - Meeting subject is made more concise\n",
    "4. The agent adapts to these changes when drafting the email\n",
    "5. The user further EDITS the email to be shorter and less formal\n",
    "6. The workflow completes with both modifications incorporated\n",
    "\n",
    "This scenario showcases one of the most powerful aspects of HITL: \n",
    "\n",
    "* Users can make precise modifications to agent actions before they are executed, ensuring the final outcome matches their preferences without having to handle all the details themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bfca1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    }
   ],
   "source": [
    "// Email to respond to\n",
    "const emailInputRespond = {\n",
    "  to: \"Lance Martin <lance@company.com>\",\n",
    "  author: \"Project Manager <pm@client.com>\",\n",
    "  subject: \"Tax season let's schedule call\",\n",
    "  email_thread: `Lance,\n",
    "\n",
    "It's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\n",
    "\n",
    "Are you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\n",
    "\n",
    "Regards,\n",
    "Project Manager`\n",
    "};\n",
    "\n",
    "// Compile the graph with new thread\n",
    "const graph = overallWorkflow.compile();\n",
    "const threadId2 = uuidv4();\n",
    "const threadConfig2 = { configurable: { thread_id: threadId2 } };\n",
    "\n",
    "// Run the graph until the first interrupt \n",
    "// will be classified as \"respond\" and the agent will create a write_email tool call\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "for await (const chunk of await graph.stream({ email_input: emailInputRespond }, threadConfig2)) {\n",
    "  if (\"__interrupt__\" in chunk) {\n",
    "      const interruptObject = chunk.__interrupt__[0];\n",
    "      console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "      console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ac0a6",
   "metadata": {},
   "source": [
    "Edit the `schedule_meeting` tool call\n",
    "\n",
    "When the agent proposes the initial meeting schedule, we now simulate the user making modifications through the edit functionality. This demonstrates how the `edit` response type works:\n",
    "\n",
    "1. The user receives the same meeting proposal as in the previous test\n",
    "2. Instead of accepting, they modify the parameters:\n",
    "   - Reducing duration from 45 to 30 minutes\n",
    "   - Keeping the same day and time\n",
    "3. The `edit` response includes the complete set of modified arguments\n",
    "4. The interrupt handler replaces the original tool arguments with these edited ones\n",
    "5. The tool is executed with the user's modifications\n",
    "\n",
    "This shows how edit capability gives users precise control over agent actions while still letting the agent handle the execution details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7175fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user editing the schedule_meeting tool call...\n"
     ]
    }
   ],
   "source": [
    "import { MemorySaver } from \"@langchain/langgraph\";\n",
    "\n",
    "const memory = new MemorySaver();\n",
    "const graph = overallWorkflow.compile({ checkpointer: memory });\n",
    "\n",
    "console.log(\"\\nSimulating user editing the schedule_meeting tool call...\");\n",
    "const editedScheduleArgs = {\n",
    "    attendees: [\"pm@client.com\", \"lance@company.com\"],\n",
    "    subject: \"Tax Planning Discussion\",\n",
    "    duration_minutes: 30,\n",
    "    preferred_day: \"2025-05-06\",\n",
    "    start_time: 14,\n",
    "};\n",
    "\n",
    "for await (const chunk of await graph.stream(\n",
    "    new Command({ resume: [{ type: \"edit\", args: { args: editedScheduleArgs } }] }),\n",
    "    threadConfig2\n",
    ")) {\n",
    "    if (chunk.response_agent?.messages) {\n",
    "        // Print the most recent message from the response agent\n",
    "        console.log(chunk.response_agent.messages[chunk.response_agent.messages.length - 1]);\n",
    "    }\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757706b",
   "metadata": {},
   "source": [
    "Edit the `write_email` tool call\n",
    "\n",
    "After accepting the modified meeting schedule, the agent drafts an email reflecting the 30-minute duration. Now we demonstrate how editing works with email content:\n",
    "\n",
    "1. The agent has adapted its email to mention the shorter 30-minute duration\n",
    "2. We simulate the user wanting an even more significant change to the email:\n",
    "   - Completely rewriting the content to be shorter and less formal\n",
    "   - Changing the meeting day mentioned in the email (showing how users can correct agent mistakes)\n",
    "   - Requesting confirmation rather than stating the meeting as definite\n",
    "3. The `edit` response contains the complete new email content\n",
    "4. The tool arguments are updated with this edited content\n",
    "5. The email is sent with the user's preferred wording\n",
    "\n",
    "This example shows the power of HITL for complex communication tasks - the agent handles the structure and initial content, while humans can refine tone, style, and substance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0604d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user editing the write_email tool call...\n"
     ]
    }
   ],
   "source": [
    "console.log(\"\\nSimulating user editing the write_email tool call...\");\n",
    "const editedEmailArgs = {\n",
    "    to: \"pm@client.com\",\n",
    "    subject: \"Re: Tax season let's schedule call\",\n",
    "    content: `Hello Project Manager,\n",
    "\n",
    "Thank you for reaching out about tax planning. I scheduled a 30-minute call next Thursday at 3:00 PM. Would that work for you?\n",
    "\n",
    "Best regards,\n",
    "Lance Martin`\n",
    "};\n",
    "\n",
    "for await (const chunk of await graph.stream(\n",
    "    new Command({ resume: [{ type: \"edit\", args: { args: editedEmailArgs } }] }),\n",
    "    threadConfig2\n",
    ")) {\n",
    "    if (chunk.response_agent?.messages) {\n",
    "        console.log(chunk.response_agent.messages[chunk.response_agent.messages.length - 1]);\n",
    "    }\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac279101",
   "metadata": {},
   "source": [
    "Look at the full message history, and see trace, to view the edited tool calls:\n",
    "\n",
    "https://smith.langchain.com/public/21769510-d57a-41e4-b5c7-0ddb23c237d8/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d3e9be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promise {\n",
      "  <pending>,\n",
      "  [Symbol(async_id_symbol)]: 42559,\n",
      "  [Symbol(trigger_async_id_symbol)]: 42549,\n",
      "  [Symbol(kResourceStore)]: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "(async () => {\n",
    "  const state = await graph.getState(threadConfig2);\n",
    "  for (const m of state.values.messages) {\n",
    "    console.log(m);\n",
    "  }\n",
    "})();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c39e9",
   "metadata": {},
   "source": [
    "### Respond (with feedback) `write_email`, `schedule_meeting`, and `question`\n",
    "\n",
    "This test set demonstrates the \"response\" capability - providing feedback without editing or accepting:\n",
    "\n",
    "1. First, we test feedback for meeting scheduling:\n",
    "   - The user provides specific preferences (30 minutes instead of 45, and afternoon meetings)\n",
    "   - The agent incorporates this feedback into a revised proposal\n",
    "   - The user then accepts the revised meeting schedule\n",
    "\n",
    "2. Second, we test feedback for email drafting:\n",
    "   - The user requests a shorter, less formal email with a specific closing statement\n",
    "   - The agent completely rewrites the email according to this guidance\n",
    "   - The user accepts the new draft\n",
    "\n",
    "3. Lastly, we test feedback for questions:\n",
    "   - For the brunch invitation, the user answers the question with additional context\n",
    "   - The agent uses this information to draft an appropriate email response\n",
    "   - The workflow proceeds with the user's input integrated\n",
    "\n",
    "The \"response\" capability bridges the gap between acceptance and editing - users can guide the agent without having to write the full content themselves. This is especially powerful for:\n",
    "- Adjusting tone and style\n",
    "- Adding context the agent missed\n",
    "- Redirecting the agent's approach\n",
    "- Answering questions in a way that shapes the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c4b3517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    }
   ],
   "source": [
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "import { MemorySaver } from \"@langchain/langgraph\";\n",
    "\n",
    "// Respond - Meeting Request Email\n",
    "const emailInputRespond = {\n",
    "    to: \"Lance Martin <lance@company.com>\",\n",
    "    author: \"Project Manager <pm@client.com>\",\n",
    "    subject: \"Tax season let's schedule call\",\n",
    "    email_thread: `Lance,\n",
    "\n",
    "It's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\n",
    "\n",
    "Are you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\n",
    "\n",
    "Regards,\n",
    "Project Manager`\n",
    "};\n",
    "\n",
    "// Compile the graph\n",
    "const checkpointer = new MemorySaver();\n",
    "const graph = overallWorkflow.compile({ checkpointer });\n",
    "const threadId5 = uuidv4();\n",
    "const threadConfig5 = { configurable: { thread_id: threadId5 } };\n",
    "\n",
    "// Run the graph until the first interrupt\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "for await (const chunk of await graph.stream({ email_input: emailInputRespond }, threadConfig5)) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2bea0a",
   "metadata": {},
   "source": [
    "Provide feedback for the `schedule_meeting` tool call\n",
    "\n",
    "Now we explore the feedback capability for meeting scheduling:\n",
    "\n",
    "1. The agent proposes the standard 45-minute meeting on Tuesday at 2:00 PM\n",
    "2. Instead of accepting or editing, we provide feedback in natural language\n",
    "3. Our feedback specifies two preferences:\n",
    "   - Shorter meeting (30 minutes instead of 45)\n",
    "   - Preference for afternoon meetings (after 2pm)\n",
    "4. The agent receives this feedback through the `response` type\n",
    "5. The interrupt handler adds this feedback as a message to the state\n",
    "6. The agent processes this feedback and generates a new tool call incorporating these preferences\n",
    "\n",
    "Unlike direct editing, which requires specifying the entire set of parameters, feedback allows users to express their preferences conversationally. The agent must then interpret this feedback and apply it appropriately to create a revised proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a916e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user providing feedback for the schedule_meeting tool call...\n"
     ]
    }
   ],
   "source": [
    "console.log(\"\\nSimulating user providing feedback for the schedule_meeting tool call...\");\n",
    "for await (const chunk of await graph.stream(\n",
    "    new Command({\n",
    "        resume: [\n",
    "            {\n",
    "                type: \"response\",\n",
    "                args: \"Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\"\n",
    "            }\n",
    "        ]\n",
    "    }),\n",
    "    threadConfig2\n",
    ")) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35f1a2",
   "metadata": {},
   "source": [
    "Accept the `schedule_meeting` tool call after providing feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2727fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user providing feedback for the schedule_meeting tool call...\n"
     ]
    }
   ],
   "source": [
    "console.log(\"\\nSimulating user providing feedback for the schedule_meeting tool call...\");\n",
    "for await (const chunk of await graph.stream(\n",
    "    new Command({\n",
    "        resume: [\n",
    "            {\n",
    "                type: \"response\",\n",
    "                args: \"Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\"\n",
    "            }\n",
    "        ]\n",
    "    }),\n",
    "    threadConfig2\n",
    ")) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca470c5",
   "metadata": {},
   "source": [
    "Now provide feedback for the `write_email` tool call\n",
    "\n",
    "After accepting the revised meeting schedule, the agent drafts an email. We now test feedback for email content:\n",
    "\n",
    "1. The agent's email is relatively formal and detailed\n",
    "2. We provide stylistic feedback requesting:\n",
    "   - A shorter, more concise email\n",
    "   - A less formal tone\n",
    "   - A specific closing statement about looking forward to the meeting\n",
    "3. The agent processes this feedback to completely rewrite the email\n",
    "4. The new draft is much shorter, more casual, and includes the requested closing\n",
    "\n",
    "This demonstrates the power of natural language feedback for content creation:\n",
    "- Users don't need to rewrite the entire email themselves\n",
    "- They can provide high-level guidance on style, tone, and content\n",
    "- The agent handles the actual writing based on this guidance\n",
    "- The result better matches user preferences while preserving the essential information\n",
    "\n",
    "The message history shows both the original and revised emails, clearly showing how the feedback was incorporated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5221d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user providing feedback for the write_email tool call...\n"
     ]
    }
   ],
   "source": [
    "console.log(\"\\nSimulating user providing feedback for the write_email tool call...\");\n",
    "for await (const chunk of await graph.stream(\n",
    "    new Command({\n",
    "        resume: [\n",
    "            {\n",
    "                type: \"response\",\n",
    "                args: \"Shorter and less formal. Include a closing statement about looking forward to the meeting!\"\n",
    "            }\n",
    "        ]\n",
    "    }),\n",
    "    threadConfig2\n",
    ")) {\n",
    "    if (chunk.response_agent?.messages) {\n",
    "        console.log(chunk.response_agent.messages[chunk.response_agent.messages.length - 1]);\n",
    "    }\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266ec72",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call after providing feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b4698c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user accepting the tool call...\n"
     ]
    }
   ],
   "source": [
    "// Simulate user accepting the write_email tool call after providing feedback\n",
    "console.log(`\\nSimulating user accepting the tool call...`);\n",
    "\n",
    "const stream = await graph.stream(\n",
    "    new Command({ resume: [{ type: \"accept\" }] }),\n",
    "    threadConfig2\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270f52a",
   "metadata": {},
   "source": [
    "Look at the full message history, and see the trace:\n",
    "\n",
    "https://smith.langchain.com/public/57006770-6bb3-4e40-b990-143c373ebe60/r\n",
    "\n",
    "We can see that user feedback in incorporated into the tool calls.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1daf10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "const stateAfterFeedback = await graph.getState(threadConfig2);\n",
    "for (const m of stateAfterFeedback.values.messages) {\n",
    "  console.log(m);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d964e36",
   "metadata": {},
   "source": [
    "Now let's try an email that calls the `Question` tool to provide feedback\n",
    "\n",
    "Finally, we test how feedback works with the `Question` tool:\n",
    "\n",
    "1. For the brunch invitation email, the agent asks about preferred day and time\n",
    "2. Instead of ignoring, we provide a substantive response with additional context:\n",
    "   - Confirming we want to invite the people mentioned\n",
    "   - Noting we need to check which weekend works best\n",
    "   - Adding information about needing a reservation\n",
    "3. The agent uses this information to:\n",
    "   - Draft a comprehensive email response incorporating all our feedback\n",
    "   - Notice we didn't provide a specific day/time, so it suggests checking the calendar\n",
    "   - Include the detail about making a reservation\n",
    "4. The complete email reflects both the original request and our additional guidance\n",
    "\n",
    "This demonstrates how question responses can shape the entire workflow:\n",
    "- Questions let the agent gather missing information\n",
    "- User responses can include both direct answers and additional context\n",
    "- The agent integrates all this information into its next actions\n",
    "- The final outcome reflects the collaborative intelligence of both human and AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8827632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    }
   ],
   "source": [
    "// Respond to a Question tool call (e.g., brunch invitation)\n",
    "const emailInputBrunch = {\n",
    "  to: \"Lance Martin <lance@company.com>\",\n",
    "  author: \"Partner <partner@home.com>\",\n",
    "  subject: \"Dinner?\",\n",
    "  email_thread: \"Hey, do you want italian or indian tonight?\"\n",
    "};\n",
    "\n",
    "const threadId3 = uuidv4();\n",
    "const threadConfig3 = { configurable: { thread_id: threadId3 } };\n",
    "\n",
    "console.log(\"Running the graph until the first interrupt...\");\n",
    "\n",
    "// Await the stream if necessary (if graph.stream returns a Promise)\n",
    "const stream = await graph.stream({ email_input: emailInputBrunch }, threadConfig3);\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "  if (\"__interrupt__\" in chunk) {\n",
    "      const interruptObject = chunk.__interrupt__[0];\n",
    "      console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "      console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f7f1b",
   "metadata": {},
   "source": [
    "Provide feedback for the `Question` tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4979effd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user providing feedback for the Question tool call...\n"
     ]
    }
   ],
   "source": [
    "// Simulate user providing feedback for the Question tool call\n",
    "console.log(\"\\nSimulating user providing feedback for the Question tool call...\");\n",
    "\n",
    "const stream = await graph.stream(\n",
    "    new Command({\n",
    "        resume: [\n",
    "            {\n",
    "                type: \"response\",\n",
    "                args: \"Let's do indian.\"\n",
    "            }\n",
    "        ]\n",
    "    }),\n",
    "    threadConfig3 // <-- pass directly, not wrapped in { config: ... }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4ba9b",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfd34ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user accepting the write_email tool call...\n"
     ]
    }
   ],
   "source": [
    "// Simulate user accepting the write_email tool call after Question\n",
    "console.log(\"\\nSimulating user accepting the write_email tool call...\");\n",
    "\n",
    "const stream = await graph.stream(\n",
    "    new Command({ resume: [{ type: \"accept\" }] }),\n",
    "    threadConfig3 // <-- pass directly, not wrapped in { config: ... }\n",
    ");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    if (chunk.response_agent?.messages) {\n",
    "        console.log(chunk.response_agent.messages[chunk.response_agent.messages.length - 1]);\n",
    "    }\n",
    "    if (\"__interrupt__\" in chunk) {\n",
    "        const interruptObject = chunk.__interrupt__[0];\n",
    "        console.log(\"\\nINTERRUPT OBJECT:\");\n",
    "        console.log(`Action Request: ${JSON.stringify(interruptObject.value[0].action_request)}`);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214fe9e",
   "metadata": {},
   "source": [
    "Look at the full message history, and see the trace:\n",
    "\n",
    "https://smith.langchain.com/public/f4c727c3-b1d9-47a5-b3d0-3451619db8a2/r\n",
    "\n",
    "We can see that user feedback in incorporated into the email response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "070393eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TypeError: m.prettyPrint is not a function\n",
      "    at evalmachine.<anonymous>:5:59\n",
      "    at Array.forEach (<anonymous>)\n",
      "    at evalmachine.<anonymous>:5:44\n",
      "    at async Object.execute (/Users/dylan/Desktop/agents-from-scratch-ts/node_modules/.pnpm/tslab@1.0.22/node_modules/tslab/dist/executor.js:173:17)\n",
      "    at async JupyterHandlerImpl.handleExecuteImpl (/Users/dylan/Desktop/agents-from-scratch-ts/node_modules/.pnpm/tslab@1.0.22/node_modules/tslab/dist/jupyter.js:250:18)\n",
      "    at async JupyterHandlerImpl.handleExecute (/Users/dylan/Desktop/agents-from-scratch-ts/node_modules/.pnpm/tslab@1.0.22/node_modules/tslab/dist/jupyter.js:208:21)\n",
      "    at async ZmqServer.handleExecute (/Users/dylan/Desktop/agents-from-scratch-ts/node_modules/.pnpm/tslab@1.0.22/node_modules/tslab/dist/jupyter.js:406:25)\n",
      "    at async ZmqServer.handleShellMessage (/Users/dylan/Desktop/agents-from-scratch-ts/node_modules/.pnpm/tslab@1.0.22/node_modules/tslab/dist/jupyter.js:351:21)\n"
     ]
    }
   ],
   "source": [
    "const state = await graph.getState(threadConfig3);\n",
    "state.values.messages.forEach(m => m.prettyPrint());"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
