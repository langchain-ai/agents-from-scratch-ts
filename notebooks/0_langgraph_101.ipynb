{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc082433",
   "metadata": {},
   "source": [
    "# LangGraph 101 Typescript\n",
    "\n",
    "[LLMs](https://js.langchain.com/docs/modules/models/chat/) make it possible to embed intelligence into a new class of applications. [LangGraph](https://langchain-ai.github.io/langgraphjs/) is a TypeScript/JavaScript framework to help build applications with LLMs. Here, we will overview the basics of LangGraph, explain its benefits, show how to use it to build workflows and agents, and show how it works with [LangChain JS](https://js.langchain.com/) and [LangSmith](https://smith.langchain.com/).\n",
    "\n",
    "![ecosystem](img/ecosystem.png)\n",
    "\n",
    "## Chat models\n",
    "\n",
    "[Chat models](https://js.langchain.com/docs/modules/models/chat/) are the foundation of LLM applications. In TypeScript, chat models are accessed via standardized interfaces that take an array of message objects and return a response message. LangChain JS provides [a unified interface for chat models](https://js.langchain.com/docs/modules/models/chat/), making it easy to [access many different providers](https://js.langchain.com/docs/integrations/providers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecc2b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "// LLM Initialization\n",
    "// Set your OpenAI API key in your environment or .env file\n",
    "const OPENAI_API_KEY = process.env.OPENAI_API_KEY;\n",
    "if (!OPENAI_API_KEY) {\n",
    "  throw new Error(\"OPENAI_API_KEY is not set in the environment.\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0ee8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { StateGraph, START, END, interrupt, Command } from \"@langchain/langgraph\";\n",
    "import { initChatModel } from \"langchain/chat_models/universal\";\n",
    "\n",
    "import \"@langchain/langgraph/zod\";\n",
    "// Initialize the chat model (OpenAI GPT-4.1)\n",
    "const llm = await initChatModel(\"openai:gpt-4.1\", { temperature: 0.0 });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50777b0b",
   "metadata": {},
   "source": [
    "## Running the model\n",
    "\n",
    "The `initChatModel` interface in LangChain JS provides [standardized methods](https://js.langchain.com/docs/concepts/runnables/) for using chat models, which include:\n",
    "- `invoke()`: Synchronously process inputs and return outputs\n",
    "- `stream()`: Return outputs [incrementally](https://js.langchain.com/docs/concepts/streaming/) as they're generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28159d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Run the model\n",
    "const result = await llm.invoke(\"What is LangGraph?\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41137023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result type: AIMessage {\n",
      "  \"id\": \"chatcmpl-BWd6YdKnYeiRESZcxMtnC7wYiKFMb\",\n",
      "  \"content\": \"**LangGraph** is an open-source framework for building stateful, multi-agent applications using Large Language Models (LLMs). It is developed by the creators of LangChain and is designed to help developers orchestrate complex workflows involving multiple LLM agents that can interact, share memory, and make decisions based on the evolving state of a conversation or process.\\n\\n### Key Features of LangGraph\\n\\n- **Stateful Workflows:** Unlike simple chains or pipelines, LangGraph allows you to define and manage the state throughout the execution of your application, enabling more complex and context-aware interactions.\\n- **Multi-Agent Collaboration:** You can define multiple agents (each powered by an LLM or other logic) that can communicate, collaborate, and make decisions together.\\n- **Graph-Based Architecture:** Workflows are defined as graphs, where nodes represent agents or functions, and edges represent possible transitions based on the current state.\\n- **Integration with LangChain:** LangGraph is built to work seamlessly with LangChain, leveraging its tools, memory, and agent abstractions.\\n- **Open Source:** LangGraph is available on GitHub and can be freely used and extended.\\n\\n### Example Use Cases\\n\\n- **Conversational AI:** Multi-turn, multi-agent chatbots where different agents handle different topics or tasks.\\n- **Automated Workflows:** Complex business processes that require decision-making and coordination between multiple AI agents.\\n- **Research Agents:** Systems where multiple LLMs collaborate to gather, analyze, and synthesize information.\\n\\n### How Does It Work?\\n\\nYou define a **state** (the information shared between agents), a set of **nodes** (agents or functions), and **edges** (rules for transitioning between nodes based on the state). LangGraph then executes the workflow, updating the state and routing control between agents as defined by your graph.\\n\\n### Resources\\n\\n- [LangGraph GitHub Repository](https://github.com/langchain-ai/langgraph)\\n- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\\n\\n---\\n\\n**In summary:**  \\nLangGraph is a framework for building advanced, stateful, multi-agent LLM applications using a graph-based approach, enabling more sophisticated and collaborative AI systems than simple chains or single-agent models.\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 12,\n",
      "      \"completionTokens\": 447,\n",
      "      \"totalTokens\": 459\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4.1-2025-04-14\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 12,\n",
      "      \"completion_tokens\": 447,\n",
      "      \"total_tokens\": 459,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b38e740b47\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 447,\n",
      "    \"input_tokens\": 12,\n",
      "    \"total_tokens\": 459,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Check the result state\n",
    "console.log(\"Result type:\", result); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1d00eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BWd6YdKnYeiRESZcxMtnC7wYiKFMb\",\n",
      "  \"content\": \"**LangGraph** is an open-source framework for building stateful, multi-agent applications using Large Language Models (LLMs). It is developed by the creators of LangChain and is designed to help developers orchestrate complex workflows involving multiple LLM agents that can interact, share memory, and make decisions based on the evolving state of a conversation or process.\\n\\n### Key Features of LangGraph\\n\\n- **Stateful Workflows:** Unlike simple chains or pipelines, LangGraph allows you to define and manage the state throughout the execution of your application, enabling more complex and context-aware interactions.\\n- **Multi-Agent Collaboration:** You can define multiple agents (each powered by an LLM or other logic) that can communicate, collaborate, and make decisions together.\\n- **Graph-Based Architecture:** Workflows are defined as graphs, where nodes represent agents or functions, and edges represent possible transitions based on the current state.\\n- **Integration with LangChain:** LangGraph is built to work seamlessly with LangChain, leveraging its tools, memory, and agent abstractions.\\n- **Open Source:** LangGraph is available on GitHub and can be freely used and extended.\\n\\n### Example Use Cases\\n\\n- **Conversational AI:** Multi-turn, multi-agent chatbots where different agents handle different topics or tasks.\\n- **Automated Workflows:** Complex business processes that require decision-making and coordination between multiple AI agents.\\n- **Research Agents:** Systems where multiple LLMs collaborate to gather, analyze, and synthesize information.\\n\\n### How Does It Work?\\n\\nYou define a **state** (the information shared between agents), a set of **nodes** (agents or functions), and **edges** (rules for transitioning between nodes based on the state). LangGraph then executes the workflow, updating the state and routing control between agents as defined by your graph.\\n\\n### Resources\\n\\n- [LangGraph GitHub Repository](https://github.com/langchain-ai/langgraph)\\n- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\\n\\n---\\n\\n**In summary:**  \\nLangGraph is a framework for building advanced, stateful, multi-agent LLM applications using a graph-based approach, enabling more sophisticated and collaborative AI systems than simple chains or single-agent models.\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 12,\n",
      "      \"completionTokens\": 447,\n",
      "      \"totalTokens\": 459\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4.1-2025-04-14\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 12,\n",
      "      \"completion_tokens\": 447,\n",
      "      \"total_tokens\": 459,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b38e740b47\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 447,\n",
      "    \"input_tokens\": 12,\n",
      "    \"total_tokens\": 459,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Print the result content\n",
    "console.log(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bc6518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**LangGraph** is an open-source framework for building stateful, multi-agent applications using Large Language Models (LLMs). It is developed by the creators of LangChain and is designed to help developers orchestrate complex workflows involving multiple LLM agents that can interact, share memory, and make decisions based on the evolving state of a conversation or process.\n",
      "\n",
      "### Key Features of LangGraph\n",
      "\n",
      "- **Stateful Workflows:** Unlike simple chains or pipelines, LangGraph allows you to define and manage the state throughout the execution of your application, enabling more complex and context-aware interactions.\n",
      "- **Multi-Agent Collaboration:** You can define multiple agents (each powered by an LLM or other logic) that can communicate, collaborate, and make decisions together.\n",
      "- **Graph-Based Architecture:** Workflows are defined as graphs, where nodes represent agents or functions, and edges represent possible transitions based on the current state.\n",
      "- **Integration with LangChain:** LangGraph is built to work seamlessly with LangChain, leveraging its tools, memory, and agent abstractions.\n",
      "- **Open Source:** LangGraph is available on GitHub and can be freely used and extended.\n",
      "\n",
      "### Example Use Cases\n",
      "\n",
      "- **Conversational AI:** Multi-turn, multi-agent chatbots where different agents handle different topics or tasks.\n",
      "- **Automated Workflows:** Complex business processes that require decision-making and coordination between multiple AI agents.\n",
      "- **Research Agents:** Systems where multiple LLMs collaborate to gather, analyze, and synthesize information.\n",
      "\n",
      "### How Does It Work?\n",
      "\n",
      "You define a **state** (the information shared between agents), a set of **nodes** (agents or functions), and **edges** (rules for transitioning between nodes based on the state). LangGraph then executes the workflow, updating the state and routing control between agents as defined by your graph.\n",
      "\n",
      "### Resources\n",
      "\n",
      "- [LangGraph GitHub Repository](https://github.com/langchain-ai/langgraph)\n",
      "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
      "\n",
      "---\n",
      "\n",
      "**In summary:**  \n",
      "LangGraph is a framework for building advanced, stateful, multi-agent LLM applications using a graph-based approach, enabling more sophisticated and collaborative AI systems than simple chains or single-agent models.\n"
     ]
    }
   ],
   "source": [
    "// Extract the result content\n",
    "console.log(result.content);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24d8ef",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "[Tools](https://js.langchain.com/docs/concepts/tools/) are utilities that can be called by a chat model. In LangChain JS, you create tools using the `tool` function from `@langchain/core/tools`, often with Zod schemas for runtime validation. This approach automatically infers the tool's name, description, and expected arguments from the function definition. You can also use [Model Context Protocol (MCP) servers](https://github.com/langchain-ai/langchain-mcp-adapters) as LangChain-compatible tools in TypeScript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afdff275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "// Define the write_email tool using LangChain's tool function and Zod for validation\n",
    " const writeEmail = tool(async ({ to, subject, content }) => {\n",
    "  // Placeholder response - in real app would send email\n",
    "  return `Email sent to ${to} with subject '${subject}' and content: ${content}`;\n",
    "},{\n",
    "  name: \"write_email\",\n",
    "  description: \"Write and send an email.\",\n",
    "  schema: z.object({\n",
    "    to: z.string(),\n",
    "    subject: z.string(),\n",
    "    content: z.string(),\n",
    "  }),\n",
    "  \n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c52ec55b-0b60-4b0c-95d4-ff528a64694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool type: DynamicStructuredTool {\n",
      "  lc_serializable: false,\n",
      "  lc_kwargs: {\n",
      "    name: 'write_email',\n",
      "    description: 'Write and send an email.',\n",
      "    schema: ZodObject {\n",
      "      spa: [Function: bound safeParseAsync] AsyncFunction,\n",
      "      _def: [Object],\n",
      "      parse: [Function: bound parse],\n",
      "      safeParse: [Function: bound safeParse],\n",
      "      parseAsync: [Function: bound parseAsync] AsyncFunction,\n",
      "      safeParseAsync: [Function: bound safeParseAsync] AsyncFunction,\n",
      "      refine: [Function: bound refine],\n",
      "      refinement: [Function: bound refinement],\n",
      "      superRefine: [Function: bound superRefine],\n",
      "      optional: [Function: bound optional],\n",
      "      nullable: [Function: bound nullable],\n",
      "      nullish: [Function: bound nullish],\n",
      "      array: [Function: bound array],\n",
      "      promise: [Function: bound promise],\n",
      "      or: [Function: bound or],\n",
      "      and: [Function: bound and],\n",
      "      transform: [Function: bound transform],\n",
      "      brand: [Function: bound brand],\n",
      "      default: [Function: bound default],\n",
      "      catch: [Function: bound catch],\n",
      "      describe: [Function: bound describe],\n",
      "      pipe: [Function: bound pipe],\n",
      "      readonly: [Function: bound readonly],\n",
      "      isNullable: [Function: bound isNullable],\n",
      "      isOptional: [Function: bound isOptional],\n",
      "      '~standard': [Object],\n",
      "      _cached: null,\n",
      "      nonstrict: [Function: passthrough],\n",
      "      augment: [Function: extend]\n",
      "    },\n",
      "    func: [AsyncFunction: func]\n",
      "  },\n",
      "  lc_runnable: true,\n",
      "  name: 'write_email',\n",
      "  verbose: false,\n",
      "  callbacks: undefined,\n",
      "  tags: [],\n",
      "  metadata: {},\n",
      "  returnDirect: false,\n",
      "  verboseParsingErrors: false,\n",
      "  responseFormat: 'content',\n",
      "  description: 'Write and send an email.',\n",
      "  func: [AsyncFunction: func],\n",
      "  schema: ZodObject {\n",
      "    spa: [Function: bound safeParseAsync] AsyncFunction,\n",
      "    _def: {\n",
      "      shape: [Function: shape],\n",
      "      unknownKeys: 'strip',\n",
      "      catchall: [ZodNever],\n",
      "      typeName: 'ZodObject'\n",
      "    },\n",
      "    parse: [Function: bound parse],\n",
      "    safeParse: [Function: bound safeParse],\n",
      "    parseAsync: [Function: bound parseAsync] AsyncFunction,\n",
      "    safeParseAsync: [Function: bound safeParseAsync] AsyncFunction,\n",
      "    refine: [Function: bound refine],\n",
      "    refinement: [Function: bound refinement],\n",
      "    superRefine: [Function: bound superRefine],\n",
      "    optional: [Function: bound optional],\n",
      "    nullable: [Function: bound nullable],\n",
      "    nullish: [Function: bound nullish],\n",
      "    array: [Function: bound array],\n",
      "    promise: [Function: bound promise],\n",
      "    or: [Function: bound or],\n",
      "    and: [Function: bound and],\n",
      "    transform: [Function: bound transform],\n",
      "    brand: [Function: bound brand],\n",
      "    default: [Function: bound default],\n",
      "    catch: [Function: bound catch],\n",
      "    describe: [Function: bound describe],\n",
      "    pipe: [Function: bound pipe],\n",
      "    readonly: [Function: bound readonly],\n",
      "    isNullable: [Function: bound isNullable],\n",
      "    isOptional: [Function: bound isOptional],\n",
      "    '~standard': { version: 1, vendor: 'zod', validate: [Function: validate] },\n",
      "    _cached: null,\n",
      "    nonstrict: [Function: passthrough],\n",
      "    augment: [Function: extend]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Check the tool type\n",
    "console.log(\"Tool type:\", writeEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e625fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writeEmail argument names: [ 'to', 'subject', 'content' ]\n"
     ]
    }
   ],
   "source": [
    "// Log the argument names of the writeEmail tool\n",
    "console.log(\"writeEmail argument names:\", Object.keys(writeEmail.schema.shape));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abd85ae4-9d4c-4efa-9577-aca96e9f22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool description: Write and send an email.\n"
     ]
    }
   ],
   "source": [
    "// Tool description\n",
    "console.log(\"Tool description:\", writeEmail.description);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6b427",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "Tools can be [called](https://js.langchain.com/docs/concepts/tool-calling/) by LLMs. When a tool is bound to the model, the model can choose to call the tool by returning a structured output with tool arguments. In TypeScript, use the `bindTools` method to augment an LLM with tools.\n",
    "\n",
    "![tool-img](img/tool_call_detail.png)\n",
    "\n",
    "You can use the [`toolChoice` parameter](https://js.langchain.com/docs/how_to/tool_choice/) to enforce tool calling behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfa57bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  to: \"[Your Boss's Email]\",\n",
      "  subject: \"Re: Tomorrow's Meeting\",\n",
      "  content: \"Dear [Boss's Name],\\n\" +\n",
      "    '\\n' +\n",
      "    \"Thank you for the invitation to tomorrow's meeting. I am confirming my attendance and look forward to participating.\\n\" +\n",
      "    '\\n' +\n",
      "    'Please let me know if there is anything specific you would like me to prepare or bring to the meeting.\\n' +\n",
      "    '\\n' +\n",
      "    'Best regards,\\n' +\n",
      "    '[Your Name]'\n",
      "}\n",
      "Email sent to [Your Boss's Email] with subject 'Re: Tomorrow's Meeting' and content: Dear [Boss's Name],\n",
      "\n",
      "Thank you for the invitation to tomorrow's meeting. I am confirming my attendance and look forward to participating.\n",
      "\n",
      "Please let me know if there is anything specific you would like me to prepare or bring to the meeting.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "// Connect tools to a chat model\n",
    "const modelWithTools = llm.bindTools([writeEmail], { toolChoice: \"required\", parallelToolCalls: false });\n",
    "\n",
    "// The model will now be able to call tools\n",
    "const output = await modelWithTools.invoke(\n",
    "  \"Please use the write_email tool to draft a response to my boss about tomorrow's meeting. The email should confirm my attendance and ask if there's anything specific I should prepare.\"\n",
    ");\n",
    "\n",
    "// Extract tool calls and execute them\n",
    "if (output.tool_calls && output.tool_calls.length > 0) {\n",
    "  const args = output.tool_calls[0].args;\n",
    "  // Print the arguments in the desired format\n",
    "  console.log(args);\n",
    " \n",
    "\n",
    "  // Call the tool\n",
    "  const result = await writeEmail.invoke(args);\n",
    "  console.log(result); // e.g. \"Email to boss@company.com drafted with subject 'Re: Meeting Tomorrow'\"\n",
    "} else {\n",
    "  console.log(\"No tool calls found in output.\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9c52a",
   "metadata": {},
   "source": [
    "Above, we enforce tool calling by setting `toolChoice: \"required\"`, so the model will always call a tool to write an email.\n",
    "\n",
    "![basic_prompt](img/tool_call.png)\n",
    "\n",
    "## Workflows\n",
    "\n",
    "There are many patterns for building applications with LLMs.\n",
    "\n",
    "[You can embed LLM calls into pre-defined workflows](https://langchain-ai.github.io/langgraphjs/tutorials/workflows/), giving the system more agency to make decisions.\n",
    "\n",
    "As an example, you could add a router step to determine whether to write an email or not.\n",
    "\n",
    "![workflow_example](img/workflow_example.png)\n",
    "\n",
    "## Agents\n",
    "\n",
    "You can further increase agency, allowing the LLM to dynamically direct its own tool usage.\n",
    "\n",
    "[Agents](https://langchain-ai.github.io/langgraphjs/tutorials/workflows/) are typically implemented as tool calling in a loop, where the output of each tool call is used to inform the next action.\n",
    "\n",
    "![agent_example](img/agent_example.png)\n",
    "\n",
    "Agents are well suited to open-ended problems where it's difficult to predict the *exact* steps needed in advance.\n",
    "\n",
    "Workflows are often appropriate when the control flow can easily be defined in advance.\n",
    "\n",
    "![workflow_v_agent](img/workflow_v_agent.png)\n",
    "\n",
    "## What is LangGraph?\n",
    "\n",
    "[LangGraph](https://langchain-ai.github.io/langgraphjs/concepts/high_level/) provides low-level supporting infrastructure that sits underneath *any* workflow or agent.\n",
    "\n",
    "It does not abstract prompts or architecture, and provides a few benefits:\n",
    "\n",
    "- **Control**: Make it easy to define and/or combine agents and workflows.\n",
    "- **Persistence**: Provide a way to persist the state of a graph, which enables both memory and human-in-the-loop.\n",
    "- **Testing, Debugging, and Deployment**: Provide an easy onramp for testing, debugging, and deploying applications.\n",
    "\n",
    "### Control\n",
    "\n",
    "LangGraph lets you define your application as a graph with:\n",
    "\n",
    "1. *State*: What information do we need to track over the course of the application?\n",
    "2. *Nodes*: How do we want to update this information over the course of the application?\n",
    "3. *Edges*: How do we want to connect these nodes together?\n",
    "\n",
    "You can use the [`StateGraph` class](https://langchain-ai.github.io/langgraphjs/concepts/low_level/) to initialize a LangGraph graph with a [Zod schema](https://langchain-ai.github.io/langgraphjs/how-tos/define-state/) for your state.\n",
    "\n",
    "`State` defines the schema for information you want to track over the course of the application.\n",
    "\n",
    "In TypeScript, this is typically a Zod object schema, which provides runtime validation and type safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3319290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StateGraph, START, END } from \"@langchain/langgraph\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "// Define the state schema using Zod\n",
    "const StateSchema = z.object({\n",
    "  request: z.string(),\n",
    "  email: z.string(),\n",
    "});\n",
    "\n",
    "\n",
    "\n",
    "// Initialize the workflow graph\n",
    "const workflow = new StateGraph(StateSchema);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84bedb9",
   "metadata": {},
   "source": [
    "Each node is simply a TypeScript function. This gives you full control over the logic inside each node.\n",
    "\n",
    "Nodes receive the current state and return an object to update the state.\n",
    "\n",
    "By default, [state keys are overwritten](https://langchain-ai.github.io/langgraphjs/how-tos/state-reducers/).\n",
    "\n",
    "However, you can [define custom update logic (reducers)](https://langchain-ai.github.io/langgraphjs/concepts/low_level/#reducers) to control how state is merged or updated.\n",
    "\n",
    "![nodes_edges](img/nodes_edges.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5e79c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "const writeEmailNode = async (state) => {\n",
    "  // Use a more explicit prompt to encourage tool use\n",
    "  const prompt = \"Please use the write_email tool to draft a response to my boss about tomorrow's meeting. The email should confirm my attendance and ask if there's anything specific I should prepare.\";\n",
    "  const output = await modelWithTools.invoke(prompt);\n",
    "\n",
    "\n",
    "\n",
    "  const args = output.tool_calls?.[0]?.args;\n",
    "  let email = \"\";\n",
    "  if (args) {\n",
    "    email = await writeEmail.func(args);\n",
    "  }\n",
    "  return { email };\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c8040",
   "metadata": {},
   "source": [
    "Edges connect nodes together. \n",
    "\n",
    "We specify the control flow by adding edges and nodes to our state graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "554e0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StateGraph, START, END } from \"@langchain/langgraph\";\n",
    "\n",
    "// Define your state schema and node functions first\n",
    "const workflow = new StateGraph(StateSchema);\n",
    "\n",
    "workflow\n",
    "  .addNode(\"write_email_node\", writeEmailNode)\n",
    "  .addEdge(START, \"write_email_node\")\n",
    "  .addEdge(\"write_email_node\", END);\n",
    "\n",
    "// Only now, compile the workflow\n",
    "const app = workflow.compile();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7cc79b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  request: \"Draft a response to my boss about tomorrow's meeting\",\n",
      "  email: \"Email sent to [Boss's Email] with subject 'Confirmation of Attendance for Tomorrow's Meeting' and content: Dear [Boss's Name],\\n\" +\n",
      "    '\\n' +\n",
      "    \"I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there is anything specific you would like me to prepare or bring to the discussion.\\n\" +\n",
      "    '\\n' +\n",
      "    'Thank you, and I look forward to the meeting.\\n' +\n",
      "    '\\n' +\n",
      "    'Best regards,\\n' +\n",
      "    '[Your Name]'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Run the workflow\n",
    "const workflowResult = await app.invoke({ request: \"Draft a response to my boss about tomorrow's meeting\" });\n",
    "console.log(workflowResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446dea9",
   "metadata": {},
   "source": [
    "Routing between nodes can be done [conditionally](https://langchain-ai.github.io/langgraphjs/concepts/low_level/#conditional-edges) using a simple function.\n",
    "\n",
    "The return value of this function is used as the name of the node (or list of nodes) to send the state to next.\n",
    "\n",
    "You can optionally provide a mapping object that maps the output of your router function to the name of the next node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f29b05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { StateGraph, START, END } from \"@langchain/langgraph\";\n",
    "\n",
    "\n",
    "// Define the MessagesState schema\n",
    "const MessagesState = z.object({\n",
    "  messages: z.array(z.any()), // Use a more specific type if available\n",
    "});\n",
    "\n",
    "\n",
    "// Node: call_llm\n",
    "const callLlm = async (state) => {\n",
    "  const output = await modelWithTools.invoke(state.messages);\n",
    "  return { messages: [output] };\n",
    "};\n",
    "\n",
    "// Node: run_tool\n",
    "const runTool = async (state) => {\n",
    "  const lastMessage = state.messages[state.messages.length - 1] ;\n",
    "  const result = [];\n",
    "  if (lastMessage.tool_calls) {\n",
    "    for (const toolCall of lastMessage.tool_calls) {\n",
    "      const observation = await writeEmail.func(toolCall.args);\n",
    "      result.push({\n",
    "        type: \"tool\",\n",
    "        content: observation,\n",
    "        tool_call_id: toolCall.id,\n",
    "      });\n",
    "    }\n",
    "  }\n",
    "  return { messages: result };\n",
    "};\n",
    "\n",
    "// Conditional router\n",
    "const shouldContinue = (state) => {\n",
    "  const messages = state.messages;\n",
    "  const lastMessage = messages[messages.length - 1] ;\n",
    "  if (lastMessage.tool_calls && lastMessage.tool_calls.length > 0) {\n",
    "    return \"run_tool\";\n",
    "  }\n",
    "  return END;\n",
    "};\n",
    "\n",
    "// Build the workflow\n",
    "const messagesWorkflow = new StateGraph(MessagesState)\n",
    "  .addNode(\"call_llm\", callLlm)\n",
    "  .addNode(\"run_tool\", runTool)\n",
    "  .addEdge(START, \"call_llm\")\n",
    "  .addConditionalEdges(\"call_llm\", shouldContinue, { run_tool: \"run_tool\", [END]: END })\n",
    "  .addEdge(\"run_tool\", END);\n",
    "\n",
    "const messagesApp = messagesWorkflow.compile();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dadbafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  messages: [\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-BWdI3KFRLBe04VNrAZlg3aQbe0bEP\",\n",
      "      \"content\": \"Of course! Could you please provide a bit more detail? For example:\\n\\n- What is the purpose of the meeting?\\n- Do you want to confirm your attendance, ask to reschedule, or provide any specific information?\\n- Is there a particular tone you’d like (formal, friendly, brief, etc.)?\\n\\nLet me know so I can tailor the response for you!\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"promptTokens\": 61,\n",
      "          \"completionTokens\": 77,\n",
      "          \"totalTokens\": 138\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"model_name\": \"gpt-4.1-2025-04-14\",\n",
      "        \"usage\": {\n",
      "          \"prompt_tokens\": 61,\n",
      "          \"completion_tokens\": 77,\n",
      "          \"total_tokens\": 138,\n",
      "          \"prompt_tokens_details\": {\n",
      "            \"cached_tokens\": 0,\n",
      "            \"audio_tokens\": 0\n",
      "          },\n",
      "          \"completion_tokens_details\": {\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "          }\n",
      "        },\n",
      "        \"system_fingerprint\": \"fp_b38e740b47\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"output_tokens\": 77,\n",
      "        \"input_tokens\": 61,\n",
      "        \"total_tokens\": 138,\n",
      "        \"input_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"cache_read\": 0\n",
      "        },\n",
      "        \"output_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"reasoning\": 0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Run the workflow (visualization is not included in TypeScript)\n",
    "// Example invocation:\n",
    "const messagesResult = await messagesApp.invoke({\n",
    "    messages: [\n",
    "      { type: \"human\", content: \"Draft a response to my boss about tomorrow's meeting\" }\n",
    "    ]\n",
    "  });\n",
    "  console.log(messagesResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b232d",
   "metadata": {},
   "source": [
    "With these low-level components, you can build many different workflows and agents. See the [workflows tutorial](https://langchain-ai.github.io/langgraphjs/tutorials/workflows/) for more examples!\n",
    "\n",
    "Because agents are such a common pattern, [LangGraph](https://langchain-ai.github.io/langgraphjs/tutorials/workflows/#pre-built) provides a [pre-built agent abstraction](https://langchain-ai.github.io/langgraphjs/agents/overview/).\n",
    "\n",
    "With LangGraph's [pre-built method](https://langchain-ai.github.io/langgraphjs/how-tos/create-react-agent/), you just pass in the LLM, tools, and prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a317ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  messages: [\n",
      "    HumanMessage {\n",
      "      \"id\": \"5cf3d1e5-98f6-4736-9340-2e1edafe6cad\",\n",
      "      \"content\": \"Draft a response to my boss about tomorrow's meeting\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {}\n",
      "    },\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-BWdI5dHpSyQKh6tejTUexRgmHHRa5\",\n",
      "      \"content\": \"Of course! Could you please provide a bit more detail? For example:\\n\\n- What is the purpose or topic of the meeting?\\n- Do you want to confirm your attendance, ask to reschedule, or address any specific points?\\n- Is there a particular tone you’d like (formal, friendly, etc.)?\\n\\nLet me know so I can tailor the response to your needs!\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"promptTokens\": 71,\n",
      "          \"completionTokens\": 78,\n",
      "          \"totalTokens\": 149\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"model_name\": \"gpt-4.1-2025-04-14\",\n",
      "        \"usage\": {\n",
      "          \"prompt_tokens\": 71,\n",
      "          \"completion_tokens\": 78,\n",
      "          \"total_tokens\": 149,\n",
      "          \"prompt_tokens_details\": {\n",
      "            \"cached_tokens\": 0,\n",
      "            \"audio_tokens\": 0\n",
      "          },\n",
      "          \"completion_tokens_details\": {\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "          }\n",
      "        },\n",
      "        \"system_fingerprint\": \"fp_b38e740b47\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"output_tokens\": 78,\n",
      "        \"input_tokens\": 71,\n",
      "        \"total_tokens\": 149,\n",
      "        \"input_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"cache_read\": 0\n",
      "        },\n",
      "        \"output_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"reasoning\": 0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "// Create a prebuilt React agent\n",
    "const agent = createReactAgent({\n",
    "  llm: llm,\n",
    "  tools: [writeEmail],\n",
    "  prompt: \"Respond to the user's request using the tools provided.\",\n",
    "});\n",
    "\n",
    "// Run the agent\n",
    "const agentResult = await agent.invoke({\n",
    "  messages: [{ type: \"human\", content: \"Draft a response to my boss about tomorrow's meeting\" }],\n",
    "});\n",
    "console.log(agentResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e506f",
   "metadata": {},
   "source": [
    "### Persistence\n",
    "\n",
    "It can be very useful to allow agents to pause and gather human feedback.\n",
    "\n",
    "LangGraph has a built-in persistence layer, implemented through [checkpointers](https://langchain-ai.github.io/langgraphjs/concepts/persistence/#checkpoints), to enable this.\n",
    "\n",
    "When you compile a graph with a checkpointer, the checkpointer saves a checkpoint of the graph state at every step.\n",
    "\n",
    "Checkpoints are saved to a thread, which can be accessed after graph execution.\n",
    "\n",
    "![checkpointer](img/checkpoints.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a72377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  messages: [\n",
      "    HumanMessage {\n",
      "      \"id\": \"75a463e5-eaf1-43b4-8c9f-2c739bc76c41\",\n",
      "      \"content\": \"What are some good practices for writing emails?\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {}\n",
      "    },\n",
      "    AIMessage {\n",
      "      \"id\": \"chatcmpl-BWdI7Sv1ENX9IC8ZKkqaWexB1zPZO\",\n",
      "      \"content\": \"Here are some good practices for writing effective emails:\\n\\n1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what the email is about.\\n\\n2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\\n\\n3. **Be Concise and to the Point:** State your purpose early and keep your message brief. Avoid unnecessary details.\\n\\n4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it is free of errors and maintains a professional tone.\\n\\n5. **Structure Your Email:** Use short paragraphs, bullet points, or numbered lists to make your message easy to read.\\n\\n6. **Be Polite and Courteous:** Use polite language and thank the recipient when appropriate.\\n\\n7. **Include a Clear Call to Action:** If you need a response or action, state it clearly.\\n\\n8. **Sign Off Properly:** End with a professional closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\\n\\n9. **Use Professional Language:** Avoid slang, emojis, or overly casual language in professional settings.\\n\\n10. **Check Attachments:** If you mention attachments, make sure to include them before sending.\\n\\nWould you like tips for a specific type of email (e.g., job application, business inquiry)?\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {\n",
      "        \"tokenUsage\": {\n",
      "          \"promptTokens\": 70,\n",
      "          \"completionTokens\": 286,\n",
      "          \"totalTokens\": 356\n",
      "        },\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"model_name\": \"gpt-4.1-2025-04-14\",\n",
      "        \"usage\": {\n",
      "          \"prompt_tokens\": 70,\n",
      "          \"completion_tokens\": 286,\n",
      "          \"total_tokens\": 356,\n",
      "          \"prompt_tokens_details\": {\n",
      "            \"cached_tokens\": 0,\n",
      "            \"audio_tokens\": 0\n",
      "          },\n",
      "          \"completion_tokens_details\": {\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "          }\n",
      "        },\n",
      "        \"system_fingerprint\": \"fp_b38e740b47\"\n",
      "      },\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"output_tokens\": 286,\n",
      "        \"input_tokens\": 70,\n",
      "        \"total_tokens\": 356,\n",
      "        \"input_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"cache_read\": 0\n",
      "        },\n",
      "        \"output_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"reasoning\": 0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { MemorySaver } from \"@langchain/langgraph\"; \n",
    "\n",
    "\n",
    "// Create a React agent with in-memory checkpointing\n",
    "const agentWithCheckpoint = createReactAgent({\n",
    "  llm: llm,\n",
    "  tools: [writeEmail],\n",
    "  prompt: \"Respond to the user's request using the tools provided.\",\n",
    "  checkpointer: new MemorySaver(),\n",
    "});\n",
    "\n",
    "// Config for thread id\n",
    "const config = { configurable: { thread_id: \"1\" } };\n",
    "\n",
    "// Run the agent with checkpointing\n",
    "const checkpointResult = await agentWithCheckpoint.invoke(\n",
    "  {\n",
    "    messages: [{ type: \"human\", content: \"What are some good practices for writing emails?\" }],\n",
    "  },\n",
    "  config\n",
    ");\n",
    "console.log(checkpointResult);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10984007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage {\n",
      "  \"id\": \"75a463e5-eaf1-43b4-8c9f-2c739bc76c41\",\n",
      "  \"content\": \"What are some good practices for writing emails?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BWdI7Sv1ENX9IC8ZKkqaWexB1zPZO\",\n",
      "  \"content\": \"Here are some good practices for writing effective emails:\\n\\n1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what the email is about.\\n\\n2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\\n\\n3. **Be Concise and to the Point:** State your purpose early and keep your message brief. Avoid unnecessary details.\\n\\n4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it is free of errors and maintains a professional tone.\\n\\n5. **Structure Your Email:** Use short paragraphs, bullet points, or numbered lists to make your message easy to read.\\n\\n6. **Be Polite and Courteous:** Use polite language and thank the recipient when appropriate.\\n\\n7. **Include a Clear Call to Action:** If you need a response or action, state it clearly.\\n\\n8. **Sign Off Properly:** End with a professional closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\\n\\n9. **Use Professional Language:** Avoid slang, emojis, or overly casual language in professional settings.\\n\\n10. **Check Attachments:** If you mention attachments, make sure to include them before sending.\\n\\nWould you like tips for a specific type of email (e.g., job application, business inquiry)?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 70,\n",
      "      \"completionTokens\": 286,\n",
      "      \"totalTokens\": 356\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4.1-2025-04-14\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 70,\n",
      "      \"completion_tokens\": 286,\n",
      "      \"total_tokens\": 356,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b38e740b47\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Get the latest state snapshot for the thread\n",
    "const state = await agentWithCheckpoint.getState(config);\n",
    "for (const message of state.values.messages) {\n",
    "  // You can define a prettyPrint function or just log the message\n",
    "  console.log(message);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage {\n",
      "  \"id\": \"75a463e5-eaf1-43b4-8c9f-2c739bc76c41\",\n",
      "  \"content\": \"What are some good practices for writing emails?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BWdI7Sv1ENX9IC8ZKkqaWexB1zPZO\",\n",
      "  \"content\": \"Here are some good practices for writing effective emails:\\n\\n1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what the email is about.\\n\\n2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\\n\\n3. **Be Concise and to the Point:** State your purpose early and keep your message brief. Avoid unnecessary details.\\n\\n4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it is free of errors and maintains a professional tone.\\n\\n5. **Structure Your Email:** Use short paragraphs, bullet points, or numbered lists to make your message easy to read.\\n\\n6. **Be Polite and Courteous:** Use polite language and thank the recipient when appropriate.\\n\\n7. **Include a Clear Call to Action:** If you need a response or action, state it clearly.\\n\\n8. **Sign Off Properly:** End with a professional closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\\n\\n9. **Use Professional Language:** Avoid slang, emojis, or overly casual language in professional settings.\\n\\n10. **Check Attachments:** If you mention attachments, make sure to include them before sending.\\n\\nWould you like tips for a specific type of email (e.g., job application, business inquiry)?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 70,\n",
      "      \"completionTokens\": 286,\n",
      "      \"totalTokens\": 356\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4.1-2025-04-14\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 70,\n",
      "      \"completion_tokens\": 286,\n",
      "      \"total_tokens\": 356,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b38e740b47\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Get the latest state snapshot for the thread\n",
    "const state = await agentWithCheckpoint.getState(config);\n",
    "for (const message of state.values.messages) {\n",
    "  console.log(message);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f09fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage {\n",
      "  \"id\": \"75a463e5-eaf1-43b4-8c9f-2c739bc76c41\",\n",
      "  \"content\": \"What are some good practices for writing emails?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BWdI7Sv1ENX9IC8ZKkqaWexB1zPZO\",\n",
      "  \"content\": \"Here are some good practices for writing effective emails:\\n\\n1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what the email is about.\\n\\n2. **Greet Appropriately:** Start with a polite greeting, such as “Hello [Name],” or “Dear [Name],” depending on the formality.\\n\\n3. **Be Concise and to the Point:** State your purpose early and keep your message brief. Avoid unnecessary details.\\n\\n4. **Use Proper Grammar and Spelling:** Proofread your email to ensure it is free of errors and maintains a professional tone.\\n\\n5. **Structure Your Email:** Use short paragraphs, bullet points, or numbered lists to make your message easy to read.\\n\\n6. **Be Polite and Courteous:** Use polite language and thank the recipient when appropriate.\\n\\n7. **Include a Clear Call to Action:** If you need a response or action, state it clearly.\\n\\n8. **Sign Off Properly:** End with a professional closing, such as “Best regards,” “Sincerely,” or “Thank you,” followed by your name.\\n\\n9. **Use Professional Language:** Avoid slang, emojis, or overly casual language in professional settings.\\n\\n10. **Check Attachments:** If you mention attachments, make sure to include them before sending.\\n\\nWould you like tips for a specific type of email (e.g., job application, business inquiry)?\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 70,\n",
      "      \"completionTokens\": 286,\n",
      "      \"totalTokens\": 356\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4.1-2025-04-14\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 70,\n",
      "      \"completion_tokens\": 286,\n",
      "      \"total_tokens\": 356,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b38e740b47\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": []\n",
      "}\n",
      "HumanMessage {\n",
      "  \"id\": \"ae70e70f-2f21-4e2a-b121-5b6a01e4dfc4\",\n",
      "  \"content\": \"I like this, let's write the email\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {}\n",
      "}\n",
      "AIMessage {\n",
      "  \"id\": \"chatcmpl-BWdID0y4mpE40KitMQw1exCUqTrv8\",\n",
      "  \"content\": \"Great! Could you please provide a bit more information so I can tailor the email for you? For example:\\n\\n- Who is the recipient (name and/or role)?\\n- What is the purpose or subject of the email?\\n- Any specific message or details you want to include?\\n- Do you want a formal or informal tone?\\n\\nOnce you provide these details, I’ll draft the email for you!\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 370,\n",
      "      \"completionTokens\": 81,\n",
      "      \"totalTokens\": 451\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"gpt-4.1-2025-04-14\",\n",
      "    \"usage\": {\n",
      "      \"prompt_tokens\": 370,\n",
      "      \"completion_tokens\": 81,\n",
      "      \"total_tokens\": 451,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_b38e740b47\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"output_tokens\": 81,\n",
      "    \"input_tokens\": 370,\n",
      "    \"total_tokens\": 451,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// Continue the conversation again\n",
    "const finalResult = await agentWithCheckpoint.invoke(\n",
    "    {\n",
    "      messages: [\n",
    "        { type: \"human\", content: \"I like this, let's write the email\" },\n",
    "      ],\n",
    "    },\n",
    "    config\n",
    "  );\n",
    "  for (const m of finalResult.messages) {\n",
    "    console.log(m);\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639a518",
   "metadata": {},
   "source": [
    "### Testing, Debugging, and Deployment\n",
    "\n",
    "When using LangChain or LangGraph JS, [LangSmith logging works out of the box](https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph) by setting the following environment variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45f864ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Set LangSmith tracing environment variables in your .env or process environment\n",
    "// Example (do this in your shell or .env file, not in code):\n",
    "// process.env.LANGSMITH_TRACING = \"true\";\n",
    "// process.env.LANGSMITH_API_KEY = \"<your-langsmith-api-key>\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2a3e5",
   "metadata": {},
   "source": [
    "Here is the LangSmith trace from above graph execution:\n",
    "\n",
    "https://smith.langchain.com/public/6f77014f-d054-44ed-aa2c-8b06ceab689f/r\n",
    "\n",
    "We can see that the agent is able to continue the conversation from the previous state because we used a checkpointer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0269214",
   "metadata": {},
   "source": [
    "It's also easy to deploy to deploy our graph using [LangGraph Platform](https://langchain-ai.github.io/langgraphjs/concepts/langgraph_platform/). \n",
    "\n",
    "We simply need to ensure our project has [a structure](https://langchain-ai.github.io/langgraphjs/cloud/deployment/setup_javascript/) like this:\n",
    "\n",
    "```\n",
    "my-app/\n",
    "├── my_agent # all project code lies within here\n",
    "│   └── agent.ts # code for constructing your graph\n",
    "├── .env # environment variables\n",
    "├── langgraph.json  # configuration file for LangGraph\n",
    "└── pyproject.toml # dependencies for your project\n",
    "```\n",
    "\n",
    "The `langgraph.json` file specifies the dependencies, graphs, environment variables, and other settings required to deploy a LangGraph application.\n",
    "\n",
    "Note: Langgraph 101 script for deployment is not available in typescript, however you can deploy `email_assistant.ts` `email_assistant_hitl.ts` and `email_assistant_hitl_memory.ts`\n",
    "\n",
    "There are a range of [deployment options](https://langchain-ai.github.io/langgraphjs/tutorials/deployment/). \n",
    "\n",
    "* All create an API [server](https://langchain-ai.github.io/langgraphjs/concepts/langgraph_server/) for our graph\n",
    "* All include an interactive IDE (LangGraph [Studio](https://langchain-ai.github.io/langgraphjs)).\n",
    " \n",
    "We can start a deployment locally using `langgraph dev`:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edf38d37",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "langgraph dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3644093",
   "metadata": {},
   "source": [
    "Here we can see a visualization of the graph as well as the graph state in Studio.\n",
    "\n",
    "![langgraph_studio](img/langgraph_studio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a3f4a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
