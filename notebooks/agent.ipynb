{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb66df4",
   "metadata": {},
   "source": [
    "# Building Agents \n",
    " \n",
    "> Note: Optionally, see [these slides](https://docs.google.com/presentation/d/13c0L1CQWAL7fuCXakOqjkvoodfynPJI4Hw_4H76okVU/edit?usp=sharing) and [langgraph_101.ipynb](langgraph_101.ipynb) for context before diving into this notebook!\n",
    "\n",
    "We're going to build an email assistant from scratch, starting here with 1) the agent architecture (using [LangGraph JS](https://langchain-ai.github.io/langgraphjs/)) and following with 2) testing (using [LangSmith](https://docs.smith.langchain.com/)), 3) human-in-the-loop, and 4) memory. This diagram show how these pieces will fit together:\n",
    "\n",
    "![overview-img](img/overview.png)\n",
    "\n",
    "### Tool Definition\n",
    "\n",
    "Let's start by defining some simple tools that an email assistant will use with the `@tool` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b708ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:25 - No overload matches this call.\n",
      "13:25 - Overload 1 of 3, '(func: RunnableFunc<string, any, ToolRunnableConfig>, fields: ToolWrapperParams<ZodString>): DynamicTool', gave the following error.\n",
      "13:25 - Argument of type '(to: any, subject: any, content: any) => Promise<string>' is not assignable to parameter of type 'RunnableFunc<string, any, ToolRunnableConfig>'.\n",
      "13:25 - Overload 2 of 3, '(func: RunnableFunc<any, any, ToolRunnableConfig>, fields: ToolWrapperParams<ZodObject<{ to: ZodString; subject: ZodString; content: ZodString; }, \"strip\", ZodTypeAny, { ...; }, { ...; }>>): DynamicStructuredTool<...>', gave the following error.\n",
      "13:25 - Argument of type '(to: any, subject: any, content: any) => Promise<string>' is not assignable to parameter of type 'RunnableFunc<any, any, ToolRunnableConfig>'.\n",
      "13:25 - Overload 3 of 3, '(func: RunnableFunc<{ to?: string; subject?: string; content?: string; }, any, ToolRunnableConfig>, fields: ToolWrapperParams<ZodObject<{ to: ZodString; subject: ZodString; content: ZodString; }, \"strip\", ZodTypeAny, { ...; }, { ...; }>>): DynamicStructuredTool<...>', gave the following error.\n",
      "13:25 - Argument of type '(to: any, subject: any, content: any) => Promise<string>' is not assignable to parameter of type 'RunnableFunc<{ to?: string; subject?: string; content?: string; }, any, ToolRunnableConfig>'.\n",
      "34:14 - Cannot redeclare exported variable 'scheduleMeeting'.\n",
      "34:36 - Cannot find name 'DynamicStructuredTool'.\n",
      "51:14 - Cannot redeclare exported variable 'checkCalendarAvailability'.\n",
      "51:46 - Cannot find name 'DynamicStructuredTool'.\n",
      "67:14 - Cannot redeclare exported variable 'Done'.\n",
      "67:25 - Cannot find name 'DynamicStructuredTool'.\n",
      "76:71 - Cannot redeclare exported variable 'scheduleMeeting'.\n",
      "76:71 - Export declaration conflicts with exported declaration of 'scheduleMeeting'.\n",
      "76:109 - Cannot redeclare exported variable 'checkCalendarAvailability'.\n",
      "76:109 - Export declaration conflicts with exported declaration of 'checkCalendarAvailability'.\n",
      "76:148 - Cannot redeclare exported variable 'Done'.\n",
      "76:148 - Export declaration conflicts with exported declaration of 'Done'.\n"
     ]
    }
   ],
   "source": [
    "import { z } from \"zod\";\n",
    "// import\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "\n",
    "// Define schema for email writing\n",
    "const writeEmailSchema = z.object({\n",
    "  to: z.string().describe(\"Email address of the recipient\"),\n",
    "  subject: z.string().describe(\"Subject line for the email\"),\n",
    "  content: z.string().describe(\"Main body text of the email\")\n",
    "});\n",
    "\n",
    "// Write email tool\n",
    "const writeEmail = tool(async ( to, subject, content ) => {\n",
    "  // Placeholder response - in real app would send email\n",
    "  return `Email sent to ${to} with subject '${subject}' and content: ${content}`;\n",
    "}, {\n",
    "  name: \"write_email\",\n",
    "  description: \"Write and send an email.\",\n",
    "  schema: writeEmailSchema,\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "// Define schema for scheduling meeting\n",
    "const scheduleMeetingSchema = z.object({\n",
    "  attendees: z.array(z.string()).describe(\"List of attendees' emails\"),\n",
    "  subject: z.string().describe(\"Meeting title or subject\"),\n",
    "  duration_minutes: z.number().describe(\"Duration of meeting in minutes\"),\n",
    "  preferred_day: z.string().describe(\"Preferred date for the meeting\"),\n",
    "  start_time: z.number().describe(\"Start time of the meeting\")\n",
    "});\n",
    "\n",
    "// Schedule meeting tool\n",
    "export const scheduleMeeting = new DynamicStructuredTool({\n",
    "  name: \"schedule_meeting\",\n",
    "  description: \"Schedule a calendar meeting.\",\n",
    "  schema: scheduleMeetingSchema,\n",
    "  func: async (attendees, subject, duration_minutes, preferred_day, start_time )=> {\n",
    "    // Placeholder response - in real app would check calendar and schedule\n",
    "    const dateStr = new Date(preferred_day).toLocaleDateString('en-US', { weekday: 'long', month: 'long', day: 'numeric', year: 'numeric' });\n",
    "    return `Meeting '${subject}' scheduled on ${dateStr} at ${start_time} for ${duration_minutes} minutes with ${attendees.length} attendees`;\n",
    "  }\n",
    "});\n",
    "\n",
    "// Define schema for checking calendar\n",
    "const checkCalendarSchema = z.object({\n",
    "  day: z.string().describe(\"Day to check calendar availability\")\n",
    "});\n",
    "\n",
    "// Check calendar availability tool\n",
    "export const checkCalendarAvailability = new DynamicStructuredTool({\n",
    "  name: \"check_calendar_availability\",\n",
    "  description: \"Check calendar availability for a given day.\",\n",
    "  schema: checkCalendarSchema,\n",
    "  func: async (day) => {\n",
    "    // Placeholder response - in real app would check actual calendar\n",
    "    return `Available times on ${day}: 9:00 AM, 2:00 PM, 4:00 PM`;\n",
    "  }\n",
    "});\n",
    "\n",
    "// Define schema for Done tool\n",
    "const doneSchema = z.object({\n",
    "  done: z.boolean().describe(\"Task completion status\")\n",
    "});\n",
    "// TODO FIX TOOl\n",
    "// Done tool\n",
    "export const Done = new DynamicStructuredTool({\n",
    "  name: \"Done\",\n",
    "  description: \"E-mail has been sent.\",\n",
    "  schema: doneSchema,\n",
    "  func: async () => {\n",
    "    return \"Task completed successfully\";\n",
    "  }\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b2600",
   "metadata": {},
   "source": [
    "### Augmenting the LLM with Tools\n",
    "\n",
    "Now we connect these tools to a LLM. We'll use LangChain's [`initChatModel`](https://js.langchain.com/docs/how_to/chat_models_universal_init/) interface, which allows us to initialize many different chat models.\n",
    "\n",
    "We [enforce tool use](https://js.langchain.com/docs/how_to/tool_choice/) by setting `tool_choice: \"required\"` (or the equivalent parameter for the specific model integration, like in `bindTools`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307eec2-49e3-468c-b6e5-4a05850bbbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import { initChatModel } from \"langchain/chat_models/universal\";\n",
    "\n",
    "// Initialize the LLM\n",
    "const llm = initChatModel(\n",
    "  \"openai:gpt-4o\",\n",
    "  {temperature: 0.0}\n",
    ");\n",
    "\n",
    "// Bind tools to the LLM\n",
    "const llmWithTools = llm.bindTools([writeEmail]);\n",
    "\n",
    "// Email input\n",
    "const emailInput = {\n",
    "  author: \"System Admin <sysadmin@company.com>\",\n",
    "  to: \"Development Team <dev@company.com>\",\n",
    "  subject: \"Scheduled maintenance - database downtime\",\n",
    "  email_thread: \"Hi team,\\n\\nThis is a reminder that we'll be performing scheduled maintenance on the production database tonight from 2AM to 4AM EST. During this time, all database services will be unavailable.\\n\\nPlease plan your work accordingly and ensure no critical deployments are scheduled during this window.\\n\\nThanks,\\nSystem Admin Team\"\n",
    "};\n",
    "\n",
    "// Run the agent\n",
    "const messages = [{ role: \"user\", content: \"Call the 'write_email' tool in order to respond to this email: \" + JSON.stringify(emailInput, null, 2) }];\n",
    "const output = await llmWithTools.invoke(messages);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fe1b1-6363-40ce-ad33-df03145ba8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(output.tool_calls);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6393f3ed-90cd-4c86-a528-af5c0a9c43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "const args = output.tool_calls?.[0]?.args;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e721597-0e17-44ea-9b7e-a9e1fee438de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "const writeEmailResult = await writeEmail.invoke(args);\n",
    "console.log(writeEmailResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911c929-5c41-4dcd-9cc8-21a8ff82b769",
   "metadata": {},
   "source": [
    "## Building our email assistant\n",
    "\n",
    "We'll combine a [router and agent](https://langchain-ai.github.io/langgraphjs/tutorials/workflows/) to build our email assistant.\n",
    "\n",
    "![agent_workflow_img](img/email_workflow.png)\n",
    "\n",
    "### Router\n",
    "\n",
    "The routing step handles the triage decision. \n",
    "\n",
    "The triage router only focuses on the triage decision, while the agent focuses *only* on the response. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690d5a4-80c4-4e56-89e7-dc64d278ccd7",
   "metadata": {},
   "source": [
    "### State\n",
    "\n",
    "When building an agent, it's important to consider the information that you want to track over time. We'll use LangGraph's pre-built [`MessagesState` type (or a similar state management concept described in the [LangGraph JS documentation](https://langchain-ai.github.io/langgraphjs/concepts/low_level/)) which is often a dictionary with a `messages` key that appends messages returned by nodes [as its update logic (see reducers or state updaters in the JS docs)](https://langchain-ai.github.io/langgraphjs/concepts/low_level/). However, LangGraph gives you flexibility to track other information. We'll define a custom `State` object (typically using Zod for schema definition in TypeScript) that might extend a base message state and adds a `classification_decision` key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692537ec-f09e-4086-81e4-9c517273b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "// to do replace with Proper State for Messages \n",
    "// Create StateSchema using Zod\n",
    "const StateSchema = \n",
    "z.object({\n",
    "  messages: z.array(z.any()),\n",
    "  email_input: z.record(z.any()),\n",
    "  classification_decision: z.enum([\"ignore\", \"respond\", \"notify\"])\n",
    "});\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd1647-6d58-4aae-b954-6a9c5790c20c",
   "metadata": {},
   "source": [
    "#### Triage node\n",
    "\n",
    "We define a TypeScript function with our triage routing logic.\n",
    "\n",
    "For this, we use [structured outputs](https://js.langchain.com/docs/concepts/structured_outputs/) with a Zod schema (instead of Pydantic models used in Python). Zod schemas are particularly useful for defining structured output schemas in TypeScript because they offer type hints and validation. The descriptions in the Zod schema are important because they get passed as part of the JSON schema to the LLM to inform the output coercion (often using the `.withStructuredOutput()` method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ae6a6-94d9-4160-8d45-18f4d29aa600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import { END } from \"@langchain/langgraph\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { StructuredOutputParser } from \"langchain/output_parsers\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "// Import utilities and prompts\n",
    "import { parseEmail, formatEmailMarkdown } from \"../../lib/utils\";\n",
    "import { \n",
    "  triageSystemPrompt, \n",
    "  triageUserPrompt, \n",
    "  defaultTriageInstructions, \n",
    "  defaultBackground\n",
    "} from \"../../lib/prompts\";\n",
    "\n",
    "// Define the router schema using Zod\n",
    "const RouterSchema = z.object({\n",
    "  reasoning: z.string().describe(\"Step-by-step reasoning behind the classification.\"),\n",
    "  classification: z.enum([\"ignore\", \"respond\", \"notify\"]).describe(\n",
    "    \"The classification of an email: 'ignore' for irrelevant emails, \" +\n",
    "    \"'notify' for important information that doesn't need a response, \" +\n",
    "    \"'respond' for emails that need a reply\"\n",
    "  )\n",
    "});\n",
    "\n",
    "// Initialize the LLM for use with router / structured output\n",
    "const llm = new ChatOpenAI({\n",
    "  modelName: \"gpt-4-turbo\",\n",
    "  temperature: 0\n",
    "});\n",
    "\n",
    "// Create structured output parser\n",
    "const outputParser = StructuredOutputParser.fromZodSchema(RouterSchema);\n",
    "const llmRouter = llm.withStructuredOutput(RouterSchema);\n",
    "\n",
    "// Triage router function\n",
    "async function triageRouter() {\n",
    "  // Parse email components\n",
    "  const { author, to, subject, email_thread } = parseEmail(state.email_input);\n",
    "  \n",
    "  // Format prompts\n",
    "  const systemPrompt = triageSystemPrompt\n",
    "    .replace(\"{background}\", defaultBackground)\n",
    "    .replace(\"{triage_instructions}\", defaultTriageInstructions);\n",
    "\n",
    "  const userPrompt = triageUserPrompt\n",
    "    .replace(\"{author}\", author)\n",
    "    .replace(\"{to}\", to)\n",
    "    .replace(\"{subject}\", subject)\n",
    "    .replace(\"{email_thread}\", email_thread);\n",
    "\n",
    "  // Invoke the LLM with structured output\n",
    "  const result = await llmRouter.invoke([\n",
    "    { role: \"system\", content: systemPrompt },\n",
    "    { role: \"user\", content: userPrompt }\n",
    "  ]);\n",
    "\n",
    "  if (result.classification === \"respond\") {\n",
    "    console.log(\"ðŸ“§ Classification: RESPOND - This email requires a response\");\n",
    "    return {\n",
    "      goto: \"response_agent\",\n",
    "      update: {\n",
    "        messages: [\n",
    "          {\n",
    "            role: \"user\",\n",
    "            content: `Respond to the email: \\n\\n${formatEmailMarkdown(subject, author, to, email_thread)}`\n",
    "          }\n",
    "        ],\n",
    "        classification_decision: result.classification\n",
    "      }\n",
    "    };\n",
    "  } else if (result.classification === \"ignore\") {\n",
    "    console.log(\"ðŸš« Classification: IGNORE - This email can be safely ignored\");\n",
    "    return {\n",
    "      goto: END,\n",
    "      update: {\n",
    "        classification_decision: result.classification\n",
    "      }\n",
    "    };\n",
    "  } else if (result.classification === \"notify\") {\n",
    "    console.log(\"ðŸ”” Classification: NOTIFY - This email contains important information\");\n",
    "    // For now, we go to END. But we will add to this later!\n",
    "    return {\n",
    "      goto: END,\n",
    "      update: {\n",
    "        classification_decision: result.classification\n",
    "      }\n",
    "    };\n",
    "  } else {\n",
    "    throw new Error(`Invalid classification: ${result.classification}`);\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d8715",
   "metadata": {},
   "source": [
    "We use concepts similar to [Commands (how to update state and jump to nodes)](https://langchain-ai.github.io/langgraphjs/how-tos/command/) in LangGraph to both update the state and select the next node to visit. This is a useful alternative to edges.\n",
    "\n",
    "### Agent\n",
    "\n",
    "Now, let's build the agent.\n",
    "\n",
    "#### LLM node\n",
    "\n",
    "Here, we define the LLM decision-making node. This node takes in the current state, calls the LLM, and updates `messages` with the LLM output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e842b3c-06f5-440f-8159-995503ef3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { AGENT_TOOLS_PROMPT } from \"../../lib/tools/default/prompt_templates\";\n",
    "import { \n",
    "  agentSystemPrompt, \n",
    "  defaultResponsePreferences, \n",
    "  defaultCalPreferences \n",
    "} from \"../../lib/prompts\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69c6fc-70aa-48f1-8312-2b1818469a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(AGENT_TOOLS_PROMPT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052fced-3fdb-4cd2-ac88-e2ccdce14e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(agentSystemPrompt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f2c120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "// Collect all tools\n",
    "const tools = [writeEmail, scheduleMeeting, checkCalendarAvailability, Done];\n",
    "const toolsByName = new Map(tools.map(tool => [tool.name, tool]));\n",
    "\n",
    "// Initialize the LLM, enforcing tool use\n",
    "const llm = new ChatOpenAI({\n",
    "  modelName: \"gpt-4-turbo\",\n",
    "  temperature: 0\n",
    "});\n",
    "\n",
    "const llmWithTools = llm.bindTools(tools, { toolChoice: \"required\" });\n",
    "\n",
    "// LLM call function\n",
    "async function llmCall() {\n",
    "  // Format the system prompt with all required information\n",
    "  const formattedSystemPrompt = agentSystemPrompt\n",
    "    .replace(\"{tools_prompt}\", AGENT_TOOLS_PROMPT)\n",
    "    .replace(\"{background}\", defaultBackground)\n",
    "    .replace(\"{response_preferences}\", defaultResponsePreferences)\n",
    "    .replace(\"{cal_preferences}\", defaultCalPreferences)\n",
    "    .replace(\"{triage_instructions}\", defaultTriageInstructions);\n",
    "\n",
    "  // Invoke the LLM with system prompt and current messages\n",
    "  const result = await llmWithTools.invoke([\n",
    "    { role: \"system\", content: formattedSystemPrompt },\n",
    "    ...state.messages\n",
    "  ]);\n",
    "  \n",
    "  return {\n",
    "    messages: [result]\n",
    "  };\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05d11a",
   "metadata": {},
   "source": [
    "#### Tool handler node\n",
    "\n",
    "After the LLM makes a decision, we need to execute the chosen tool. The `toolHandler` node executes the tool. We can see that nodes can update the graph state to capture any important state changes, such as the classification decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43eb6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Tool handler function\n",
    "async function toolHandler() {\n",
    "  // List for tool messages\n",
    "  const result = [];\n",
    "  \n",
    "  // Get the last message\n",
    "  const lastMessage = state.messages[state.messages.length - 1];\n",
    "  \n",
    "  // Iterate through tool calls\n",
    "  for (const toolCall of lastMessage.tool_calls || []) {\n",
    "    // Get the tool\n",
    "    const tool = toolsByName.get(toolCall.name);\n",
    "    \n",
    "    if (!tool) {\n",
    "      throw new Error(`Tool ${toolCall.name} not found`);\n",
    "    }\n",
    "    \n",
    "    // Run it\n",
    "    const observation = await tool.invoke(toolCall.args);\n",
    "    \n",
    "    // Create a tool message\n",
    "    result.push({\n",
    "      role: \"tool\",\n",
    "      content: observation,\n",
    "      tool_call_id: toolCall.id\n",
    "    });\n",
    "  }\n",
    "  \n",
    "  // Add it to our messages\n",
    "  return { messages: result };\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721dede",
   "metadata": {},
   "source": [
    "#### Conditional Routing\n",
    "\n",
    "Our agent needs to decide when to continue using tools and when to stop. This conditional routing function directs the agent to either continue or terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c7cbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Function to determine if we should continue or end\n",
    "function shouldContinue() {\n",
    "  // Get the last message\n",
    "  const messages = state.messages;\n",
    "  const lastMessage = messages[messages.length - 1];\n",
    "  \n",
    "  // If the last message is a tool call, check if it's a Done tool call\n",
    "  if (lastMessage.tool_calls && lastMessage.tool_calls.length > 0) {\n",
    "    for (const toolCall of lastMessage.tool_calls) {\n",
    "      if (toolCall.name === \"Done\") {\n",
    "        return END;\n",
    "      }\n",
    "    }\n",
    "    return \"tool_handler\";\n",
    "  }\n",
    "  \n",
    "  // Default case - shouldn't reach here\n",
    "  return \"tool_handler\";\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4ede8",
   "metadata": {},
   "source": [
    "#### Agent Graph\n",
    "\n",
    "Finally, we can assemble all components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81df767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StateGraph, START, END } from \"@langchain/langgraph\";\n",
    "\n",
    "// Build workflow\n",
    "const overallWorkflow = new StateGraph<State>({\n",
    "  channels: StateSchema\n",
    "})\n",
    "  .addNode(\"llm_call\", llmCall)\n",
    "  .addNode(\"tool_handler\", toolHandler);\n",
    "\n",
    "// Add edges\n",
    "overallWorkflow.addEdge(START, \"llm_call\");\n",
    "overallWorkflow.addConditionalEdges(\n",
    "  \"llm_call\",\n",
    "  shouldContinue,\n",
    "  {\n",
    "    \"tool_handler\": \"tool_handler\",\n",
    "    [END]: END,\n",
    "  }\n",
    ");\n",
    "overallWorkflow.addEdge(\"tool_handler\", \"llm_call\");\n",
    "\n",
    "// Compile the agent\n",
    "const agent = overallWorkflow.compile();\n",
    "\n",
    "// In a TypeScript environment, we would visualize it with:\n",
    "// agent.showGraph();\n",
    "\n",
    "// For the notebook, we'd output an image similar to the Python version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8367c4",
   "metadata": {},
   "source": [
    "This creates a graph that:\n",
    "1. Starts with an LLM decision\n",
    "2. Conditionally routes to tool execution or termination\n",
    "3. After tool execution, returns to LLM for the next decision\n",
    "4. Repeats until completion or no tool is called\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3406d-496d-43c9-942e-c5ce7e3a8321",
   "metadata": {},
   "source": [
    "### Combine workflow with our agent\n",
    "\n",
    "We can combine the router and the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6dcc4-6346-4d41-ae36-61f3fc83b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Combine the triage router and agent workflow\n",
    "const combinedWorkflow = new StateGraph<State>({\n",
    "  channels: StateSchema\n",
    "})\n",
    "  .addNode(\"triage_router\", triageRouter)\n",
    "  .addNode(\"response_agent\", agent)\n",
    "  .addEdge(START, \"triage_router\");\n",
    "\n",
    "// Compile the combined workflow\n",
    "const finalWorkflow = combinedWorkflow.compile();\n",
    "\n",
    "// For the notebook, we'd output an image similar to the Python version\n",
    "// In a TypeScript environment, we would visualize it with:\n",
    "// finalWorkflow.showGraph();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2091d5cc",
   "metadata": {},
   "source": [
    "This is a higher-level composition where:\n",
    "1. First, the triage router analyzes the email\n",
    "2. If needed, the response agent handles crafting a response\n",
    "3. The workflow ends when either the triage decides no response is needed or the response agent completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Test email input\n",
    "const testEmailInput = {\n",
    "  author: \"System Admin <sysadmin@company.com>\",\n",
    "  to: \"Development Team <dev@company.com>\",\n",
    "  subject: \"Scheduled maintenance - database downtime\",\n",
    "  email_thread: \"Hi team,\\n\\nThis is a reminder that we'll be performing scheduled maintenance on the production database tonight from 2AM to 4AM EST. During this time, all database services will be unavailable.\\n\\nPlease plan your work accordingly and ensure no critical deployments are scheduled during this window.\\n\\nThanks,\\nSystem Admin Team\"\n",
    "};\n",
    "\n",
    "// Run the agent\n",
    "const response = await finalWorkflow.invoke({\n",
    "  email_input: testEmailInput,\n",
    "  messages: [],\n",
    "  classification_decision: null  // Will be set during execution\n",
    "});\n",
    "\n",
    "// In a real TypeScript environment, we would display messages like:\n",
    "// response.messages.forEach(m => console.log(m));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50ae0a-7bd1-4e69-90be-781b1e77b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Second test email input\n",
    "const testEmailInput2 = {\n",
    "  author: \"Alice Smith <alice.smith@company.com>\",\n",
    "  to: \"John Doe <john.doe@company.com>\",\n",
    "  subject: \"Quick question about API documentation\",\n",
    "  email_thread: \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "};\n",
    "\n",
    "// Run the agent with the second test input\n",
    "const response2 = await finalWorkflow.invoke({\n",
    "  email_input: testEmailInput2,\n",
    "  messages: [],\n",
    "  classification_decision: null  // Will be set during execution\n",
    "});\n",
    "\n",
    "// In a real TypeScript environment, we would display messages like:\n",
    "// response2.messages.forEach(m => console.log(m));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f631f61f",
   "metadata": {},
   "source": [
    "## Testing with Local Deployment\n",
    "\n",
    "You can find the file for our agent in the `src` directory:\n",
    "\n",
    "* `src/email_assistant.ts`\n",
    "\n",
    "You can test them locally in LangGraph Studio by running:\n",
    "\n",
    "```bash\n",
    "pnpm agent\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12752016",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Example e-mail you can test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "const emailInputExample = {\n",
    "  author: \"Alice Smith <alice.smith@company.com>\",\n",
    "  to: \"John Doe <john.doe@company.com>\",\n",
    "  subject: \"Quick question about API documentation\",\n",
    "  email_thread: \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e33b6",
   "metadata": {},
   "source": [
    "![studio-img](img/studio.png)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
